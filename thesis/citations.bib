@misc{250112948DeepSeekR1Incentivizing,
  title = {[2501.12948] {{DeepSeek-R1}}: {{Incentivizing Reasoning Capability}} in {{LLMs}} via {{Reinforcement Learning}}},
  urldate = {2025-06-03},
  howpublished = {https://arxiv.org/abs/2501.12948},
  file = {C:\Users\lenna\Zotero\storage\5TA7QRHX\2501.html}
}

@misc{AadityaLlama3OpenBioLLM70BHugging,
  title = {Aaditya/{{Llama3-OpenBioLLM-70B}} {$\cdot$} {{Hugging Face}}},
  urldate = {2025-06-03},
  abstract = {We're on a journey to advance and democratize artificial intelligence through open source and open science.},
  howpublished = {https://huggingface.co/aaditya/Llama3-OpenBioLLM-70B},
  keywords = {Zwischenprasentation},
  file = {C:\Users\lenna\Zotero\storage\UNP4MXYX\Llama3-OpenBioLLM-70B.html}
}

@misc{agrawalLargeLanguageModels2022,
  title = {Large {{Language Models}} Are {{Few-Shot Clinical Information Extractors}}},
  author = {Agrawal, Monica and Hegselmann, Stefan and Lang, Hunter and Kim, Yoon and Sontag, David},
  year = {2022},
  month = nov,
  number = {arXiv:2205.12689},
  eprint = {2205.12689},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2205.12689},
  urldate = {2024-12-19},
  abstract = {A long-running goal of the clinical NLP community is the extraction of important variables trapped in clinical notes. However, roadblocks have included dataset shift from the general domain and a lack of public clinical corpora and annotations. In this work, we show that large language models, such as InstructGPT, perform well at zero- and few-shot information extraction from clinical text despite not being trained specifically for the clinical domain. Whereas text classification and generation performance have already been studied extensively in such models, here we additionally demonstrate how to leverage them to tackle a diverse set of NLP tasks which require more structured outputs, including span identification, token-level sequence classification, and relation extraction. Further, due to the dearth of available data to evaluate these systems, we introduce new datasets for benchmarking few-shot clinical information extraction based on a manual re-annotation of the CASI dataset for new tasks. On the clinical extraction tasks we studied, the GPT-3 systems significantly outperform existing zero- and few-shot baselines.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\IWJ9RUBF\\Agrawal et al. - 2022 - Large Language Models are Few-Shot Clinical Inform.pdf;C\:\\Users\\lenna\\Zotero\\storage\\3PJ9ZY92\\2205.html}
}

@misc{AlibayramMedgemma,
  title = {Alibayram/Medgemma},
  urldate = {2025-08-12},
  abstract = {MedGemma is a collection of Gemma 3 variants that are trained for performance on medical text and image comprehension.},
  howpublished = {https://ollama.com/alibayram/medgemma},
  keywords = {evaluation_models},
  file = {C:\Users\lenna\Zotero\storage\CIPGB8CJ\medgemma.html}
}

@article{aliExplainableArtificialIntelligence2023,
  title = {Explainable {{Artificial Intelligence}} ({{XAI}}): {{What}} We Know and What Is Left to Attain {{Trustworthy Artificial Intelligence}}},
  shorttitle = {Explainable {{Artificial Intelligence}} ({{XAI}})},
  author = {Ali, Sajid and Abuhmed, Tamer and {El-Sappagh}, Shaker and Muhammad, Khan and {Alonso-Moral}, Jose M. and Confalonieri, Roberto and Guidotti, Riccardo and Del Ser, Javier and {D{\'i}az-Rodr{\'i}guez}, Natalia and Herrera, Francisco},
  year = {2023},
  month = nov,
  journal = {Information Fusion},
  volume = {99},
  pages = {101805},
  issn = {1566-2535},
  doi = {10.1016/j.inffus.2023.101805},
  urldate = {2024-06-30},
  abstract = {Artificial intelligence (AI) is currently being utilized in a wide range of sophisticated applications, but the outcomes of many AI models are challenging to comprehend and trust due to their black-box nature. Usually, it is essential to understand the reasoning behind an AI model's decision-making. Thus, the need for eXplainable AI (XAI) methods for improving trust in AI models has arisen. XAI has become a popular research subject within the AI field in recent years. Existing survey papers have tackled the concepts of XAI, its general terms, and post-hoc explainability methods but there have not been any reviews that have looked at the assessment methods, available tools, XAI datasets, and other related aspects. Therefore, in this comprehensive study, we provide readers with an overview of the current research and trends in this rapidly emerging area with a case study example. The study starts by explaining the background of XAI, common definitions, and summarizing recently proposed techniques in XAI for supervised machine learning. The review divides XAI techniques into four axes using a hierarchical categorization system: (i) data explainability, (ii) model explainability, (iii) post-hoc explainability, and (iv) assessment of explanations. We also introduce available evaluation metrics as well as open-source packages and datasets with future research directions. Then, the significance of explainability in terms of legal demands, user viewpoints, and application orientation is outlined, termed as XAI concerns. This paper advocates for tailoring explanation content to specific user types. An examination of XAI techniques and evaluation was conducted by looking at 410 critical articles, published between January 2016 and October 2022, in reputed journals and using a wide range of research databases as a source of information. The article is aimed at XAI researchers who are interested in making their AI models more trustworthy, as well as towards researchers from other disciplines who are looking for effective XAI methods to complete tasks with confidence while communicating meaning from data.},
  keywords = {AI principles,Data Fusion,Deep Learning,Explainable Artificial Intelligence,Interpretable machine learning,Post-hoc explainability,Trustworthy AI,XAI assessment},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\XEII2IW9\\Ali et al. - 2023 - Explainable Artificial Intelligence (XAI) What we.pdf;C\:\\Users\\lenna\\Zotero\\storage\\GDQLL4Z3\\S1566253523001148.html}
}

@article{angelovExplainableArtificialIntelligence2021,
  title = {Explainable Artificial Intelligence: An Analytical Review},
  shorttitle = {Explainable Artificial Intelligence},
  author = {Angelov, Plamen P. and Soares, Eduardo A. and Jiang, Richard and Arnold, Nicholas I. and Atkinson, Peter M.},
  year = {2021},
  journal = {WIREs Data Mining and Knowledge Discovery},
  volume = {11},
  number = {5},
  pages = {e1424},
  issn = {1942-4795},
  doi = {10.1002/widm.1424},
  urldate = {2024-06-29},
  abstract = {This paper provides a brief analytical review of the current state-of-the-art in relation to the explainability of artificial intelligence in the context of recent advances in machine learning and deep learning. The paper starts with a brief historical introduction and a taxonomy, and formulates the main challenges in terms of explainability building on the recently formulated National Institute of Standards four principles of explainability. Recently published methods related to the topic are then critically reviewed and analyzed. Finally, future directions for research are suggested. This article is categorized under: Technologies {$>$} Artificial Intelligence Fundamental Concepts of Data and Knowledge {$>$} Explainable AI},
  copyright = {{\copyright} 2021 The Authors. WIREs Data Mining and Knowledge Discovery published by Wiley Periodicals LLC.},
  langid = {english},
  keywords = {black-box models,deep learning,explainable AI,machine learning,prototype-based models,surrogate models},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\RDFXAF7L\\Angelov et al. - 2021 - Explainable artificial intelligence an analytical.pdf;C\:\\Users\\lenna\\Zotero\\storage\\H87F6DYV\\widm.html}
}

@article{angRiseArtificialIntelligence2023,
  title = {The Rise of Artificial Intelligence: Addressing the Impact of Large Language Models Such as {{ChatGPT}} on Scientific Publications},
  shorttitle = {The Rise of Artificial Intelligence},
  author = {Ang, Tiing Leong and Choolani, Mahesh and See, Kay Choong and Poh, Kian Keong},
  year = {2023},
  month = apr,
  journal = {Singapore Medical Journal},
  volume = {64},
  number = {4},
  pages = {219},
  issn = {0037-5675},
  doi = {10.4103/singaporemedj.SMJ-2023-055},
  urldate = {2024-08-05},
  abstract = {An abstract is unavailable.},
  langid = {american},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\S53QV7FR\\Ang et al. - 2023 - The rise of artificial intelligence addressing th.pdf;C\:\\Users\\lenna\\Zotero\\storage\\NT69KHNF\\the_rise_of_artificial_intelligence__addressing.1.html}
}

@misc{aroraOptimizingLargeLanguage2024,
  title = {Optimizing {{Large Language Model Hyperparameters}} for {{Code Generation}}},
  author = {Arora, Chetan and Sayeed, Ahnaf Ibn and Licorish, Sherlock and Wang, Fanyu and Treude, Christoph},
  year = {2024},
  month = aug,
  number = {arXiv:2408.10577},
  eprint = {2408.10577},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2408.10577},
  urldate = {2025-08-12},
  abstract = {Large Language Models (LLMs), such as GPT models, are increasingly used in software engineering for various tasks, such as code generation, requirements management, and debugging. While automating these tasks has garnered significant attention, a systematic study on the impact of varying hyperparameters on code generation outcomes remains unexplored. This study aims to assess LLMs' code generation performance by exhaustively exploring the impact of various hyperparameters. Hyperparameters for LLMs are adjustable settings that affect the model's behaviour and performance. Specifically, we investigated how changes to the hyperparameters: temperature, top probability (top\_p), frequency penalty, and presence penalty affect code generation outcomes. We systematically adjusted all hyperparameters together, exploring every possible combination by making small increments to each hyperparameter at a time. This exhaustive approach was applied to 13 Python code generation tasks, yielding one of four outcomes for each hyperparameter combination: no output from the LLM, non executable code, code that fails unit tests, or correct and functional code. We analysed these outcomes for a total of 14,742 generated Python code segments, focusing on correctness, to determine how the hyperparameters influence the LLM to arrive at each outcome. Using correlation coefficient and regression tree analyses, we ascertained which hyperparameters influence which aspect of the LLM. Our results indicate that optimal performance is achieved with a temperature below 0.5, top probability below 0.75, frequency penalty above -1 and below 1.5, and presence penalty above -1. We make our dataset and results available to facilitate replication.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Software Engineering},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\KNZZ3S6X\\Arora et al. - 2024 - Optimizing Large Language Model Hyperparameters fo.pdf;C\:\\Users\\lenna\\Zotero\\storage\\ND5FS9HK\\2408.html}
}

@article{atkinsonExplanationAILaw2020,
  title = {Explanation in {{AI}} and Law: {{Past}}, Present and Future},
  shorttitle = {Explanation in {{AI}} and Law},
  author = {Atkinson, Katie and {Bench-Capon}, Trevor and Bollegala, Danushka},
  year = {2020},
  month = dec,
  journal = {Artificial Intelligence},
  volume = {289},
  pages = {103387},
  issn = {0004-3702},
  doi = {10.1016/j.artint.2020.103387},
  urldate = {2024-06-29},
  abstract = {Explanation has been a central feature of AI systems for legal reasoning since their inception. Recently, the topic of explanation of decisions has taken on a new urgency, throughout AI in general, with the increasing deployment of AI tools and the need for lay users to be able to place trust in the decisions that the support tools are recommending. This paper provides a comprehensive review of the variety of techniques for explanation that have been developed in AI and Law. We summarise the early contributions and how these have since developed. We describe a number of notable current methods for automated explanation of legal reasoning and we also highlight gaps that must be addressed by future systems to ensure that accurate, trustworthy, unbiased decision support can be provided to legal professionals. We believe that insights from AI and Law, where explanation has long been a concern, may provide useful pointers for future development of explainable AI.},
  keywords = {AI and law,Case-based reasoning,Computational models of argument,Explainable AI},
  file = {C:\Users\lenna\Zotero\storage\V6DPVNW8\S0004370220301375.html}
}

@misc{baiQwenTechnicalReport2023,
  title = {Qwen {{Technical Report}}},
  author = {Bai, Jinze and Bai, Shuai and Chu, Yunfei and Cui, Zeyu and Dang, Kai and Deng, Xiaodong and Fan, Yang and Ge, Wenbin and Han, Yu and Huang, Fei and Hui, Binyuan and Ji, Luo and Li, Mei and Lin, Junyang and Lin, Runji and Liu, Dayiheng and Liu, Gao and Lu, Chengqiang and Lu, Keming and Ma, Jianxin and Men, Rui and Ren, Xingzhang and Ren, Xuancheng and Tan, Chuanqi and Tan, Sinan and Tu, Jianhong and Wang, Peng and Wang, Shijie and Wang, Wei and Wu, Shengguang and Xu, Benfeng and Xu, Jin and Yang, An and Yang, Hao and Yang, Jian and Yang, Shusheng and Yao, Yang and Yu, Bowen and Yuan, Hongyi and Yuan, Zheng and Zhang, Jianwei and Zhang, Xingxuan and Zhang, Yichang and Zhang, Zhenru and Zhou, Chang and Zhou, Jingren and Zhou, Xiaohuan and Zhu, Tianhang},
  year = {2023},
  month = sep,
  number = {arXiv:2309.16609},
  eprint = {2309.16609},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2309.16609},
  urldate = {2025-08-19},
  abstract = {Large language models (LLMs) have revolutionized the field of artificial intelligence, enabling natural language processing tasks that were previously thought to be exclusive to humans. In this work, we introduce Qwen, the first installment of our large language model series. Qwen is a comprehensive language model series that encompasses distinct models with varying parameter counts. It includes Qwen, the base pretrained language models, and Qwen-Chat, the chat models finetuned with human alignment techniques. The base language models consistently demonstrate superior performance across a multitude of downstream tasks, and the chat models, particularly those trained using Reinforcement Learning from Human Feedback (RLHF), are highly competitive. The chat models possess advanced tool-use and planning capabilities for creating agent applications, showcasing impressive performance even when compared to bigger models on complex tasks like utilizing a code interpreter. Furthermore, we have developed coding-specialized models, Code-Qwen and Code-Qwen-Chat, as well as mathematics-focused models, Math-Qwen-Chat, which are built upon base language models. These models demonstrate significantly improved performance in comparison with open-source models, and slightly fall behind the proprietary models.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\YZGEUBCU\\Bai et al. - 2023 - Qwen Technical Report.pdf;C\:\\Users\\lenna\\Zotero\\storage\\8I59ULAZ\\2309.html}
}

@article{barredoarrietaExplainableArtificialIntelligence2020,
  title = {Explainable {{Artificial Intelligence}} ({{XAI}}): {{Concepts}}, Taxonomies, Opportunities and Challenges toward Responsible {{AI}}},
  shorttitle = {Explainable {{Artificial Intelligence}} ({{XAI}})},
  author = {Barredo Arrieta, Alejandro and {D{\'i}az-Rodr{\'i}guez}, Natalia and Del Ser, Javier and Bennetot, Adrien and Tabik, Siham and Barbado, Alberto and Garcia, Salvador and {Gil-Lopez}, Sergio and Molina, Daniel and Benjamins, Richard and Chatila, Raja and Herrera, Francisco},
  year = {2020},
  month = jun,
  journal = {Information Fusion},
  volume = {58},
  pages = {82--115},
  issn = {1566-2535},
  doi = {10.1016/j.inffus.2019.12.012},
  urldate = {2024-08-05},
  abstract = {In the last few years, Artificial Intelligence (AI) has achieved a notable momentum that, if harnessed appropriately, may deliver the best of expectations over many application sectors across the field. For this to occur shortly in Machine Learning, the entire community stands in front of the barrier of explainability, an inherent problem of the latest techniques brought by sub-symbolism (e.g. ensembles or Deep Neural Networks) that were not present in the last hype of AI (namely, expert systems and rule based models). Paradigms underlying this problem fall within the so-called eXplainable AI (XAI) field, which is widely acknowledged as a crucial feature for the practical deployment of AI models. The overview presented in this article examines the existing literature and contributions already done in the field of XAI, including a prospect toward what is yet to be reached. For this purpose we summarize previous efforts made to define explainability in Machine Learning, establishing a novel definition of explainable Machine Learning that covers such prior conceptual propositions with a major focus on the audience for which the explainability is sought. Departing from this definition, we propose and discuss about a taxonomy of recent contributions related to the explainability of different Machine Learning models, including those aimed at explaining Deep Learning methods for which a second dedicated taxonomy is built and examined in detail. This critical literature analysis serves as the motivating background for a series of challenges faced by XAI, such as the interesting crossroads of data fusion and explainability. Our prospects lead toward the concept of Responsible Artificial Intelligence, namely, a methodology for the large-scale implementation of AI methods in real organizations with fairness, model explainability and accountability at its core. Our ultimate goal is to provide newcomers to the field of XAI with a thorough taxonomy that can serve as reference material in order to stimulate future research advances, but also to encourage experts and professionals from other disciplines to embrace the benefits of AI in their activity sectors, without any prior bias for its lack of interpretability.},
  keywords = {Accountability,Comprehensibility,Data Fusion,Deep Learning,Explainable Artificial Intelligence,Fairness,Interpretability,Machine Learning,Privacy,Responsible Artificial Intelligence,Transparency},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\A6ZGNITR\\Barredo Arrieta et al. - 2020 - Explainable Artificial Intelligence (XAI) Concept.pdf;C\:\\Users\\lenna\\Zotero\\storage\\3TA7XCSD\\S1566253519308103.html}
}

@article{bharadiyaRiseArtificialIntelligence2023,
  title = {Rise of {{Artificial Intelligence}} in {{Business}} and {{Industry}}},
  author = {Bharadiya, Jasmin Praful and Thomas, Reji Kurien and Ahmed, Farhan},
  year = {2023},
  month = jun,
  journal = {Journal of Engineering Research and Reports},
  volume = {25},
  number = {3},
  pages = {85--103},
  issn = {2582-2926},
  doi = {10.9734/jerr/2023/v25i3893},
  urldate = {2024-08-04},
  langid = {english},
  keywords = {Artificial intelligence,business,healthcare,industry,machine learning ML,pharmaceutical},
  file = {C:\Users\lenna\Zotero\storage\7WIH6RR8\Bharadiya et al. - 2023 - Rise of Artificial Intelligence in Business and In.pdf}
}

@misc{bianaVANERLeveragingLarge2024,
  title = {{{VANER}}: {{Leveraging Large Language Model}} for {{Versatile}} and {{Adaptive Biomedical Named Entity Recognition}}},
  shorttitle = {{{VANER}}},
  author = {Biana, Junyi and Zhai, Weiqi and Huang, Xiaodi and Zheng, Jiaxuan and Zhu, Shanfeng},
  year = {2024},
  month = apr,
  number = {arXiv:2404.17835},
  eprint = {2404.17835},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2404.17835},
  urldate = {2025-01-16},
  abstract = {Prevalent solution for BioNER involves using representation learning techniques coupled with sequence labeling. However, such methods are inherently task-specific, demonstrate poor generalizability, and often require dedicated model for each dataset. To leverage the versatile capabilities of recently remarkable large language models (LLMs), several endeavors have explored generative approaches to entity extraction. Yet, these approaches often fall short of the effectiveness of previouly sequence labeling approaches. In this paper, we utilize the open-sourced LLM LLaMA2 as the backbone model, and design specific instructions to distinguish between different types of entities and datasets. By combining the LLM's understanding of instructions with sequence labeling techniques, we use mix of datasets to train a model capable of extracting various types of entities. Given that the backbone LLMs lacks specialized medical knowledge, we also integrate external entity knowledge bases and employ instruction tuning to compel the model to densely recognize carefully curated entities. Our model VANER, trained with a small partition of parameters, significantly outperforms previous LLMs-based models and, for the first time, as a model based on LLM, surpasses the majority of conventional state-of-the-art BioNER systems, achieving the highest F1 scores across three datasets.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\FDJJYTNT\\Biana et al. - 2024 - VANER Leveraging Large Language Model for Versati.pdf;C\:\\Users\\lenna\\Zotero\\storage\\L57XY2EK\\2404.html}
}

@misc{bianInspireLargeLanguage2023,
  title = {Inspire the {{Large Language Model}} by {{External Knowledge}} on {{BioMedical Named Entity Recognition}}},
  author = {Bian, Junyi and Zheng, Jiaxuan and Zhang, Yuyi and Zhu, Shanfeng},
  year = {2023},
  month = sep,
  number = {arXiv:2309.12278},
  eprint = {2309.12278},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2309.12278},
  urldate = {2025-01-16},
  abstract = {Large language models (LLMs) have demonstrated dominating performance in many NLP tasks, especially on generative tasks. However, they often fall short in some information extraction tasks, particularly those requiring domain-specific knowledge, such as Biomedical Named Entity Recognition (NER). In this paper, inspired by Chain-of-thought, we leverage the LLM to solve the Biomedical NER step-by-step: break down the NER task into entity span extraction and entity type determination. Additionally, for entity type determination, we inject entity knowledge to address the problem that LLM's lack of domain knowledge when predicting entity category. Experimental results show a significant improvement in our two-step BioNER approach compared to previous few-shot LLM baseline. Additionally, the incorporation of external knowledge significantly enhances entity category determination performance.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\NKLQPNIB\\Bian et al. - 2023 - Inspire the Large Language Model by External Knowl.pdf;C\:\\Users\\lenna\\Zotero\\storage\\ZC3R3A8N\\2309.html}
}

@inproceedings{bianOneshotBiomedicalNamed2024,
  title = {One-Shot {{Biomedical Named Entity Recognition}} via {{Knowledge-Inspired Large Language Model}}},
  booktitle = {Proceedings of the 15th {{ACM International Conference}} on {{Bioinformatics}}, {{Computational Biology}} and {{Health Informatics}}},
  author = {Bian, Jnuyi and Zheng, Jiaxuan and Zhang, Yuyi and Zhou, Hong and Zhu, Shanfeng},
  year = {2024},
  month = dec,
  series = {{{BCB}} '24},
  pages = {1--10},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3698587.3701356},
  urldate = {2025-07-15},
  abstract = {Large Language Models (LLMs) have demonstrated exceptional performance in numerous natural language processing tasks, particularly in generative tasks. Nevertheless, their performance in non-generative tasks, such as information extraction, especially within specialized domain-specific extraction tasks like Biomedical Named Entity Recognition (NER), has been less successful when applied in an unsupervised manner. To address this challenge, we draw inspiration from the chain-of-thought concept and adopt a two-step approach for NER using LLMs: entity span extraction and entity type determination. Additionally, we introduce a framework for incorporating domain-specific entity knowledge to mitigate the LLM's inherent lack of domain expertise during entity category determination. Experimental results from four biomedical NER datasets illustrate a significant improvement in our approach when compared to prior LLM-based methods. Furthermore, our approach achieves results on par with other few-shot methods using just one shot, in contrast to their requirement of 50 shots.},
  isbn = {9798400713026},
  keywords = {Zwischenprasentation},
  file = {C:\Users\lenna\Zotero\storage\XQDJ7F9C\Bian et al. - 2024 - One-shot Biomedical Named Entity Recognition via K.pdf}
}

@article{biswasRuleExtractionTraining2017,
  title = {Rule {{Extraction}} from {{Training Data Using Neural Network}}},
  author = {Biswas, Saroj Kumar and Chakraborty, Manomita and Purkayastha, Biswajit and Roy, Pinki and Thounaojam, Dalton Meitei},
  year = {2017},
  month = jun,
  journal = {Int. J. Artif. Intell. Tools},
  volume = {26},
  number = {03},
  pages = {1750006},
  publisher = {World Scientific Publishing Co.},
  issn = {0218-2130},
  doi = {10.1142/S0218213017500063},
  urldate = {2024-08-06},
  abstract = {Data Mining is a powerful technology to help organization to concentrate on most important data by extracting useful information from large database. One of the most commonly used techniques in data mining is Artificial Neural Network due to its high performance in many application domains. Despite many advantages of Artificial Neural Network, one of its main drawbacks is its inherent black box nature which is the main problem of using Artificial Neural Network in data mining. Therefore, this paper proposes a rule extraction algorithm from neural network using classified and misclassified data to convert the black box nature of Artificial Neural Network into a white box. The proposed algorithm is a modification of the existing algorithm, Rule Extraction by Reverse Engineering (RxREN). The proposed algorithm extracts rules from trained neural network for datasets with mixed mode attributes using pedagogical approach. The proposed algorithm uses both classified as well as misclassified data to find out the data ranges of significant attributes in respective classes, which is the innovation of the proposed algorithm. The experimental results clearly show that the performance of the proposed algorithm is superior to existing algorithms.},
  keywords = {artificial neural networks,classification,Data mining,pedagogical,rule extraction,RxREN algorithm}
}

@inproceedings{bogireddyComparativeAnalysisChatGPT42024,
  title = {Comparative {{Analysis}} of {{ChatGPT-4}} and {{LLaMA}}: {{Performance Evaluation}} on {{Text Summarization}}, {{Data Analysis}}, and {{Question Answering}}},
  shorttitle = {Comparative {{Analysis}} of {{ChatGPT-4}} and {{LLaMA}}},
  booktitle = {2024 15th {{International Conference}} on {{Computing Communication}} and {{Networking Technologies}} ({{ICCCNT}})},
  author = {Bogireddy, Srinivasa Rao and Dasari, Nagaraju},
  year = {2024},
  month = jun,
  pages = {1--7},
  publisher = {IEEE},
  address = {Kamand, India},
  doi = {10.1109/ICCCNT61001.2024.10725662},
  urldate = {2025-06-02},
  abstract = {The rise of large language models (LLMs) such as GPT-4 and LLaMA has revolutionized natural language processing (NLP) applications. While these models exhibit impressive performance across various tasks, their explainability---the ability to understand and interpret how and why they generate specific outputs---remains a critical area of research. This paper explores the explainability of GPT-4 and LLaMA responses, comparing their internal mechanisms, interpretability approaches, and the implications of their decision-making processes. Through an empirical analysis, we investigate methods to enhance their transparency and discuss the trade-offs between performance and explainability. This study highlights the challenges and opportunities in making large language models more interpretable for a wide range of stakeholders.},
  copyright = {https://doi.org/10.15223/policy-029},
  isbn = {9798350370249},
  langid = {english},
  file = {C:\Users\lenna\Zotero\storage\93L2GBLS\Bogireddy und Dasari - 2024 - Comparative Analysis of ChatGPT-4 and LLaMA Perfo.pdf}
}

@article{bolgovaComparativeAnalysisLLMs2025,
  title = {Comparative Analysis of {{LLMs}} Performance in Medical Embryology: {{A}} Cross-Platform Study of {{ChatGPT}}, {{Claude}}, {{Gemini}}, and {{Copilot}}},
  shorttitle = {Comparative Analysis of {{LLMs}} Performance in Medical Embryology},
  author = {Bolgova, Olena and Ganguly, Paul and Mavrych, Volodymyr},
  year = {2025},
  journal = {Anatomical Sciences Education},
  volume = {18},
  number = {7},
  pages = {718--726},
  issn = {1935-9780},
  doi = {10.1002/ase.70044},
  urldate = {2025-08-19},
  abstract = {Integrating artificial intelligence, particularly large language models (LLMs), into medical education represents a significant new step in how medical knowledge is accessed, processed, and evaluated. The objective of this study was to conduct a comprehensive analysis comparing the performance of advanced LLM chatbots in different topics of medical embryology courses. Two hundred United States Medical Licensing Examination (USMLE)-style multiple-choice questions were selected from the course exam database and distributed across 20 topics. The results of 3 attempts by GPT-4o, Claude, Gemini, Copilot, and GPT-3.5 to answer the assessment items were evaluated. Statistical analyses included intraclass correlation coefficients for reliability, one-way and two-way mixed ANOVAs for performance comparisons, and post hoc analyses. Effect sizes were calculated using Cohen's f and eta-squared ({$\eta$}2). On average, the selected chatbots correctly answered 78.7\% {\textpm} 15.1\% of the questions. GPT-4o and Claude performed best, correctly answering 89.7\% and 87.5\% of the questions, respectively, without a statistical difference in their performance (p = 0.238). The performance of other chatbots was significantly lower (p {$<$} 0.01): Copilot (82.5\%), Gemini (74.8\%), and GPT-3.5 (59.0\%). Test--retest reliability analysis showed good reliability for GPT-4o (ICC = 0.803), Claude (ICC = 0.865), and Gemini (ICC = 0.876), with moderate reliability for Copilot and GPT-3.5. This study suggests that AI models like GPT-4o and Claude show promise for providing tailored embryology instruction, though instructor verification remains essential.},
  copyright = {{\copyright} 2025 American Association for Anatomy.},
  langid = {english},
  keywords = {artificial intelligence,ChatGPT,Claude,Copilot,embryology,Gemini,large language models,medical education},
  file = {C:\Users\lenna\Zotero\storage\YHCUV6P3\ase.html}
}

@article{chaiComparisonTextPreprocessing2023,
  title = {Comparison of Text Preprocessing Methods},
  author = {Chai, Christine P.},
  year = {2023},
  month = may,
  journal = {Natural Language Engineering},
  volume = {29},
  number = {3},
  pages = {509--553},
  issn = {1351-3249, 1469-8110},
  doi = {10.1017/S1351324922000213},
  urldate = {2025-03-24},
  abstract = {Text preprocessing is not only an essential step to prepare the corpus for modeling but also a key area that directly affects the natural language processing (NLP) application results. For instance, precise tokenization increases the accuracy of part-of-speech (POS) tagging, and retaining multiword expressions improves reasoning and machine translation. The text corpus needs to be appropriately preprocessed before it is ready to serve as the input to computer models. The preprocessing requirements depend on both the nature of the corpus and the NLP application itself, that is, what researchers would like to achieve from analyzing the data. Conventional text preprocessing practices generally suffice, but there exist situations where the text preprocessing needs to be customized for better analysis results. Hence, we discuss the pros and cons of several common text preprocessing methods: removing formatting, tokenization, text normalization, handling punctuation, removing stopwords, stemming and lemmatization, n-gramming, and identifying multiword expressions. Then, we provide examples of text datasets which require special preprocessing and how previous researchers handled the challenge. We expect this article to be a starting guideline on how to select and fine-tune text preprocessing methods.},
  langid = {english},
  keywords = {Data preprocessing,Parsing,Text data mining},
  file = {C:\Users\lenna\Zotero\storage\QDK6ZAG8\Chai - 2023 - Comparison of text preprocessing methods.pdf}
}

@inproceedings{chiemekeEvaluationVisionRelatedProblems2007,
  title = {Evaluation of {{Vision-Related Problems}} amongst {{Computer Users}}: {{A Case Study}} of {{University}} of {{Benin}}, {{Nigeria}}.},
  shorttitle = {Evaluation of {{Vision-Related Problems}} amongst {{Computer Users}}},
  booktitle = {World {{Congress}} on {{Engineering}}},
  author = {Chiemeke, Stella C. and Akhahowa, Allen E. and Ajayi, Olajire B.},
  year = {2007},
  volume = {1},
  pages = {217--221},
  urldate = {2024-04-30},
  file = {C:\Users\lenna\Zotero\storage\HVCQF4UC\Chiemeke et al. - 2007 - Evaluation of Vision-Related Problems amongst Comp.pdf}
}

@misc{christopheMed42v2SuiteClinical2024,
  title = {Med42-v2: {{A Suite}} of {{Clinical LLMs}}},
  shorttitle = {Med42-V2},
  author = {Christophe, Cl{\'e}ment and Kanithi, Praveen K. and Raha, Tathagata and Khan, Shadab and Pimentel, Marco AF},
  year = {2024},
  month = aug,
  number = {arXiv:2408.06142},
  eprint = {2408.06142},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2408.06142},
  urldate = {2025-08-12},
  abstract = {Med42-v2 introduces a suite of clinical large language models (LLMs) designed to address the limitations of generic models in healthcare settings. These models are built on Llama3 architecture and fine-tuned using specialized clinical data. They underwent multi-stage preference alignment to effectively respond to natural prompts. While generic models are often preference-aligned to avoid answering clinical queries as a precaution, Med42-v2 is specifically trained to overcome this limitation, enabling its use in clinical settings. Med42-v2 models demonstrate superior performance compared to the original Llama3 models in both 8B and 70B parameter configurations and GPT-4 across various medical benchmarks. These LLMs are developed to understand clinical queries, perform reasoning tasks, and provide valuable assistance in clinical environments. The models are now publicly available at {\textbackslash}href\{https://huggingface.co/m42-health\}\{https://huggingface.co/m42-health\}.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,evaluation_models},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\43UMW994\\Christophe et al. - 2024 - Med42-v2 A Suite of Clinical LLMs.pdf;C\:\\Users\\lenna\\Zotero\\storage\\UE6WYLK8\\2408.html}
}

@misc{ContactDoctorBioMedicalLlama38BHugging,
  title = {{{ContactDoctor}}/{{Bio-Medical-Llama-3-8B}} {$\cdot$} {{Hugging Face}}},
  urldate = {2025-06-02},
  howpublished = {https://huggingface.co/ContactDoctor/Bio-Medical-Llama-3-8B},
  file = {C:\Users\lenna\Zotero\storage\VY7KG4SQ\Bio-Medical-Llama-3-8B.html}
}

@misc{ContextSensitiveDataGlasses,
  title = {Context-{{Sensitive Data Glasses}}},
  journal = {Else Kr{\"o}ner Fresenius Center for Digital Health},
  urldate = {2025-08-19},
  abstract = {Smart Glasses with augmented reality provide fast access to relevant information in everyday clinical practice.},
  langid = {american},
  file = {C:\Users\lenna\Zotero\storage\L9SC3QC3\context-sensitive-data-glasses.html}
}

@article{cowieInformationExtraction1996,
  title = {Information Extraction},
  author = {Cowie, Jim and Lehnert, Wendy},
  year = {1996},
  month = jan,
  journal = {Commun. ACM},
  volume = {39},
  number = {1},
  pages = {80--91},
  issn = {0001-0782},
  doi = {10.1145/234173.234209},
  urldate = {2025-07-30},
  file = {C:\Users\lenna\Zotero\storage\8FPDTYP2\Cowie und Lehnert - 1996 - Information extraction.pdf}
}

@incollection{cravenUsingSamplingQueries1994,
  title = {Using {{Sampling}} and {{Queries}} to {{Extract Rules}} from {{Trained Neural Networks}}},
  booktitle = {Machine {{Learning Proceedings}} 1994},
  author = {Craven, Mark W. and Shavlik, Jude W.},
  editor = {Cohen, William W. and Hirsh, Haym},
  year = {1994},
  month = jan,
  pages = {37--45},
  publisher = {Morgan Kaufmann},
  address = {San Francisco (CA)},
  doi = {10.1016/B978-1-55860-335-6.50013-1},
  urldate = {2024-08-06},
  abstract = {Concepts learned by neural networks are difficult to understand because they are represented using large assemblages of real-valued parameters. One approach to understanding trained neural networks is to extract symbolic rules that describe their classification behavior. There are several existing rule-extraction approaches that operate by searching for such rules. We present a novel method that casts rule extraction not as a search problem, but instead as a learning problem. In addition to learning from training examples, our method exploits the property that networks can be efficiently queried. We describe algorithms for extracting both conjunctive and M-of-N rules, and present experiments that show that our method is more efficient than conventional search-based approaches.},
  isbn = {978-1-55860-335-6},
  file = {C:\Users\lenna\Zotero\storage\FPXCGGA6\B9781558603356500131.html}
}

@article{crouseImplementing2DRectangular2016,
  title = {On Implementing {{2D}} Rectangular Assignment Algorithms},
  author = {Crouse, David F.},
  year = {2016},
  month = aug,
  journal = {IEEE Trans. Aerosp. Electron. Syst.},
  volume = {52},
  number = {4},
  pages = {1679--1696},
  issn = {0018-9251},
  doi = {10.1109/TAES.2016.140952},
  urldate = {2025-08-17},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html}
}

@article{dagdelenStructuredInformationExtraction2024,
  title = {Structured Information Extraction from Scientific Text with Large Language Models},
  author = {Dagdelen, John and Dunn, Alexander and Lee, Sanghoon and Walker, Nicholas and Rosen, Andrew S. and Ceder, Gerbrand and Persson, Kristin A. and Jain, Anubhav},
  year = {2024},
  month = feb,
  journal = {Nat Commun},
  volume = {15},
  number = {1},
  pages = {1418},
  publisher = {Nature Publishing Group},
  issn = {2041-1723},
  doi = {10.1038/s41467-024-45563-x},
  urldate = {2025-04-23},
  abstract = {Extracting structured knowledge from scientific text remains a challenging task for machine learning models. Here, we present a simple approach to joint named entity recognition and relation extraction and demonstrate how pretrained large language models (GPT-3, Llama-2) can be fine-tuned to extract useful records of complex scientific knowledge. We test three representative tasks in materials chemistry: linking dopants and host materials, cataloging metal-organic frameworks, and general composition/phase/morphology/application information extraction. Records are extracted from single sentences or entire paragraphs, and the output can be returned as simple English sentences or a more structured format such as a list of JSON objects. This approach represents a simple, accessible, and highly flexible route to obtaining large databases of structured specialized scientific knowledge extracted from research papers.},
  copyright = {2024 The Author(s)},
  langid = {english},
  keywords = {Databases,Materials science,Scientific data,Theory and computation},
  file = {C:\Users\lenna\Zotero\storage\HT49WL9A\Dagdelen et al. - 2024 - Structured information extraction from scientific .pdf}
}

@inproceedings{daiBiasUnfairnessInformation2024,
  title = {Bias and {{Unfairness}} in {{Information Retrieval Systems}}: {{New Challenges}} in the {{LLM Era}}},
  shorttitle = {Bias and {{Unfairness}} in {{Information Retrieval Systems}}},
  booktitle = {Proceedings of the 30th {{ACM SIGKDD Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Dai, Sunhao and Xu, Chen and Xu, Shicheng and Pang, Liang and Dong, Zhenhua and Xu, Jun},
  year = {2024},
  month = aug,
  series = {{{KDD}} '24},
  pages = {6437--6447},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3637528.3671458},
  urldate = {2025-06-03},
  abstract = {With the rapid advancements of large language models (LLMs), information retrieval (IR) systems, such as search engines and recommender systems, have undergone a significant paradigm shift. This evolution, while heralding new opportunities, introduces emerging challenges, particularly in terms of biases and unfairness, which may threaten the information ecosystem. In this paper, we present a comprehensive survey of existing works on emerging and pressing bias and unfairness issues in IR systems when the integration of LLMs. We first unify bias and unfairness issues as distribution mismatch problems, providing a groundwork for categorizing various mitigation strategies through distribution alignment. Subsequently, we systematically delve into the specific bias and unfairness issues arising from three critical stages of LLMs integration into IR systems: data collection, model development, and result evaluation. In doing so, we meticulously review and analyze recent literature, focusing on the definitions, characteristics, and corresponding mitigation strategies associated with these issues. Finally, we identify and highlight some open problems and challenges for future work, aiming to inspire researchers and stakeholders in the IR field and beyond to better understand and mitigate bias and unfairness issues of IR in this LLM era. We also consistently maintain a GitHub repository for the relevant papers and resources in this rising direction at https://github.com/KID-22/LLM-IR-Bias-Fairness-Survey.},
  isbn = {9798400704901},
  file = {C:\Users\lenna\Zotero\storage\952P2LP2\Dai et al. - 2024 - Bias and Unfairness in Information Retrieval Syste.pdf}
}

@misc{deepseek-aiDeepSeekR1IncentivizingReasoning2025,
  title = {{{DeepSeek-R1}}: {{Incentivizing Reasoning Capability}} in {{LLMs}} via {{Reinforcement Learning}}},
  shorttitle = {{{DeepSeek-R1}}},
  author = {{DeepSeek-AI} and Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and Zhang, Xiaokang and Yu, Xingkai and Wu, Yu and Wu, Z. F. and Gou, Zhibin and Shao, Zhihong and Li, Zhuoshu and Gao, Ziyi and Liu, Aixin and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Feng, Bei and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and Dai, Damai and Chen, Deli and Ji, Dongjie and Li, Erhang and Lin, Fangyun and Dai, Fucong and Luo, Fuli and Hao, Guangbo and Chen, Guanting and Li, Guowei and Zhang, H. and Bao, Han and Xu, Hanwei and Wang, Haocheng and Ding, Honghui and Xin, Huajian and Gao, Huazuo and Qu, Hui and Li, Hui and Guo, Jianzhong and Li, Jiashi and Wang, Jiawei and Chen, Jingchang and Yuan, Jingyang and Qiu, Junjie and Li, Junlong and Cai, J. L. and Ni, Jiaqi and Liang, Jian and Chen, Jin and Dong, Kai and Hu, Kai and Gao, Kaige and Guan, Kang and Huang, Kexin and Yu, Kuai and Wang, Lean and Zhang, Lecong and Zhao, Liang and Wang, Litong and Zhang, Liyue and Xu, Lei and Xia, Leyi and Zhang, Mingchuan and Zhang, Minghua and Tang, Minghui and Li, Meng and Wang, Miaojun and Li, Mingming and Tian, Ning and Huang, Panpan and Zhang, Peng and Wang, Qiancheng and Chen, Qinyu and Du, Qiushi and Ge, Ruiqi and Zhang, Ruisong and Pan, Ruizhe and Wang, Runji and Chen, R. J. and Jin, R. L. and Chen, Ruyi and Lu, Shanghao and Zhou, Shangyan and Chen, Shanhuang and Ye, Shengfeng and Wang, Shiyu and Yu, Shuiping and Zhou, Shunfeng and Pan, Shuting and Li, S. S. and Zhou, Shuang and Wu, Shaoqing and Ye, Shengfeng and Yun, Tao and Pei, Tian and Sun, Tianyu and Wang, T. and Zeng, Wangding and Zhao, Wanjia and Liu, Wen and Liang, Wenfeng and Gao, Wenjun and Yu, Wenqin and Zhang, Wentao and Xiao, W. L. and An, Wei and Liu, Xiaodong and Wang, Xiaohan and Chen, Xiaokang and Nie, Xiaotao and Cheng, Xin and Liu, Xin and Xie, Xin and Liu, Xingchao and Yang, Xinyu and Li, Xinyuan and Su, Xuecheng and Lin, Xuheng and Li, X. Q. and Jin, Xiangyue and Shen, Xiaojin and Chen, Xiaosha and Sun, Xiaowen and Wang, Xiaoxiang and Song, Xinnan and Zhou, Xinyi and Wang, Xianzu and Shan, Xinxia and Li, Y. K. and Wang, Y. Q. and Wei, Y. X. and Zhang, Yang and Xu, Yanhong and Li, Yao and Zhao, Yao and Sun, Yaofeng and Wang, Yaohui and Yu, Yi and Zhang, Yichao and Shi, Yifan and Xiong, Yiliang and He, Ying and Piao, Yishi and Wang, Yisong and Tan, Yixuan and Ma, Yiyang and Liu, Yiyuan and Guo, Yongqiang and Ou, Yuan and Wang, Yuduan and Gong, Yue and Zou, Yuheng and He, Yujia and Xiong, Yunfan and Luo, Yuxiang and You, Yuxiang and Liu, Yuxuan and Zhou, Yuyang and Zhu, Y. X. and Xu, Yanhong and Huang, Yanping and Li, Yaohui and Zheng, Yi and Zhu, Yuchen and Ma, Yunxian and Tang, Ying and Zha, Yukun and Yan, Yuting and Ren, Z. Z. and Ren, Zehui and Sha, Zhangli and Fu, Zhe and Xu, Zhean and Xie, Zhenda and Zhang, Zhengyan and Hao, Zhewen and Ma, Zhicheng and Yan, Zhigang and Wu, Zhiyu and Gu, Zihui and Zhu, Zijia and Liu, Zijun and Li, Zilin and Xie, Ziwei and Song, Ziyang and Pan, Zizheng and Huang, Zhen and Xu, Zhipeng and Zhang, Zhongyu and Zhang, Zhen},
  year = {2025},
  month = jan,
  journal = {arXiv.org},
  urldate = {2025-06-03},
  abstract = {We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.},
  howpublished = {https://arxiv.org/abs/2501.12948v1},
  langid = {english},
  file = {C:\Users\lenna\Zotero\storage\96PJNZJ2\DeepSeek-AI et al. - 2025 - DeepSeek-R1 Incentivizing Reasoning Capability in.pdf}
}

@misc{deepseek-aiDeepSeekR1IncentivizingReasoning2025a,
  title = {{{DeepSeek-R1}}: {{Incentivizing Reasoning Capability}} in {{LLMs}} via {{Reinforcement Learning}}},
  shorttitle = {{{DeepSeek-R1}}},
  author = {{DeepSeek-AI} and Guo, Daya and Yang, Dejian and Zhang, Haowei and Song, Junxiao and Zhang, Ruoyu and Xu, Runxin and Zhu, Qihao and Ma, Shirong and Wang, Peiyi and Bi, Xiao and Zhang, Xiaokang and Yu, Xingkai and Wu, Yu and Wu, Z. F. and Gou, Zhibin and Shao, Zhihong and Li, Zhuoshu and Gao, Ziyi and Liu, Aixin and Xue, Bing and Wang, Bingxuan and Wu, Bochao and Feng, Bei and Lu, Chengda and Zhao, Chenggang and Deng, Chengqi and Zhang, Chenyu and Ruan, Chong and Dai, Damai and Chen, Deli and Ji, Dongjie and Li, Erhang and Lin, Fangyun and Dai, Fucong and Luo, Fuli and Hao, Guangbo and Chen, Guanting and Li, Guowei and Zhang, H. and Bao, Han and Xu, Hanwei and Wang, Haocheng and Ding, Honghui and Xin, Huajian and Gao, Huazuo and Qu, Hui and Li, Hui and Guo, Jianzhong and Li, Jiashi and Wang, Jiawei and Chen, Jingchang and Yuan, Jingyang and Qiu, Junjie and Li, Junlong and Cai, J. L. and Ni, Jiaqi and Liang, Jian and Chen, Jin and Dong, Kai and Hu, Kai and Gao, Kaige and Guan, Kang and Huang, Kexin and Yu, Kuai and Wang, Lean and Zhang, Lecong and Zhao, Liang and Wang, Litong and Zhang, Liyue and Xu, Lei and Xia, Leyi and Zhang, Mingchuan and Zhang, Minghua and Tang, Minghui and Li, Meng and Wang, Miaojun and Li, Mingming and Tian, Ning and Huang, Panpan and Zhang, Peng and Wang, Qiancheng and Chen, Qinyu and Du, Qiushi and Ge, Ruiqi and Zhang, Ruisong and Pan, Ruizhe and Wang, Runji and Chen, R. J. and Jin, R. L. and Chen, Ruyi and Lu, Shanghao and Zhou, Shangyan and Chen, Shanhuang and Ye, Shengfeng and Wang, Shiyu and Yu, Shuiping and Zhou, Shunfeng and Pan, Shuting and Li, S. S. and Zhou, Shuang and Wu, Shaoqing and Ye, Shengfeng and Yun, Tao and Pei, Tian and Sun, Tianyu and Wang, T. and Zeng, Wangding and Zhao, Wanjia and Liu, Wen and Liang, Wenfeng and Gao, Wenjun and Yu, Wenqin and Zhang, Wentao and Xiao, W. L. and An, Wei and Liu, Xiaodong and Wang, Xiaohan and Chen, Xiaokang and Nie, Xiaotao and Cheng, Xin and Liu, Xin and Xie, Xin and Liu, Xingchao and Yang, Xinyu and Li, Xinyuan and Su, Xuecheng and Lin, Xuheng and Li, X. Q. and Jin, Xiangyue and Shen, Xiaojin and Chen, Xiaosha and Sun, Xiaowen and Wang, Xiaoxiang and Song, Xinnan and Zhou, Xinyi and Wang, Xianzu and Shan, Xinxia and Li, Y. K. and Wang, Y. Q. and Wei, Y. X. and Zhang, Yang and Xu, Yanhong and Li, Yao and Zhao, Yao and Sun, Yaofeng and Wang, Yaohui and Yu, Yi and Zhang, Yichao and Shi, Yifan and Xiong, Yiliang and He, Ying and Piao, Yishi and Wang, Yisong and Tan, Yixuan and Ma, Yiyang and Liu, Yiyuan and Guo, Yongqiang and Ou, Yuan and Wang, Yuduan and Gong, Yue and Zou, Yuheng and He, Yujia and Xiong, Yunfan and Luo, Yuxiang and You, Yuxiang and Liu, Yuxuan and Zhou, Yuyang and Zhu, Y. X. and Xu, Yanhong and Huang, Yanping and Li, Yaohui and Zheng, Yi and Zhu, Yuchen and Ma, Yunxian and Tang, Ying and Zha, Yukun and Yan, Yuting and Ren, Z. Z. and Ren, Zehui and Sha, Zhangli and Fu, Zhe and Xu, Zhean and Xie, Zhenda and Zhang, Zhengyan and Hao, Zhewen and Ma, Zhicheng and Yan, Zhigang and Wu, Zhiyu and Gu, Zihui and Zhu, Zijia and Liu, Zijun and Li, Zilin and Xie, Ziwei and Song, Ziyang and Pan, Zizheng and Huang, Zhen and Xu, Zhipeng and Zhang, Zhongyu and Zhang, Zhen},
  year = {2025},
  month = jan,
  number = {arXiv:2501.12948},
  eprint = {2501.12948},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2501.12948},
  urldate = {2025-06-03},
  abstract = {We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1. DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without supervised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities. Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing reasoning behaviors. However, it encounters challenges such as poor readability, and language mixing. To address these issues and further enhance reasoning performance, we introduce DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models (1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\GJ46BJRG\\DeepSeek-AI et al. - 2025 - DeepSeek-R1 Incentivizing Reasoning Capability in.pdf;C\:\\Users\\lenna\\Zotero\\storage\\LJ5W99XW\\2501.html}
}

@article{dharXPLAINXAIInterpretable2025,
  title = {{{XPLAIN}}: {{XAI}} for {{Interpretable LLMs}} through {{Perturbation Analysis}} and {{Normalized Vector Similarity}}},
  shorttitle = {{{XPLAIN}}},
  author = {Dhar, Gopala and Devi, Sharmila},
  year = {2025},
  month = jun,
  journal = {Defensive Publications Series},
  file = {C:\Users\lenna\Zotero\storage\GCWMDNQM\8273.html}
}

@misc{DifflibHelpersComputing,
  title = {Difflib --- {{Helpers}} for Computing Deltas},
  journal = {Python documentation},
  urldate = {2025-08-17},
  abstract = {Source code: Lib/difflib.py This module provides classes and functions for comparing sequences. It can be used for example, for comparing files, and can produce information about file differences i...},
  howpublished = {https://docs.python.org/3/library/\#difflib.SequenceMatcher.ratio},
  langid = {english},
  file = {C:\Users\lenna\Zotero\storage\RYMRSLK6\difflib.html}
}

@article{doganUseArtificialIntelligence2023,
  title = {The {{Use}} of {{Artificial Intelligence}} ({{AI}}) in {{Online Learning}} and {{Distance Education Processes}}: {{A Systematic Review}} of {{Empirical Studies}}},
  shorttitle = {The {{Use}} of {{Artificial Intelligence}} ({{AI}}) in {{Online Learning}} and {{Distance Education Processes}}},
  author = {Dogan, Murat Ertan and Goru Dogan, Tulay and Bozkurt, Aras},
  year = {2023},
  month = jan,
  journal = {Applied Sciences},
  volume = {13},
  number = {5},
  pages = {3056},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3417},
  doi = {10.3390/app13053056},
  urldate = {2024-08-04},
  abstract = {Artificial intelligence (AI) technologies are used in many dimensions of our lives, including education. Motivated by the increasing use of AI technologies and the current state of the art, this study examines research on AI from the perspective of online distance education. Following a systematic review protocol and using data mining and analytics approaches, the study examines a total of 276 publications. Accordingly, time trend analysis increases steadily with a peak in recent years, and China, India, and the United States are the leading countries in research on AI in online learning and distance education. Computer science and engineering are the research areas that make the most of the contribution, followed by social sciences. t-SNE analysis reveals three dominant clusters showing thematic tendencies, which are as follows: (1) how AI technologies are used in online teaching and learning processes, (2) how algorithms are used for the recognition, identification, and prediction of students' behaviors, and (3) adaptive and personalized learning empowered through artificial intelligence technologies. Additionally, the text mining and social network analysis identified three broad research themes, which are (1) educational data mining, learning analytics, and artificial intelligence for adaptive and personalized learning; (2) algorithmic online educational spaces, ethics, and human agency; and (3) online learning through detection, identification, recognition, and prediction.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {artificial intelligence,deep learning,distance education,machine learning,online learning},
  file = {C:\Users\lenna\Zotero\storage\6773AS6Z\Dogan et al. - 2023 - The Use of Artificial Intelligence (AI) in Online .pdf}
}

@misc{dorfnerBiomedicalLargeLanguages2024,
  title = {Biomedical {{Large Languages Models Seem}} Not to Be {{Superior}} to {{Generalist Models}} on {{Unseen Medical Data}}},
  author = {Dorfner, Felix J. and Dada, Amin and Busch, Felix and Makowski, Marcus R. and Han, Tianyu and Truhn, Daniel and Kleesiek, Jens and Sushil, Madhumita and Lammert, Jacqueline and Adams, Lisa C. and Bressem, Keno K.},
  year = {2024},
  month = aug,
  number = {arXiv:2408.13833},
  eprint = {2408.13833},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2408.13833},
  urldate = {2025-06-02},
  abstract = {Large language models (LLMs) have shown potential in biomedical applications, leading to efforts to fine-tune them on domain-specific data. However, the effectiveness of this approach remains unclear. This study evaluates the performance of biomedically fine-tuned LLMs against their general-purpose counterparts on a variety of clinical tasks. We evaluated their performance on clinical case challenges from the New England Journal of Medicine (NEJM) and the Journal of the American Medical Association (JAMA) and on several clinical tasks (e.g., information extraction, document summarization, and clinical coding). Using benchmarks specifically chosen to be likely outside the fine-tuning datasets of biomedical models, we found that biomedical LLMs mostly perform inferior to their general-purpose counterparts, especially on tasks not focused on medical knowledge. While larger models showed similar performance on case tasks (e.g., OpenBioLLM-70B: 66.4\% vs. Llama-3-70B-Instruct: 65\% on JAMA cases), smaller biomedical models showed more pronounced underperformance (e.g., OpenBioLLM-8B: 30\% vs. Llama-3-8B-Instruct: 64.3\% on NEJM cases). Similar trends were observed across the CLUE (Clinical Language Understanding Evaluation) benchmark tasks, with general-purpose models often performing better on text generation, question answering, and coding tasks. Our results suggest that fine-tuning LLMs to biomedical data may not provide the expected benefits and may potentially lead to reduced performance, challenging prevailing assumptions about domain-specific adaptation of LLMs and highlighting the need for more rigorous evaluation frameworks in healthcare AI. Alternative approaches, such as retrieval-augmented generation, may be more effective in enhancing the biomedical capabilities of LLMs without compromising their general knowledge.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\WXYT989I\\Dorfner et al. - 2024 - Biomedical Large Languages Models Seem not to be S.pdf;C\:\\Users\\lenna\\Zotero\\storage\\KQWQVCB4\\2408.html}
}

@article{dorfnerEvaluatingEffectivenessBiomedical2025,
  title = {Evaluating the Effectiveness of Biomedical Fine-Tuning for Large Language Models on Clinical Tasks},
  author = {Dorfner, Felix J and Dada, Amin and Busch, Felix and Makowski, Marcus R and Han, Tianyu and Truhn, Daniel and Kleesiek, Jens and Sushil, Madhumita and Adams, Lisa C and Bressem, Keno K},
  year = {2025},
  month = jun,
  journal = {Journal of the American Medical Informatics Association},
  volume = {32},
  number = {6},
  pages = {1015--1024},
  issn = {1527-974X},
  doi = {10.1093/jamia/ocaf045},
  urldate = {2025-06-02},
  abstract = {Large language models (LLMs) have shown potential in biomedical applications, leading to efforts to fine-tune them on domain-specific data. However, the effectiveness of this approach remains unclear. This study aims to critically evaluate the performance of biomedically fine-tuned LLMs against their general-purpose counterparts across a range of clinical tasks.We evaluated the performance of biomedically fine-tuned LLMs against their general-purpose counterparts on clinical case challenges from NEJM and JAMA, and on multiple clinical tasks, such as information extraction, document summarization and clinical coding. We used a diverse set of benchmarks specifically chosen to be outside the likely fine-tuning datasets of biomedical models, ensuring a fair assessment of generalization capabilities.Biomedical LLMs generally underperformed compared to general-purpose models, especially on tasks not focused on probing medical knowledge. While on the case challenges, larger biomedical and general-purpose models showed similar performance (eg, OpenBioLLM-70B: 66.4\% vs Llama-3-70B-Instruct: 65\% on JAMA), smaller biomedical models showed more pronounced underperformance (OpenBioLLM-8B: 30\% vs Llama-3-8B-Instruct: 64.3\% on NEJM). Similar trends appeared across CLUE benchmarks, with general-purpose models often achieving higher scores in text generation, question answering, and coding. Notably, biomedical LLMs also showed a higher tendency to hallucinate.Our findings challenge the assumption that biomedical fine-tuning inherently improves LLM performance, as general-purpose models consistently performed better on unseen medical tasks. Retrieval-augmented generation may offer a more effective strategy for clinical adaptation.Fine-tuning LLMs on biomedical data may not yield the anticipated benefits. Alternative approaches, such as retrieval augmentation, should be further explored for effective and reliable clinical integration of LLMs.},
  file = {C:\Users\lenna\Zotero\storage\WRY5UCBJ\8107422.html}
}

@misc{DrLejlaBegic2022,
  title = {{Dr. Lejla Begic Fazlic / NLP-Fuzzy {$\cdot$} GitLab}},
  year = {2022},
  month = sep,
  journal = {GitLab},
  urldate = {2025-01-19},
  abstract = {This project is a part of publication " Developing Novel NLP-FUZZY System Prototype for Information Extraction from Medical Guideline ".},
  howpublished = {https://gitlab.rlp.net/l.begic899724/NLP-FUZZY},
  langid = {ngerman},
  file = {C:\Users\lenna\Zotero\storage\LV2L53YC\main.html}
}

@misc{EinsatzKuenstlicherIntelligenz,
  title = {{Einsatz von K{\"u}nstlicher Intelligenz in medizinischen Diagnosesystemen}},
  journal = {Bundesamt f{\"u}r Sicherheit in der Informationstechnik},
  urldate = {2025-02-02},
  abstract = {Im Projekt 540 ,,Einsatz von K{\"u}nstlicher Intelligenz in medizinischen Diagnose- und Prognosesystemen`` erfolgte eine prototypische Entwicklung von Qualit{\"a}tsmerkmalen f{\"u}r KI-Methoden im Bereich der EKG-Diagnostik.},
  howpublished = {https://www.bsi.bund.de/DE/Service-Navi/Publikationen/Studien/Projekt\_P540/projekt\_P540.html?nn=1108820},
  langid = {ngerman},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\PV8LGGSV\\Projekt_P540.pdf;C\:\\Users\\lenna\\Zotero\\storage\\ERB5PD8Y\\projekt_P540.html}
}

@article{erasmusWhatInterpretability2021,
  title = {What Is {{Interpretability}}?},
  author = {Erasmus, Adrian and Brunet, Tyler D. P. and Fisher, Eyal},
  year = {2021},
  month = dec,
  journal = {Philos. Technol.},
  volume = {34},
  number = {4},
  pages = {833--862},
  issn = {2210-5441},
  doi = {10.1007/s13347-020-00435-2},
  urldate = {2024-06-29},
  abstract = {We argue that artificial networks are explainable and offer a novel theory of interpretability. Two sets of conceptual questions are prominent in theoretical engagements with artificial neural networks, especially in the context of medical artificial intelligence: (1) Are networks explainable, and if so, what does it mean to explain the output of a network? And (2) what does it mean for a network to be interpretable? We argue that accounts of ``explanation'' tailored specifically to neural networks have ineffectively reinvented the wheel. In response to (1), we show how four familiar accounts of explanation apply to neural networks as they would to any scientific phenomenon. We diagnose the confusion about explaining neural networks within the machine learning literature as an equivocation on ``explainability,'' ``understandability'' and ``interpretability.'' To remedy this, we distinguish between these notions, and answer (2) by offering a theory and typology of interpretation in machine learning. Interpretation is something one does to an explanation with the aim of producing another, more understandable, explanation. As with explanation, there are various concepts and methods involved in interpretation: Total or Partial, Global or Local, and Approximative or Isomorphic. Our account of ``interpretability'' is consistent with uses in the machine learning literature, in keeping with the philosophy of explanation and understanding, and pays special attention to medical artificial intelligence systems.},
  langid = {english},
  keywords = {Explainability,Interpretability,Medical AI,XAI},
  file = {C:\Users\lenna\Zotero\storage\7TTQYF7D\Erasmus et al. - 2021 - What is Interpretability.pdf}
}

@misc{EUGesetzZurKuenstlichen,
  title = {{EU-Gesetz zur k{\"u}nstlichen Intelligenz {\textbar} Aktuelle Entwicklungen und Analysen zum EU-KI-Gesetz}},
  urldate = {2025-02-02},
  langid = {ngerman},
  file = {C:\Users\lenna\Zotero\storage\ZTKQA8BC\de.html}
}

@misc{EUGesetzZurKuenstlichena,
  title = {{EU-Gesetz zur k{\"u}nstlichen Intelligenz {\textbar} Aktuelle Entwicklungen und Analysen zum EU-KI-Gesetz}},
  urldate = {2025-02-02},
  langid = {ngerman},
  file = {C:\Users\lenna\Zotero\storage\3P54EKYH\de.html}
}

@article{fayekFuzzyLogicFuzzy2020,
  title = {Fuzzy {{Logic}} and {{Fuzzy Hybrid Techniques}} for {{Construction Engineering}} and {{Management}}},
  author = {Fayek, Aminah Robinson},
  year = {2020},
  month = jul,
  journal = {Journal of Construction Engineering and Management},
  volume = {146},
  number = {7},
  pages = {04020064},
  publisher = {American Society of Civil Engineers},
  issn = {1943-7862},
  doi = {10.1061/(ASCE)CO.1943-7862.0001854},
  urldate = {2024-08-06},
  abstract = {AbstractConstruction engineering and management are vital for successful project execution, and both researchers and practitioners continually seek ways to improve construction processes. Fuzzy logic plays an important role in many construction ...},
  copyright = {This work is made available under the terms of the Creative Commons Attribution 4.0 International license, https://creativecommons.org/licenses/by/4.0/.},
  langid = {english},
  keywords = {Artificial intelligence,Fuzzy hybrid techniques,Fuzzy logic,Machine learning,Multicriteria decision making,Optimization,Simulation},
  file = {C:\Users\lenna\Zotero\storage\5DG4GYZS\Fayek - 2020 - Fuzzy Logic and Fuzzy Hybrid Techniques for Constr.pdf}
}

@inproceedings{fazlicNovelNLPFUZZYSystem2019,
  title = {A {{Novel NLP-FUZZY System Prototype}} for {{Information Extraction}} from {{Medical Guidelines}}},
  booktitle = {2019 42nd {{International Convention}} on {{Information}} and {{Communication Technology}}, {{Electronics}} and {{Microelectronics}} ({{MIPRO}})},
  author = {Fazlic, Lejla Begic and Hallawa, Ahmed and Schmeink, Anke and Peine, Arne and Martin, Lukas and Dartmann, Guido},
  year = {2019},
  month = may,
  pages = {1025--1030},
  issn = {2623-8764},
  doi = {10.23919/MIPRO.2019.8756929},
  urldate = {2024-12-19},
  abstract = {Medical guidelines have a significant role in the field of evidence-based medical treatment. The content of a medical guideline is based on a systematic review of clinical evidence with instructions and recommendations that clinicians can refer to. Most of the guidelines are available in an unstructured text format. Hence, clinicians must take a considerable time to search and find relevant recommendations in their semantic context. Using Machine Learning algorithms, automatic information extraction from medical guidelines has recently become possible. We present a novel system for information extraction and a fuzzy rule database developed for clinical guidelines. The proposed system, dubbed NLP-FUZZY, combines capabilities of Natural Language Processing (NLP) and Fuzzy Logic approaches. First, the NLP-FUZZY performs a semantic extraction of medical guidelines using a bi-directional Long short-term memory (LSTM). Subsequently, using the extracted semantic, it creates fuzzy rules, which are able to recognize new cases in a learning domain while predicting and extract the grade of recommendation. In order to test the NLP-FUZZY system, we compared its performance with state-of-the-art NLP approaches for clinical information extraction.},
  keywords = {Biomedical imaging,Databases,Digitalization,Fuzzy logic,Fuzzy Logic,Guidelines,Machine learning,Medical guidelines,Natural language processing,Natural Language Processing,Semantics,Training},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\SR8GWPLM\\Fazlic et al. - 2019 - A Novel NLP-FUZZY System Prototype for Information.pdf;C\:\\Users\\lenna\\Zotero\\storage\\CVK8VEBB\\8756929.html}
}

@misc{Gemma3,
  title = {Gemma3},
  urldate = {2025-08-12},
  abstract = {The current, most capable model that runs on a single GPU.},
  howpublished = {https://ollama.com/library/gemma3},
  keywords = {evaluation_models},
  file = {C:\Users\lenna\Zotero\storage\VPL4SB4Z\gemma3.html}
}

@misc{GithubcomHitzzentroaGoLLIE2025,
  title = {Github.Com/Hitz-Zentroa/{{GoLLIE}}},
  year = {2025},
  month = jan,
  urldate = {2025-01-16},
  abstract = {Guideline following Large Language Model for Information Extraction},
  copyright = {Apache-2.0},
  howpublished = {HiTZ zentroa},
  keywords = {code-llama,event-extraction,gollie,guidelines,hugginface-hub,huggingface,inference,information-extraction,llama,llama2,llm,llms,named-entity-recognition,relation-extraction,state-of-the-art,text-generation,training,transformer}
}

@inproceedings{goyalHealAIHealthcareLLM2024b,
  title = {{{HealAI}}: {{A Healthcare LLM}} for {{Effective Medical Documentation}}},
  shorttitle = {{{HealAI}}},
  booktitle = {Proceedings of the 17th {{ACM International Conference}} on {{Web Search}} and {{Data Mining}}},
  author = {Goyal, Sagar and Rastogi, Eti and Rajagopal, Sree Prasanna and Yuan, Dong and Zhao, Fen and Chintagunta, Jai and Naik, Gautam and Ward, Jeff},
  year = {2024},
  month = mar,
  series = {{{WSDM}} '24},
  pages = {1167--1168},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3616855.3635739},
  urldate = {2025-05-26},
  abstract = {Since the advent of LLM's like GPT4 everyone in various industries has been trying to harness their power. Healthcare is an industry where this is a specifically challenging problem due to the high accuracy requirements. Prompt Engineering is a common technique used to design instructions for model responses, however, its challenges lie in the fact that the generic models may not be trained to accurately execute these specific tasks. We will present our journey of developing a cost-effective medical LLM, surpassing GPT4 in medical note-writing tasks. We'll touch upon our trials with medical prompt engineering, GPT4's limitations, and training an optimized LLM for specific medical tasks. We'll showcase multiple comparisons on model sizes, training data, and pipeline designs that enabled us to outperform GPT4 with smaller models, maintaining precision, reducing biases, preventing hallucinations, and enhancing note-writing style.},
  isbn = {9798400703713},
  file = {C:\Users\lenna\Zotero\storage\WLWEL5KK\Goyal et al. - 2024 - HealAI A Healthcare LLM for Effective Medical Doc.pdf}
}

@misc{grattafioriLlama3Herd2024,
  title = {The {{Llama}} 3 {{Herd}} of {{Models}}},
  author = {Grattafiori, Aaron and Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and {Al-Dahle}, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Vaughan, Alex and Yang, Amy and Fan, Angela and Goyal, Anirudh and Hartshorn, Anthony and Yang, Aobo and Mitra, Archi and Sravankumar, Archie and Korenev, Artem and Hinsvark, Arthur and Rao, Arun and Zhang, Aston and Rodriguez, Aurelien and Gregerson, Austen and Spataru, Ava and Roziere, Baptiste and Biron, Bethany and Tang, Binh and Chern, Bobbie and Caucheteux, Charlotte and Nayak, Chaya and Bi, Chloe and Marra, Chris and McConnell, Chris and Keller, Christian and Touret, Christophe and Wu, Chunyang and Wong, Corinne and Ferrer, Cristian Canton and Nikolaidis, Cyrus and Allonsius, Damien and Song, Daniel and Pintz, Danielle and Livshits, Danny and Wyatt, Danny and Esiobu, David and Choudhary, Dhruv and Mahajan, Dhruv and {Garcia-Olano}, Diego and Perino, Diego and Hupkes, Dieuwke and Lakomkin, Egor and AlBadawy, Ehab and Lobanova, Elina and Dinan, Emily and Smith, Eric Michael and Radenovic, Filip and Guzm{\'a}n, Francisco and Zhang, Frank and Synnaeve, Gabriel and Lee, Gabrielle and Anderson, Georgia Lewis and Thattai, Govind and Nail, Graeme and Mialon, Gregoire and Pang, Guan and Cucurell, Guillem and Nguyen, Hailey and Korevaar, Hannah and Xu, Hu and Touvron, Hugo and Zarov, Iliyan and Ibarra, Imanol Arrieta and Kloumann, Isabel and Misra, Ishan and Evtimov, Ivan and Zhang, Jack and Copet, Jade and Lee, Jaewon and Geffert, Jan and Vranes, Jana and Park, Jason and Mahadeokar, Jay and Shah, Jeet and van der Linde, Jelmer and Billock, Jennifer and Hong, Jenny and Lee, Jenya and Fu, Jeremy and Chi, Jianfeng and Huang, Jianyu and Liu, Jiawen and Wang, Jie and Yu, Jiecao and Bitton, Joanna and Spisak, Joe and Park, Jongsoo and Rocca, Joseph and Johnstun, Joshua and Saxe, Joshua and Jia, Junteng and Alwala, Kalyan Vasuden and Prasad, Karthik and Upasani, Kartikeya and Plawiak, Kate and Li, Ke and Heafield, Kenneth and Stone, Kevin and {El-Arini}, Khalid and Iyer, Krithika and Malik, Kshitiz and Chiu, Kuenley and Bhalla, Kunal and Lakhotia, Kushal and {Rantala-Yeary}, Lauren and van der Maaten, Laurens and Chen, Lawrence and Tan, Liang and Jenkins, Liz and Martin, Louis and Madaan, Lovish and Malo, Lubo and Blecher, Lukas and Landzaat, Lukas and de Oliveira, Luke and Muzzi, Madeline and Pasupuleti, Mahesh and Singh, Mannat and Paluri, Manohar and Kardas, Marcin and Tsimpoukelli, Maria and Oldham, Mathew and Rita, Mathieu and Pavlova, Maya and Kambadur, Melanie and Lewis, Mike and Si, Min and Singh, Mitesh Kumar and Hassan, Mona and Goyal, Naman and Torabi, Narjes and Bashlykov, Nikolay and Bogoychev, Nikolay and Chatterji, Niladri and Zhang, Ning and Duchenne, Olivier and {\c C}elebi, Onur and Alrassy, Patrick and Zhang, Pengchuan and Li, Pengwei and Vasic, Petar and Weng, Peter and Bhargava, Prajjwal and Dubal, Pratik and Krishnan, Praveen and Koura, Punit Singh and Xu, Puxin and He, Qing and Dong, Qingxiao and Srinivasan, Ragavan and Ganapathy, Raj and Calderer, Ramon and Cabral, Ricardo Silveira and Stojnic, Robert and Raileanu, Roberta and Maheswari, Rohan and Girdhar, Rohit and Patel, Rohit and Sauvestre, Romain and Polidoro, Ronnie and Sumbaly, Roshan and Taylor, Ross and Silva, Ruan and Hou, Rui and Wang, Rui and Hosseini, Saghar and Chennabasappa, Sahana and Singh, Sanjay and Bell, Sean and Kim, Seohyun Sonia and Edunov, Sergey and Nie, Shaoliang and Narang, Sharan and Raparthy, Sharath and Shen, Sheng and Wan, Shengye and Bhosale, Shruti and Zhang, Shun and Vandenhende, Simon and Batra, Soumya and Whitman, Spencer and Sootla, Sten and Collot, Stephane and Gururangan, Suchin and Borodinsky, Sydney and Herman, Tamar and Fowler, Tara and Sheasha, Tarek and Georgiou, Thomas and Scialom, Thomas and Speckbacher, Tobias and Mihaylov, Todor and Xiao, Tong and Karn, Ujjwal and Goswami, Vedanuj and Gupta, Vibhor and Ramanathan, Vignesh and Kerkez, Viktor and Gonguet, Vincent and Do, Virginie and Vogeti, Vish and Albiero, V{\'i}tor and Petrovic, Vladan and Chu, Weiwei and Xiong, Wenhan and Fu, Wenyin and Meers, Whitney and Martinet, Xavier and Wang, Xiaodong and Wang, Xiaofang and Tan, Xiaoqing Ellen and Xia, Xide and Xie, Xinfeng and Jia, Xuchao and Wang, Xuewei and Goldschlag, Yaelle and Gaur, Yashesh and Babaei, Yasmine and Wen, Yi and Song, Yiwen and Zhang, Yuchen and Li, Yue and Mao, Yuning and Coudert, Zacharie Delpierre and Yan, Zheng and Chen, Zhengxing and Papakipos, Zoe and Singh, Aaditya and Srivastava, Aayushi and Jain, Abha and Kelsey, Adam and Shajnfeld, Adam and Gangidi, Adithya and Victoria, Adolfo and Goldstand, Ahuva and Menon, Ajay and Sharma, Ajay and Boesenberg, Alex and Baevski, Alexei and Feinstein, Allie and Kallet, Amanda and Sangani, Amit and Teo, Amos and Yunus, Anam and Lupu, Andrei and Alvarado, Andres and Caples, Andrew and Gu, Andrew and Ho, Andrew and Poulton, Andrew and Ryan, Andrew and Ramchandani, Ankit and Dong, Annie and Franco, Annie and Goyal, Anuj and Saraf, Aparajita and Chowdhury, Arkabandhu and Gabriel, Ashley and Bharambe, Ashwin and Eisenman, Assaf and Yazdan, Azadeh and James, Beau and Maurer, Ben and Leonhardi, Benjamin and Huang, Bernie and Loyd, Beth and Paola, Beto De and Paranjape, Bhargavi and Liu, Bing and Wu, Bo and Ni, Boyu and Hancock, Braden and Wasti, Bram and Spence, Brandon and Stojkovic, Brani and Gamido, Brian and Montalvo, Britt and Parker, Carl and Burton, Carly and Mejia, Catalina and Liu, Ce and Wang, Changhan and Kim, Changkyu and Zhou, Chao and Hu, Chester and Chu, Ching-Hsiang and Cai, Chris and Tindal, Chris and Feichtenhofer, Christoph and Gao, Cynthia and Civin, Damon and Beaty, Dana and Kreymer, Daniel and Li, Daniel and Adkins, David and Xu, David and Testuggine, Davide and David, Delia and Parikh, Devi and Liskovich, Diana and Foss, Didem and Wang, Dingkang and Le, Duc and Holland, Dustin and Dowling, Edward and Jamil, Eissa and Montgomery, Elaine and Presani, Eleonora and Hahn, Emily and Wood, Emily and Le, Eric-Tuan and Brinkman, Erik and Arcaute, Esteban and Dunbar, Evan and Smothers, Evan and Sun, Fei and Kreuk, Felix and Tian, Feng and Kokkinos, Filippos and Ozgenel, Firat and Caggioni, Francesco and Kanayet, Frank and Seide, Frank and Florez, Gabriela Medina and Schwarz, Gabriella and Badeer, Gada and Swee, Georgia and Halpern, Gil and Herman, Grant and Sizov, Grigory and Guangyi and Zhang and Lakshminarayanan, Guna and Inan, Hakan and Shojanazeri, Hamid and Zou, Han and Wang, Hannah and Zha, Hanwen and Habeeb, Haroun and Rudolph, Harrison and Suk, Helen and Aspegren, Henry and Goldman, Hunter and Zhan, Hongyuan and Damlaj, Ibrahim and Molybog, Igor and Tufanov, Igor and Leontiadis, Ilias and Veliche, Irina-Elena and Gat, Itai and Weissman, Jake and Geboski, James and Kohli, James and Lam, Janice and Asher, Japhet and Gaya, Jean-Baptiste and Marcus, Jeff and Tang, Jeff and Chan, Jennifer and Zhen, Jenny and Reizenstein, Jeremy and Teboul, Jeremy and Zhong, Jessica and Jin, Jian and Yang, Jingyi and Cummings, Joe and Carvill, Jon and Shepard, Jon and McPhie, Jonathan and Torres, Jonathan and Ginsburg, Josh and Wang, Junjie and Wu, Kai and U, Kam Hou and Saxena, Karan and Khandelwal, Kartikay and Zand, Katayoun and Matosich, Kathy and Veeraraghavan, Kaushik and Michelena, Kelly and Li, Keqian and Jagadeesh, Kiran and Huang, Kun and Chawla, Kunal and Huang, Kyle and Chen, Lailin and Garg, Lakshya and A, Lavender and Silva, Leandro and Bell, Lee and Zhang, Lei and Guo, Liangpeng and Yu, Licheng and Moshkovich, Liron and Wehrstedt, Luca and Khabsa, Madian and Avalani, Manav and Bhatt, Manish and Mankus, Martynas and Hasson, Matan and Lennie, Matthew and Reso, Matthias and Groshev, Maxim and Naumov, Maxim and Lathi, Maya and Keneally, Meghan and Liu, Miao and Seltzer, Michael L. and Valko, Michal and Restrepo, Michelle and Patel, Mihir and Vyatskov, Mik and Samvelyan, Mikayel and Clark, Mike and Macey, Mike and Wang, Mike and Hermoso, Miquel Jubert and Metanat, Mo and Rastegari, Mohammad and Bansal, Munish and Santhanam, Nandhini and Parks, Natascha and White, Natasha and Bawa, Navyata and Singhal, Nayan and Egebo, Nick and Usunier, Nicolas and Mehta, Nikhil and Laptev, Nikolay Pavlovich and Dong, Ning and Cheng, Norman and Chernoguz, Oleg and Hart, Olivia and Salpekar, Omkar and Kalinli, Ozlem and Kent, Parkin and Parekh, Parth and Saab, Paul and Balaji, Pavan and Rittner, Pedro and Bontrager, Philip and Roux, Pierre and Dollar, Piotr and Zvyagina, Polina and Ratanchandani, Prashant and Yuvraj, Pritish and Liang, Qian and Alao, Rachad and Rodriguez, Rachel and Ayub, Rafi and Murthy, Raghotham and Nayani, Raghu and Mitra, Rahul and Parthasarathy, Rangaprabhu and Li, Raymond and Hogan, Rebekkah and Battey, Robin and Wang, Rocky and Howes, Russ and Rinott, Ruty and Mehta, Sachin and Siby, Sachin and Bondu, Sai Jayesh and Datta, Samyak and Chugh, Sara and Hunt, Sara and Dhillon, Sargun and Sidorov, Sasha and Pan, Satadru and Mahajan, Saurabh and Verma, Saurabh and Yamamoto, Seiji and Ramaswamy, Sharadh and Lindsay, Shaun and Lindsay, Shaun and Feng, Sheng and Lin, Shenghao and Zha, Shengxin Cindy and Patil, Shishir and Shankar, Shiva and Zhang, Shuqiang and Zhang, Shuqiang and Wang, Sinong and Agarwal, Sneha and Sajuyigbe, Soji and Chintala, Soumith and Max, Stephanie and Chen, Stephen and Kehoe, Steve and Satterfield, Steve and Govindaprasad, Sudarshan and Gupta, Sumit and Deng, Summer and Cho, Sungmin and Virk, Sunny and Subramanian, Suraj and Choudhury, Sy and Goldman, Sydney and Remez, Tal and Glaser, Tamar and Best, Tamara and Koehler, Thilo and Robinson, Thomas and Li, Tianhe and Zhang, Tianjun and Matthews, Tim and Chou, Timothy and Shaked, Tzook and Vontimitta, Varun and Ajayi, Victoria and Montanez, Victoria and Mohan, Vijai and Kumar, Vinay Satish and Mangla, Vishal and Ionescu, Vlad and Poenaru, Vlad and Mihailescu, Vlad Tiberiu and Ivanov, Vladimir and Li, Wei and Wang, Wenchen and Jiang, Wenwen and Bouaziz, Wes and Constable, Will and Tang, Xiaocheng and Wu, Xiaojian and Wang, Xiaolan and Wu, Xilun and Gao, Xinbo and Kleinman, Yaniv and Chen, Yanjun and Hu, Ye and Jia, Ye and Qi, Ye and Li, Yenda and Zhang, Yilin and Zhang, Ying and Adi, Yossi and Nam, Youngjin and Yu and Wang and Zhao, Yu and Hao, Yuchen and Qian, Yundi and Li, Yunlu and He, Yuzi and Rait, Zach and DeVito, Zachary and Rosnbrick, Zef and Wen, Zhaoduo and Yang, Zhenyu and Zhao, Zhiwei and Ma, Zhiyu},
  year = {2024},
  month = nov,
  number = {arXiv:2407.21783},
  eprint = {2407.21783},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2407.21783},
  urldate = {2025-06-02},
  abstract = {Modern artificial intelligence (AI) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens. This paper presents an extensive empirical evaluation of Llama 3. We find that Llama 3 delivers comparable quality to leading language models such as GPT-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety. The paper also presents the results of experiments in which we integrate image, video, and speech capabilities into Llama 3 via a compositional approach. We observe this approach performs competitively with the state-of-the-art on image, video, and speech recognition tasks. The resulting models are not yet being broadly released as they are still under development.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,evaluation_models,Zwischenprasentation},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\MSSCVJXW\\Grattafiori et al. - 2024 - The Llama 3 Herd of Models.pdf;C\:\\Users\\lenna\\Zotero\\storage\\RIWAQJ73\\2407.html}
}

@incollection{grishman1997information,
  title = {Information Extraction: {{Techniques}} and Challenges},
  booktitle = {International Summer School on Information Extraction},
  author = {Grishman, Ralph},
  year = {1997},
  pages = {10--27},
  publisher = {Springer},
  file = {C:\Users\lenna\Zotero\storage\BR2SXRIX\1997 - Information extraction Techniques and challenges.pdf}
}

@article{grishmanInformationExtraction2015,
  title = {Information {{Extraction}}},
  author = {Grishman, Ralph},
  year = {2015},
  month = sep,
  journal = {IEEE Intelligent Systems},
  volume = {30},
  number = {5},
  pages = {8--15},
  issn = {1941-1294},
  doi = {10.1109/MIS.2015.68},
  urldate = {2025-07-30},
  abstract = {Much of the world's knowledge is recorded in natural language text, but making effective use of it in this form poses a major challenge. Information extraction converts this knowledge to a structured form suitable for computer manipulation, opening up many possibilities for using it. In this review, the author describes the processing pipeline of information extraction, how the pipeline components are trained, and how this training can be made more efficient. He also describes some of the challenges that must be addressed for information extraction to become a more widely used technology.},
  keywords = {Chemistry,Databases,Hidden Markov models,information extraction,intelligent systems,natural language processing,NLP,Semantics,Syntactics,Tagging,Training},
  file = {C:\Users\lenna\Zotero\storage\LC4FE2T2\7243219.html}
}

@article{grishmanInformationExtraction2015a,
  title = {Information {{Extraction}}},
  author = {Grishman, Ralph},
  year = {2015},
  month = sep,
  journal = {IEEE Intelligent Systems},
  volume = {30},
  number = {5},
  pages = {8--15},
  issn = {1941-1294},
  doi = {10.1109/MIS.2015.68},
  urldate = {2025-07-30},
  abstract = {Much of the world's knowledge is recorded in natural language text, but making effective use of it in this form poses a major challenge. Information extraction converts this knowledge to a structured form suitable for computer manipulation, opening up many possibilities for using it. In this review, the author describes the processing pipeline of information extraction, how the pipeline components are trained, and how this training can be made more efficient. He also describes some of the challenges that must be addressed for information extraction to become a more widely used technology.},
  keywords = {Chemistry,Databases,Hidden Markov models,information extraction,intelligent systems,natural language processing,NLP,Semantics,Syntactics,Tagging,Training}
}

@article{grishmanInformationExtraction2015b,
  title = {Information {{Extraction}}},
  author = {Grishman, Ralph},
  year = {2015},
  month = sep,
  journal = {IEEE Intelligent Systems},
  volume = {30},
  number = {5},
  pages = {8--15},
  issn = {1941-1294},
  doi = {10.1109/MIS.2015.68},
  urldate = {2025-07-30},
  abstract = {Much of the world's knowledge is recorded in natural language text, but making effective use of it in this form poses a major challenge. Information extraction converts this knowledge to a structured form suitable for computer manipulation, opening up many possibilities for using it. In this review, the author describes the processing pipeline of information extraction, how the pipeline components are trained, and how this training can be made more efficient. He also describes some of the challenges that must be addressed for information extraction to become a more widely used technology.},
  keywords = {Chemistry,Databases,Hidden Markov models,information extraction,intelligent systems,natural language processing,NLP,Semantics,Syntactics,Tagging,Training},
  file = {C:\Users\lenna\Zotero\storage\Q2BPBRFI\Grishman - 2015 - Information Extraction.pdf}
}

@inbook{grishmanInformationExtractionTechniques1997,
  title = {Information Extraction: {{Techniques}} and Challenges},
  shorttitle = {Information Extraction},
  booktitle = {Lecture {{Notes}} in {{Computer Science}}},
  year = {1997},
  pages = {10--27},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  issn = {0302-9743, 1611-3349},
  doi = {10.1007/3-540-63438-x_2},
  urldate = {2025-07-30},
  collaborator = {Grishman, Ralph},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-3-540-63438-6 978-3-540-69548-6},
  langid = {english},
  file = {C:\Users\lenna\Zotero\storage\TXQD3LEI\1997 - Information extraction Techniques and challenges.pdf}
}

@inbook{grishmanInformationExtractionTechniques1997a,
  title = {Information Extraction: {{Techniques}} and Challenges},
  shorttitle = {Information Extraction},
  booktitle = {Lecture {{Notes}} in {{Computer Science}}},
  year = {1997},
  pages = {10--27},
  publisher = {Springer Berlin Heidelberg},
  address = {Berlin, Heidelberg},
  issn = {0302-9743, 1611-3349},
  doi = {10.1007/3-540-63438-x_2},
  urldate = {2025-07-30},
  collaborator = {Grishman, Ralph},
  copyright = {http://www.springer.com/tdm},
  isbn = {978-3-540-63438-6 978-3-540-69548-6},
  langid = {english}
}

@misc{guoBenchmarkingOpenSourceLarge2025,
  title = {Benchmarking {{Open-Source Large Language Models}} on {{Healthcare Text Classification Tasks}}},
  author = {Guo, Yuting and Sarker, Abeed},
  year = {2025},
  month = may,
  number = {arXiv:2503.15169},
  eprint = {2503.15169},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2503.15169},
  urldate = {2025-06-03},
  abstract = {The application of large language models (LLMs) to healthcare information extraction has emerged as a promising approach. This study evaluates the classification performance of five open-source LLMs: GEMMA-3-27B-IT, LLAMA3-70B, LLAMA4-109B, DEEPSEEK-R1-DISTILL-LLAMA-70B, and DEEPSEEK-V3-0324-UD-Q2\_K\_XL, across six healthcare-related classification tasks involving both social media data (breast cancer, changes in medication regimen, adverse pregnancy outcomes, potential COVID-19 cases) and clinical data (stigma labeling, medication change discussion). We report precision, recall, and F1 scores with 95\% confidence intervals for all model-task combinations. Our findings reveal significant performance variability between LLMs, with DeepSeekV3 emerging as the strongest overall performer, achieving the highest F1 scores in four tasks. Notably, models generally performed better on social media tasks compared to clinical data tasks, suggesting potential domain-specific challenges. GEMMA-3-27B-IT demonstrated exceptionally high recall despite its smaller parameter count, while LLAMA4-109B showed surprisingly underwhelming performance compared to its predecessor LLAMA3-70B, indicating that larger parameter counts do not guarantee improved classification results. We observed distinct precision-recall trade-offs across models, with some favoring sensitivity over specificity and vice versa. These findings highlight the importance of task-specific model selection for healthcare applications, considering the particular data domain and precision-recall requirements rather than model size alone. As healthcare increasingly integrates AI-driven text classification tools, this comprehensive benchmarking provides valuable guidance for model selection and implementation while underscoring the need for continued evaluation and domain adaptation of LLMs in healthcare contexts.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\8JKKFDRW\\Guo und Sarker - 2025 - Benchmarking Open-Source Large Language Models on .pdf;C\:\\Users\\lenna\\Zotero\\storage\\GF6WCYNC\\2503.html}
}

@inproceedings{guoKNNModelBasedApproach2003,
  title = {{{KNN Model-Based Approach}} in {{Classification}}},
  booktitle = {On {{The Move}} to {{Meaningful Internet Systems}} 2003: {{CoopIS}}, {{DOA}}, and {{ODBASE}}},
  author = {Guo, Gongde and Wang, Hui and Bell, David and Bi, Yaxin and Greer, Kieran},
  editor = {Meersman, Robert and Tari, Zahir and Schmidt, Douglas C.},
  year = {2003},
  pages = {986--996},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-540-39964-3_62},
  abstract = {The k-Nearest-Neighbours (kNN) is a simple but effective method for classification. The major drawbacks with respect to kNN are (1) its low efficiency -- being a lazy learning method prohibits it in many applications such as dynamic web mining for a large repository, and (2) its dependency on the selection of a ``good value'' for k. In this paper, we propose a novel kNN type method for classification that is aimed at overcoming these shortcomings. Our method constructs a kNN model for the data, which replaces the data to serve as the basis of classification. The value of k is automatically determined, is varied for different data, and is optimal in terms of classification accuracy. The construction of the model reduces the dependency on k and makes classification faster. Experiments were carried out on some public datasets collected from the UCI machine learning repository in order to test our method. The experimental results show that the kNN based model compares well with C5.0 and kNN in terms of classification accuracy, but is more efficient than the standard kNN.},
  isbn = {978-3-540-39964-3},
  langid = {english},
  file = {C:\Users\lenna\Zotero\storage\F8DWKTCI\Guo et al. - 2003 - KNN Model-Based Approach in Classification.pdf}
}

@article{hahnMedicalInformationExtraction2020,
  title = {Medical {{Information Extraction}} in the {{Age}} of {{Deep Learning}}},
  author = {Hahn, Udo and Oleynik, Michel},
  year = {2020},
  month = aug,
  journal = {Yearb Med Inform},
  volume = {29},
  number = {1},
  pages = {208--220},
  publisher = {Georg Thieme Verlag KG},
  issn = {0943-4747, 2364-0502},
  doi = {10.1055/s-0040-1702001},
  urldate = {2024-12-19},
  abstract = {Objectives: We survey recent developments in medical Information Extraction (IE) as reported in the literature from the past three years. Our focus is on the fundamental methodological paradigm shift from standard Machine Learning (ML) techniques to Deep Neural Networks (DNNs). We describe applications of this new paradigm concentrating on two basic IE tasks, named entity recognition and relation extraction, for two selected semantic classes---diseases and drugs (or medications)---and relations between them.   Methods: For the time period from 2017 to early 2020, we searched for relevant publications from three major scientific communities: medicine and medical informatics, natural language processing, as well as neural networks and artificial intelligence.   Results: In the past decade, the field of Natural Language Processing (NLP) has undergone a profound methodological shift from symbolic to distributed representations based on the paradigm of Deep Learning (DL). Meanwhile, this trend is, although with some delay, also reflected in the medical NLP community. In the reporting period, overwhelming experimental evidence has been gathered, as illustrated in this survey for medical IE, that DL-based approaches outperform non-DL ones by often large margins. Still, small-sized and access-limited corpora create intrinsic problems for data-greedy DL as do special linguistic phenomena of medical sublanguages that have to be overcome by adaptive learning strategies.   Conclusions: The paradigm shift from (feature-engineered) ML to DNNs changes the fundamental methodological rules of the game for medical NLP. This change is by no means restricted to medical IE but should also deeply influence other areas of medical informatics, either NLP- or non-NLP-based.},
  copyright = {Georg Thieme Verlag KG Stuttgart},
  langid = {english},
  keywords = {deep learning,information extraction,named entity recognition,natural language processing,Neural networks,relation extraction},
  file = {C:\Users\lenna\Zotero\storage\IBSBTSMQ\Hahn und Oleynik - 2020 - Medical Information Extraction in the Age of Deep .pdf}
}

@article{hassijaInterpretingBlackBoxModels2024a,
  title = {Interpreting {{Black-Box Models}}: {{A Review}} on {{Explainable Artificial Intelligence}}},
  shorttitle = {Interpreting {{Black-Box Models}}},
  author = {Hassija, Vikas and Chamola, Vinay and Mahapatra, Atmesh and Singal, Abhinandan and Goel, Divyansh and Huang, Kaizhu and Scardapane, Simone and Spinelli, Indro and Mahmud, Mufti and Hussain, Amir},
  year = {2024},
  month = jan,
  journal = {Cogn Comput},
  volume = {16},
  number = {1},
  pages = {45--74},
  issn = {1866-9964},
  doi = {10.1007/s12559-023-10179-8},
  urldate = {2024-08-06},
  abstract = {Recent years have seen a tremendous growth in Artificial Intelligence (AI)-based methodological development in a broad range of~domains. In this~rapidly evolving field, large number of methods are being reported using machine learning (ML) and Deep Learning (DL) models. Majority of these models are~inherently complex and lacks explanations~of the decision making process~causing these models to be termed as 'Black-Box'. One of the major bottlenecks to adopt such models in mission-critical application domains, such as~banking, e-commerce, healthcare, and public services and~safety, is the difficulty in~interpreting them. Due to the rapid proleferation of these AI models, explaining their learning and decision making process are~getting harder which require~transparency~and easy predictability.~Aiming to collate the current state-of-the-art in interpreting the black-box models,~this study provides a comprehensive analysis of the~explainable AI (XAI)~models. To reduce~false negative and false positive outcomes of these back-box models,~finding flaws in them~is still difficult and inefficient. In this paper, the development of XAI is reviewed meticulously~through careful selection and analysis of the current state-of-the-art of XAI research. It~also provides a comprehensive and in-depth evaluation of the XAI frameworks and their efficacy to serve as a starting point of XAI for applied and theoretical researchers. Towards the end, it~highlights emerging~and~critical issues pertaining to XAI research to~showcase major, model-specific trends~for better explanation, enhanced~transparency, and improved~prediction~accuracy.},
  langid = {english},
  keywords = {Black-box models,Interpretability,Machine learning,Responsible AI,Transparency,XAI},
  file = {C:\Users\lenna\Zotero\storage\CIXFPE8A\Hassija et al. - 2024 - Interpreting Black-Box Models A Review on Explain.pdf}
}

@misc{howardUniversalLanguageModel2018,
  title = {Universal {{Language Model Fine-tuning}} for {{Text Classification}}},
  author = {Howard, Jeremy and Ruder, Sebastian},
  year = {2018},
  month = may,
  number = {arXiv:1801.06146},
  eprint = {1801.06146},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1801.06146},
  urldate = {2025-08-18},
  abstract = {Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24\% on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100x more data. We open-source our pretrained models and code.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\KY5RUSRW\\Howard und Ruder - 2018 - Universal Language Model Fine-tuning for Text Clas.pdf;C\:\\Users\\lenna\\Zotero\\storage\\47FQACAD\\1801.html}
}

@misc{HttpsCdnAaai,
  title = {{{https://cdn.aaai.org/FLAIRS/2004/Flairs04-113.pdf}}},
  urldate = {2024-08-06},
  howpublished = {https://cdn.aaai.org/FLAIRS/2004/Flairs04-113.pdf}
}

@misc{HttpsWwwresearchgatenetProfile,
  title = {{{https://www.researchgate.net/profile/Ravi-Ranjan-84/publication/386506882\_Trustworthiness\_of\_LLMs\_in\_Medical\_Domain/links/675351dcb558f41d0fbd6e5d/Trustworthiness-of-LLMs-in-Medical-Domain.pdf}}},
  urldate = {2025-07-16},
  howpublished = {https://www.researchgate.net/profile/Ravi-Ranjan-84/publication/386506882\_Trustworthiness\_of\_LLMs\_in\_Medical\_Domain/links/675351dcb558f41d0fbd6e5d/Trustworthiness-of-LLMs-in-Medical-Domain.pdf}
}

@misc{HttpsWwwresearchgatenetProfilea,
  title = {{{https://www.researchgate.net/profile/Ravi-Ranjan-84/publication/386506882\_Trustworthiness\_of\_LLMs\_in\_Medical\_Domain/links/675351dcb558f41d0fbd6e5d/Trustworthiness-of-LLMs-in-Medical-Domain.pdf}}},
  urldate = {2025-07-16},
  howpublished = {https://www.researchgate.net/profile/Ravi-Ranjan-84/publication/386506882\_Trustworthiness\_of\_LLMs\_in\_Medical\_Domain/links/675351dcb558f41d0fbd6e5d/Trustworthiness-of-LLMs-in-Medical-Domain.pdf}
}

@misc{HttpsWwwresearchgatenetProfileb,
  title = {{{https://www.researchgate.net/profile/Ravi-Ranjan-84/publication/386506882\_Trustworthiness\_of\_LLMs\_in\_Medical\_Domain/links/675351dcb558f41d0fbd6e5d/Trustworthiness-of-LLMs-in-Medical-Domain.pdf}}},
  urldate = {2025-07-16},
  howpublished = {https://www.researchgate.net/profile/Ravi-Ranjan-84/publication/386506882\_Trustworthiness\_of\_LLMs\_in\_Medical\_Domain/links/675351dcb558f41d0fbd6e5d/Trustworthiness-of-LLMs-in-Medical-Domain.pdf}
}

@misc{HttpsWwwteamnborgWpcontent,
  title = {{{https://www.team-nb.org/wp-content/uploads/2024/11/Team-NB-PositionPaper-AI-in-MD-Questionnaire-V1-20241125.pdf}}},
  urldate = {2025-02-02},
  howpublished = {https://www.team-nb.org/wp-content/uploads/2024/11/Team-NB-PositionPaper-AI-in-MD-Questionnaire-V1-20241125.pdf}
}

@article{huebnerSavingEnergyLight2016,
  title = {Saving Energy with Light? {{Experimental}} Studies Assessing the Impact of Colour Temperature on Thermal Comfort},
  shorttitle = {Saving Energy with Light?},
  author = {Huebner, Gesche M. and Shipworth, David T. and Gauthier, Stephanie and Witzel, Christoph and Raynham, Peter and Chan, {\relax WJER}},
  year = {2016},
  journal = {Energy Research \& Social Science},
  volume = {15},
  pages = {45--57},
  publisher = {Elsevier},
  urldate = {2024-04-30},
  file = {C:\Users\lenna\Zotero\storage\UX4ZULUW\S2214629616300196.html}
}

@article{huImprovingLargeLanguage2024,
  title = {Improving Large Language Models for Clinical Named Entity Recognition via Prompt Engineering},
  author = {Hu, Yan and Chen, Qingyu and Du, Jingcheng and Peng, Xueqing and Keloth, Vipina Kuttichi and Zuo, Xu and Zhou, Yujia and Li, Zehan and Jiang, Xiaoqian and Lu, Zhiyong and Roberts, Kirk and Xu, Hua},
  year = {2024},
  month = sep,
  journal = {Journal of the American Medical Informatics Association},
  volume = {31},
  number = {9},
  pages = {1812--1820},
  issn = {1527-974X},
  doi = {10.1093/jamia/ocad259},
  urldate = {2025-01-16},
  abstract = {The study highlights the potential of large language models, specifically GPT-3.5 and GPT-4, in processing complex clinical data and extracting meaningful information with minimal training data. By developing and refining prompt-based strategies, we can significantly enhance the models' performance, making them viable tools for clinical NER tasks and possibly reducing the reliance on extensive annotated datasets.This study quantifies the capabilities of GPT-3.5 and GPT-4 for clinical named entity recognition (NER) tasks and proposes task-specific prompts to improve their performance.We evaluated these models on 2 clinical NER tasks: (1) to extract medical problems, treatments, and tests from clinical notes in the MTSamples corpus, following the 2010 i2b2 concept extraction shared task, and (2) to identify nervous system disorder-related adverse events from safety reports in the vaccine adverse event reporting system (VAERS). To improve the GPT models' performance, we developed a clinical task-specific prompt framework that includes (1) baseline prompts with task description and format specification, (2) annotation guideline-based prompts, (3) error analysis-based instructions, and (4) annotated samples for few-shot learning. We assessed each prompt's effectiveness and compared the models to BioClinicalBERT.Using baseline prompts, GPT-3.5 and GPT-4 achieved relaxed F1 scores of 0.634, 0.804 for MTSamples and 0.301, 0.593 for VAERS. Additional prompt components consistently improved model performance. When all 4 components were used, GPT-3.5 and GPT-4 achieved relaxed F1 socres of 0.794, 0.861 for MTSamples and 0.676, 0.736 for VAERS, demonstrating the effectiveness of our prompt framework. Although these results trail BioClinicalBERT (F1 of 0.901 for the MTSamples dataset and 0.802 for the VAERS), it is very promising considering few training samples are needed.The study's findings suggest a promising direction in leveraging LLMs for clinical NER tasks. However, while the performance of GPT models improved with task-specific prompts, there's a need for further development and refinement. LLMs like GPT-4 show potential in achieving close performance to state-of-the-art models like BioClinicalBERT, but they still require careful prompt engineering and understanding of task-specific knowledge. The study also underscores the importance of evaluation schemas that accurately reflect the capabilities and performance of LLMs in clinical settings.While direct application of GPT models to clinical NER tasks falls short of optimal performance, our task-specific prompt framework, incorporating medical knowledge and training samples, significantly enhances GPT models' feasibility for potential clinical applications.},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\X2GEBXC3\\Hu et al. - 2024 - Improving large language models for clinical named.pdf;C\:\\Users\\lenna\\Zotero\\storage\\KWW5IRS3\\7590607.html}
}

@misc{hussainAIDrivenKnowledge2020,
  title = {{{AI Driven Knowledge Extraction}} from {{Clinical Practice Guidelines}}: {{Turning Research}} into {{Practice}}},
  shorttitle = {{{AI Driven Knowledge Extraction}} from {{Clinical Practice Guidelines}}},
  author = {Hussain, Musarrat and Hussain, Jamil and Ali, Taqdir and Satti, Fahad Ahmed and Lee, Sungyoung},
  year = {2020},
  month = dec,
  number = {arXiv:2012.05489},
  eprint = {2012.05489},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2012.05489},
  urldate = {2024-12-19},
  abstract = {Background and Objectives: Clinical Practice Guidelines (CPGs) represent the foremost methodology for sharing state-of-the-art research findings in the healthcare domain with medical practitioners to limit practice variations, reduce clinical cost, improve the quality of care, and provide evidence based treatment. However, extracting relevant knowledge from the plethora of CPGs is not feasible for already burdened healthcare professionals, leading to large gaps between clinical findings and real practices. It is therefore imperative that state-of-the-art Computing research, especially machine learning is used to provide artificial intelligence based solution for extracting the knowledge from CPGs and reducing the gap between healthcare research/guidelines and practice. Methods: This research presents a novel methodology for knowledge extraction from CPGs to reduce the gap and turn the latest research findings into clinical practice. First, our system classifies the CPG sentences into four classes such as condition-action, condition-consequences, action, and not-applicable based on the information presented in a sentence. We use deep learning with state-of-the-art word embedding, improved word vectors technique in classification process. Second, it identifies qualifier terms in the classified sentences, which assist in recognizing the condition and action phrases in a sentence. Finally, the condition and action phrase are processed and transformed into plain rule If Condition(s) Then Action format. Results: We evaluate the methodology on three different domains guidelines including Hypertension, Rhinosinusitis, and Asthma. The deep learning model classifies the CPG sentences with an accuracy of 95\%. While rule extraction was validated by user-centric approach, which achieved a Jaccard coefficient of 0.6, 0.7, and 0.4 with three human experts extracted rules, respectively.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Zwischenprasentation},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\4MC5SPTC\\Hussain et al. - 2020 - AI Driven Knowledge Extraction from Clinical Pract.pdf;C\:\\Users\\lenna\\Zotero\\storage\\SURT4NWA\\2012.html}
}

@inproceedings{hussainInformationExtractionClinical2019,
  title = {Information {{Extraction}} from {{Clinical Practice Guidelines}}: {{A Step Towards Guidelines Adherence}}},
  shorttitle = {Information {{Extraction}} from {{Clinical Practice Guidelines}}},
  booktitle = {Proceedings of the 13th {{International Conference}} on {{Ubiquitous Information Management}} and {{Communication}} ({{IMCOM}}) 2019},
  author = {Hussain, Musarrat and Lee, Sungyoung},
  editor = {Lee, Sukhan and Ismail, Roslan and Choo, Hyunseung},
  year = {2019},
  pages = {1029--1036},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-19063-7_81},
  abstract = {Clinical Practice Guidelines (CPGs) are an essential resource for standardization and dissemination of medical knowledge. Adherence to these guidelines at the point of care or by the Clinical Decision Support System (CDSS) can greatly enhance the healthcare quality and reduce practice variations. However, CPG adherence is greatly impeded due to the variety of information held by these lengthy and difficult to parse text documents. In this research, we propose a mechanism for extracting meaningful information from CPGs, by transforming it into a structured format and training machine learning models including Na{\"i}ve Bayes, Generalized Linear Model, Deep Learning, Decision Tree, Random Forest, and Ensemble Learner on that structured formatted data. Application of our proposed technique with the aforementioned models on Rhinosinusitis and Hypertension guidelines achieved an accuracy of 82.10\%, 74.40\%, 66.70\%, 66.79\%, 74.40\%, and 83.94\% respectively. Our proposed solution is not only able to reduce the processing time of CPGs but is equally beneficial to be used as a preprocessing step for other applications utilizing CPGs.},
  isbn = {978-3-030-19063-7},
  langid = {english}
}

@article{hussainTextClassificationClinical2021,
  title = {Text {{Classification}} in {{Clinical Practice Guidelines Using Machine-Learning Assisted Pattern-Based Approach}}},
  author = {Hussain, Musarrat and Hussain, Jamil and Ali, Taqdir and Ali, Syed Imran and Bilal, Hafiz Syed Muhammad and Lee, Sungyoung and Chung, Taechoong},
  year = {2021},
  month = jan,
  journal = {Applied Sciences},
  volume = {11},
  number = {8},
  pages = {3296},
  publisher = {Multidisciplinary Digital Publishing Institute},
  issn = {2076-3417},
  doi = {10.3390/app11083296},
  urldate = {2025-02-25},
  abstract = {Clinical Practice Guidelines (CPGs) aim to optimize patient care by assisting physicians during the decision-making process. However, guideline adherence is highly affected by its unstructured format and aggregation of background information with disease-specific information. The objective of our study is to extract disease-specific information from CPG for enhancing its adherence ratio. In this research, we propose a semi-automatic mechanism for extracting disease-specific information from CPGs using pattern-matching techniques. We apply supervised and unsupervised machine-learning algorithms on CPG to extract a list of salient terms contributing to distinguishing recommendation sentences (RS) from non-recommendation sentences (NRS). Simultaneously, a group of experts also analyzes the same CPG and extract the initial patterns ``Heuristic Patterns'' using a group decision-making method, nominal group technique (NGT). We provide the list of salient terms to the experts and ask them to refine their extracted patterns. The experts refine patterns considering the provided salient terms. The extracted heuristic patterns depend on specific terms and suffer from the specialization problem due to synonymy and polysemy. Therefore, we generalize the heuristic patterns to part-of-speech (POS) patterns and unified medical language system (UMLS) patterns, which make the proposed method generalize for all types of CPGs. We evaluated the initial extracted patterns on asthma, rhinosinusitis, and hypertension guidelines with the accuracy of 76.92\%, 84.63\%, and 89.16\%, respectively. The accuracy increased to 78.89\%, 85.32\%, and 92.07\% with refined machine-learning assistive patterns, respectively. Our system assists physicians by locating disease-specific information in the CPGs, which enhances the physicians' performance and reduces CPG processing time. Additionally, it is beneficial in CPGs content annotation.},
  copyright = {http://creativecommons.org/licenses/by/3.0/},
  langid = {english},
  keywords = {clinical text mining,guideline processing,information extraction,pattern extraction,recommendation statements identification},
  file = {C:\Users\lenna\Zotero\storage\DI8TM6SJ\Hussain et al. - 2021 - Text Classification in Clinical Practice Guideline.pdf}
}

@incollection{husseinyRisingTrendArtificial2023,
  title = {The {{Rising Trend}} of {{Artificial Intelligence}} in {{Social Media}}: {{Applications}}, {{Challenges}}, and {{Opportunities}}},
  shorttitle = {The {{Rising Trend}} of {{Artificial Intelligence}} in {{Social Media}}},
  booktitle = {Handbook of {{Research}} on {{AI Methods}} and {{Applications}} in {{Computer Engineering}}},
  author = {Husseiny, Fatima Al},
  year = {2023},
  pages = {42--61},
  publisher = {IGI Global},
  doi = {10.4018/978-1-6684-6937-8.ch003},
  urldate = {2024-08-05},
  abstract = {Artificial intelligence (AI) is a branch of cognitive science concerned with intelligent machines capable of doing tasks formerly accomplished by humans. It focuses on using computers to perform activities that require knowledge, perception, reasoning, comprehension, and cognitive talents. AI algori...},
  copyright = {Access limited to members},
  isbn = {978-1-66846-937-8},
  langid = {english}
}

@article{igbinoviaArtificialIntelligenceAlgorithm2025,
  title = {Artificial Intelligence Algorithm Bias in Information Retrieval Systems and Its Implication for Library and Information Science Professionals: {{A}} Scoping Review},
  shorttitle = {Artificial Intelligence Algorithm Bias in Information Retrieval Systems and Its Implication for Library and Information Science Professionals},
  author = {Igbinovia, Magnus Osahon and Danquah, Monica Mensah},
  year = {2025},
  month = may,
  journal = {Technical Services Quarterly},
  volume = {0},
  number = {0},
  pages = {1--27},
  publisher = {Routledge},
  issn = {0731-7131},
  doi = {10.1080/07317131.2025.2512282},
  urldate = {2025-06-03},
  abstract = {This scoping review examines AI algorithm bias and its implications for library and information science (LIS) professionals. Using the ScR methodology and PRISMA-ScR checklist, an initial search across Scopus, Web of Science, and EBSCOhost yielded 665 documents, with 76 meeting inclusion criteria. Findings reveal that AI bias affects Information Retrieval Systems (IRS) through biased training data, unfair representation, and lack of transparency, raising ethical concerns. The study emphasizes LIS professionals' role in mitigating bias through information literacy, algorithmic audits, ethical data curation, collaboration, and policy advocacy. Addressing AI bias is crucial to ensuring credible and fair IRS.},
  keywords = {algorithm bias,Artificial intelligence,information retrieval system,library and information science professionals,scoping review},
  file = {C:\Users\lenna\Zotero\storage\554GQI65\Igbinovia und and Mensah Danquah - Artificial intelligence algorithm bias in informat.pdf}
}

@article{igbinoviaArtificialIntelligenceAlgorithma,
  title = {Artificial Intelligence Algorithm Bias in Information Retrieval Systems and Its Implication for Library and Information Science Professionals: {{A}} Scoping Review},
  shorttitle = {Artificial Intelligence Algorithm Bias in Information Retrieval Systems and Its Implication for Library and Information Science Professionals},
  author = {Igbinovia, Magnus Osahon and {and Mensah Danquah}, Monica},
  journal = {Technical Services Quarterly},
  volume = {0},
  number = {0},
  pages = {1--27},
  publisher = {Routledge},
  issn = {0731-7131},
  doi = {10.1080/07317131.2025.2512282},
  urldate = {2025-06-03},
  abstract = {This scoping review examines AI algorithm bias and its implications for library and information science (LIS) professionals. Using the ScR methodology and PRISMA-ScR checklist, an initial search across Scopus, Web of Science, and EBSCOhost yielded 665 documents, with 76 meeting inclusion criteria. Findings reveal that AI bias affects Information Retrieval Systems (IRS) through biased training data, unfair representation, and lack of transparency, raising ethical concerns. The study emphasizes LIS professionals' role in mitigating bias through information literacy, algorithmic audits, ethical data curation, collaboration, and policy advocacy. Addressing AI bias is crucial to ensuring credible and fair IRS.},
  keywords = {algorithm bias,Artificial intelligence,information retrieval system,library and information science professionals,scoping review},
  file = {C:\Users\lenna\Zotero\storage\NUPQI9R8\Igbinovia und and Mensah Danquah - Artificial intelligence algorithm bias in informat.pdf}
}

@misc{ImprovingLanguageUnderstanding,
  title = {Improving Language Understanding with Unsupervised Learning {\textbar} {{OpenAI}}},
  urldate = {2025-08-19},
  howpublished = {https://openai.com/index/language-unsupervised/},
  file = {C:\Users\lenna\Zotero\storage\NIXRYMNU\language-unsupervised.html}
}

@misc{IntroducingClaude,
  title = {Introducing {{Claude}}},
  urldate = {2025-08-19},
  abstract = {Anthropic is an AI safety and research company that's working to build reliable, interpretable, and steerable AI systems.},
  howpublished = {https://www.anthropic.com/news/introducing-claude},
  langid = {english},
  file = {C:\Users\lenna\Zotero\storage\ZYU3LKPC\introducing-claude.html}
}

@misc{IntroducingClaude4,
  title = {Introducing {{Claude}} 4 {\textbackslash} {{Anthropic}}},
  urldate = {2025-08-19},
  howpublished = {https://www.anthropic.com/news/claude-4},
  file = {C:\Users\lenna\Zotero\storage\U4543ZZ9\claude-4.html}
}

@misc{IntroducingGemini202024,
  title = {Introducing {{Gemini}} 2.0: Our New {{AI}} Model for the Agentic Era},
  shorttitle = {Introducing {{Gemini}} 2.0},
  year = {2024},
  month = dec,
  journal = {Google},
  urldate = {2025-08-19},
  abstract = {Today, we're announcing Gemini 2.0, our most capable AI model yet.},
  howpublished = {https://blog.google/technology/google-deepmind/google-gemini-ai-update-december-2024/},
  langid = {american},
  file = {C:\Users\lenna\Zotero\storage\AVQTKFYQ\google-gemini-ai-update-december-2024.html}
}

@misc{IntroducingGPT52025,
  title = {Introducing {{GPT-5}}},
  year = {2025},
  month = aug,
  urldate = {2025-08-17},
  abstract = {Our smartest, fastest, most useful model yet, with built-in thinking that puts expert-level intelligence in everyone's hands.},
  howpublished = {https://openai.com/index/introducing-gpt-5/},
  langid = {american}
}

@misc{IntroducingLlama31,
  title = {Introducing {{Llama}} 3.1: {{Our}} Most Capable Models to Date},
  shorttitle = {Introducing {{Llama}} 3.1},
  journal = {Meta AI},
  urldate = {2025-07-16},
  abstract = {Bringing open intelligence to all, our latest models expand context length, add support across eight languages, and include Meta Llama 3.1 405B--- the first frontier-level open source AI model.},
  howpublished = {https://ai.meta.com/blog/meta-llama-3-1/},
  langid = {english},
  file = {C:\Users\lenna\Zotero\storage\F5EQJGMM\meta-llama-3-1.html}
}

@book{jaoEfficientDecisionSupport2011,
  title = {Efficient {{Decision Support Systems}}: {{Practice}} and {{Challenges}} in {{Biomedical Related Domain}}},
  shorttitle = {Efficient {{Decision Support Systems}}},
  author = {Jao, Chiang},
  year = {2011},
  month = sep,
  publisher = {BoD -- Books on Demand},
  abstract = {This series is directed to diverse managerial professionals who are leading the transformation of individual domains by using expert information and domain knowledge to drive decision support systems (DSSs). The series offers a broad range of subjects addressed in specific areas such as health care, business management, banking, agriculture, environmental improvement, natural resource and spatial management, aviation administration, and hybrid applications of information technology aimed to interdisciplinary issues. This book series is composed of three volumes: Volume 1 consists of general concepts and methodology of DSSs; Volume 2 consists of applications of DSSs in the biomedical domain; Volume 3 consists of hybrid applications of DSSs in multidisciplinary domains. The book is shaped decision support strategies in the new infrastructure that assists the readers in full use of the creative technology to manipulate input data and to transform information into useful decisions for decision makers.},
  googlebooks = {iHSfDwAAQBAJ},
  isbn = {978-953-307-258-6},
  langid = {english},
  keywords = {Computers / Database Administration & Management,Computers / General}
}

@book{jaoEfficientDecisionSupport2011a,
  title = {Efficient {{Decision Support Systems}}: {{Practice}} and {{Challenges}} in {{Biomedical Related Domain}}},
  shorttitle = {Efficient {{Decision Support Systems}}},
  author = {Jao, Chiang},
  year = {2011},
  month = sep,
  publisher = {BoD -- Books on Demand},
  abstract = {This series is directed to diverse managerial professionals who are leading the transformation of individual domains by using expert information and domain knowledge to drive decision support systems (DSSs). The series offers a broad range of subjects addressed in specific areas such as health care, business management, banking, agriculture, environmental improvement, natural resource and spatial management, aviation administration, and hybrid applications of information technology aimed to interdisciplinary issues. This book series is composed of three volumes: Volume 1 consists of general concepts and methodology of DSSs; Volume 2 consists of applications of DSSs in the biomedical domain; Volume 3 consists of hybrid applications of DSSs in multidisciplinary domains. The book is shaped decision support strategies in the new infrastructure that assists the readers in full use of the creative technology to manipulate input data and to transform information into useful decisions for decision makers.},
  googlebooks = {iHSfDwAAQBAJ},
  isbn = {978-953-307-258-6},
  langid = {english},
  keywords = {Computers / Database Administration & Management,Computers / General}
}

@misc{jaradehBetterCallPlumber2021,
  title = {Better {{Call}} the {{Plumber}}: {{Orchestrating Dynamic Information Extraction Pipelines}}},
  shorttitle = {Better {{Call}} the {{Plumber}}},
  author = {Jaradeh, Mohamad Yaser and Singh, Kuldeep and Stocker, Markus and Both, Andreas and Auer, S{\"o}ren},
  year = {2021},
  month = feb,
  number = {arXiv:2102.10966},
  eprint = {2102.10966},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2102.10966},
  urldate = {2025-07-29},
  abstract = {We propose Plumber, the first framework that brings together the research community's disjoint information extraction (IE) efforts. The Plumber architecture comprises 33 reusable components for various Knowledge Graphs (KG) information extraction subtasks, such as coreference resolution, entity linking, and relation extraction. Using these components, Plumber dynamically generates suitable information extraction pipelines and offers overall 264 distinct pipelines. We study the optimization problem of choosing suitable pipelines based on input sentences. To do so, we train a transformer-based classification model that extracts contextual embeddings from the input and finds an appropriate pipeline. We study the efficacy of Plumber for extracting the KG triples using standard datasets over two KGs: DBpedia, and Open Research Knowledge Graph (ORKG). Our results demonstrate the effectiveness of Plumber in dynamically generating KG information extraction pipelines, outperforming all baselines agnostics of the underlying KG. Furthermore, we provide an analysis of collective failure cases, study the similarities and synergies among integrated components, and discuss their limitations.},
  archiveprefix = {arXiv},
  langid = {english},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval},
  file = {C:\Users\lenna\Zotero\storage\4ZS4W639\Jaradeh et al. - 2021 - Better Call the Plumber Orchestrating Dynamic Inf.pdf}
}

@inproceedings{jaradehBetterCallPlumber2021a,
  title = {Better {{Call}} the {{Plumber}}: {{Orchestrating Dynamic Information Extraction Pipelines}}},
  shorttitle = {Better {{Call}} the {{Plumber}}},
  booktitle = {Web {{Engineering}}},
  author = {Jaradeh, Mohamad Yaser and Singh, Kuldeep and Stocker, Markus and Both, Andreas and Auer, S{\"o}ren},
  editor = {Brambilla, Marco and Chbeir, Richard and Frasincar, Flavius and Manolescu, Ioana},
  year = {2021},
  pages = {240--254},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-74296-6_19},
  abstract = {We propose Plumber, the first framework that brings together the research community's disjoint information extraction (IE) efforts. The Plumber architecture comprises 33~reusable components for various Knowledge Graphs (KG) information extraction subtasks, such as coreference resolution, entity linking, and relation extraction. Using these components, Plumber dynamically generates suitable information extraction pipelines and offers overall 264~distinct pipelines. We study the optimization problem of choosing suitable pipelines based on input sentences. To do so, we train a transformer-based classification model that extracts contextual embeddings from the input and finds an appropriate pipeline. We study the efficacy of Plumber for extracting the KG triples using standard datasets over two KGs: DBpedia, and Open Research Knowledge Graph (ORKG). Our results demonstrate the effectiveness of Plumber in dynamically generating KG information extraction pipelines, outperforming all baselines agnostics of the underlying KG. Furthermore, we provide an analysis of collective failure cases, study the similarities and synergies among integrated components, and discuss their limitations.},
  isbn = {978-3-030-74296-6},
  langid = {english},
  keywords = {Information extraction,NLP pipelines,Semantic search,Semantic Web,Software reusability},
  file = {C:\Users\lenna\Zotero\storage\RIJK892K\Jaradeh et al. - 2021 - Better Call the Plumber Orchestrating Dynamic Inf.pdf}
}

@misc{jiangMistral7B2023,
  title = {Mistral {{7B}}},
  author = {Jiang, Albert Q. and Sablayrolles, Alexandre and Mensch, Arthur and Bamford, Chris and Chaplot, Devendra Singh and de las Casas, Diego and Bressand, Florian and Lengyel, Gianna and Lample, Guillaume and Saulnier, Lucile and Lavaud, L{\'e}lio Renard and Lachaux, Marie-Anne and Stock, Pierre and Scao, Teven Le and Lavril, Thibaut and Wang, Thomas and Lacroix, Timoth{\'e}e and Sayed, William El},
  year = {2023},
  month = oct,
  number = {arXiv:2310.06825},
  eprint = {2310.06825},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.06825},
  urldate = {2025-08-12},
  abstract = {We introduce Mistral 7B v0.1, a 7-billion-parameter language model engineered for superior performance and efficiency. Mistral 7B outperforms Llama 2 13B across all evaluated benchmarks, and Llama 1 34B in reasoning, mathematics, and code generation. Our model leverages grouped-query attention (GQA) for faster inference, coupled with sliding window attention (SWA) to effectively handle sequences of arbitrary length with a reduced inference cost. We also provide a model fine-tuned to follow instructions, Mistral 7B -- Instruct, that surpasses the Llama 2 13B -- Chat model both on human and automated benchmarks. Our models are released under the Apache 2.0 license.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning,evaluation_models},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\F6JU77BI\\Jiang et al. - 2023 - Mistral 7B.pdf;C\:\\Users\\lenna\\Zotero\\storage\\UE8VNSGX\\2310.html}
}

@article{johanssonTruthThereRule,
  title = {The {{Truth}} Is in {{There}} - {{Rule Extraction}} from {{Opaque Models Using Genetic Programming}}},
  author = {Johansson, Ulf and Konig, Rikard and Niklasson, Lars},
  abstract = {A common problem when using complicated models for prediction and classification is that the complexity of the model entails that it is hard, or impossible, to interpret. For some scenarios this might not be a limitation, since the priority is the accuracy of the model. In other situations the limitations might be severe, since additional aspects are important to consider; e.g. comprehensibility or scalability of the model. In this study we show how the gap between accuracy and other aspects can be bridged by using a rule extraction method (termed G-REX) based on genetic programming. The extraction method is evaluated against the five criteria accuracy, comprehensibility, fidelity, scalability and generality. It is also shown how G-REX can create novel representation languages; here regression trees and fuzzy rules. The problem used is a data-mining problem from the marketing domain where the impact of advertising is predicted from investment plans. Several experiments, covering both regression and classification tasks, are evaluated. Results show that G-REX in general is capable of extracting both accurate and comprehensible representations, thus allowing high performance also in domains where comprehensibility is of essence.},
  langid = {english},
  file = {C:\Users\lenna\Zotero\storage\RJMTB5VG\Johansson et al. - The Truth is in There - Rule Extraction from Opaqu.pdf}
}

@book{josephsonAbductiveInferenceComputation1996,
  title = {Abductive {{Inference}}: {{Computation}}, {{Philosophy}}, {{Technology}}},
  shorttitle = {Abductive {{Inference}}},
  author = {Josephson, John R. and Josephson, Susan G.},
  year = {1996},
  month = aug,
  publisher = {Cambridge University Press},
  abstract = {In informal terms, abductive reasoning involves inferring the best or most plausible explanation from a given set of facts or data. This volume presents new ideas about inferential and information-processing foundations for knowledge and certainty. The authors argue that knowledge arises from experience by processes of abductive inference, in contrast to the view that it arises noninferentially, or that deduction and inductive generalization are enough to account for knowledge. The book tells the story of six generations of increasingly sophisticated generic abduction machines and the discovery of reasoning strategies that make it computationally feasible to form well-justified composite explanatory hypotheses, despite the threat of combinatorial explosion. This book will be of great interest to researchers in AI, cognitive science, and philosophy of science.},
  googlebooks = {uu6zXrogwWAC},
  isbn = {978-0-521-57545-4},
  langid = {english},
  keywords = {Computers / Artificial Intelligence / General,Computers / Artificial Intelligence / Natural Language Processing,Philosophy / Epistemology,Philosophy / Logic,Psychology / Cognitive Psychology & Cognition,Science / Philosophy & Social Aspects}
}

@inproceedings{kaiserGainingProcessInformation2005,
  title = {Gaining {{Process Information}} from {{Clinical Practice Guidelines Using Information Extraction}}},
  booktitle = {Artificial {{Intelligence}} in {{Medicine}}},
  author = {Kaiser, Katharina and Akkaya, Cem and Miksch, Silvia},
  editor = {Miksch, Silvia and Hunter, Jim and Keravnou, Elpida T.},
  year = {2005},
  pages = {181--190},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/11527770_27},
  abstract = {Formalizing Clinical Practice Guidelines for subsequent computer-supported processing is a cumbersome, challenging, and time-consuming task. But currently available tools and methods do not satisfactorily support this task.},
  isbn = {978-3-540-31884-2},
  langid = {english},
  keywords = {Clinical Practice Guideline,Information Extraction,Intermediate Representation,Negative Action,Precision Score,Zwischenprasentation},
  file = {C:\Users\lenna\Zotero\storage\PZQMTZZW\Kaiser et al. - 2005 - Gaining Process Information from Clinical Practice.pdf}
}

@article{kaiserHowCanInformation2007a,
  title = {How Can Information Extraction Ease Formalizing Treatment Processes in Clinical Practice Guidelines?: {{A}} Method and Its Evaluation},
  shorttitle = {How Can Information Extraction Ease Formalizing Treatment Processes in Clinical Practice Guidelines?},
  author = {Kaiser, Katharina and Akkaya, Cem and Miksch, Silvia},
  year = {2007},
  month = feb,
  journal = {Artificial Intelligence in Medicine},
  series = {Artificial {{Intelligence}} in {{Medicine AIME}} '05},
  volume = {39},
  number = {2},
  pages = {151--163},
  issn = {0933-3657},
  doi = {10.1016/j.artmed.2006.07.011},
  urldate = {2024-12-19},
  abstract = {Objective Formalizing clinical practice guidelines (CPGs) for a subsequent computer-supported processing is a challenging, but burdensome and time-consuming task. Existing methods and tools to support this task demand detailed medical knowledge, knowledge about the formal representations, and a manual modeling. Furthermore, formalized guideline documents mostly fall far short in terms of readability and understandability for the human domain modeler. Methods and material We propose a new multi-step approach using information extraction methods to support the human modeler by both automating parts of the modeling process and making the modeling process traceable and comprehensible. This paper addresses the first steps to obtain a representation containing processes which is independent of the final guideline representation language. Results We have developed and evaluated several heuristics without the need to apply natural language understanding and implemented them in a framework to apply them to several guidelines from the medical subject of otolaryngology. Findings in the evaluation indicate that using semi-automatic, step-wise information extraction methods are a valuable instrument to formalize CPGs. Conclusion Our evaluation shows that a heuristic-based approach can achieve good results, especially for guidelines with a major portion of semi-structured text. It can be applied to guidelines irrespective to the final guideline representation format.},
  keywords = {Clinical practice guidelines,Computer-interpretable guidelines,Guideline representation,Information extraction and integration,Otolaryngology,Time-oriented information,Treatment processes},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\BZN8FK78\\Kaiser et al. - 2007 - How can information extraction ease formalizing tr.pdf;C\:\\Users\\lenna\\Zotero\\storage\\EKV7GG73\\S0933365706001126.html}
}

@article{koenigKnowledgebasedBestBreed2019,
  title = {Knowledge-Based Best of Breed Approach for Automated Detection of Clinical Events Based on {{German}} Free Text Digital Hospital Discharge Letters},
  author = {Koenig, Maximilian and Sander, Andr{\'e} and Demuth, Ilja and Diekmann, Daniel and {Steinhagen-Thiessen}, Elisabeth},
  year = {2019},
  month = nov,
  journal = {PLOS ONE},
  volume = {14},
  pages = {e0224916},
  doi = {10.1371/journal.pone.0224916},
  abstract = {Objectives The secondary use of medical data contained in electronic medical records, such as hospital discharge letters, is a valuable resource for the improvement of clinical care (e.g. in terms of medication safety) or for research purposes. However, the automated processing and analysis of medical free text still poses a huge challenge to available natural language processing (NLP) systems. The aim of this study was to implement a knowledge-based best of breed approach, combining a terminology server with integrated ontology, a NLP pipeline and a rules engine. Methods We tested the performance of this approach in a use case. The clinical event of interest was the particular drug-disease interaction ``proton-pump inhibitor [PPI] use and osteoporosis''. Cases were to be identified based on free text digital discharge letters as source of information. Automated detection was validated against a gold standard. Results Precision of recognition of osteoporosis was 94.19\%, and recall was 97.45\%. PPIs were detected with 100\% precision and 97.97\% recall. The F-score for the detection of the given drug-disease-interaction was 96,13\%. Conclusion We could show that our approach of combining a NLP pipeline, a terminology server, and a rules engine for the purpose of automated detection of clinical events such as drug-disease interactions from free text digital hospital discharge letters was effective. There is huge potential for the implementation in clinical and research contexts, as this approach enables analyses of very high numbers of medical free text documents within a short time period.},
  file = {C:\Users\lenna\Zotero\storage\5MCIHIGP\Koenig et al. - 2019 - Knowledge-based best of breed approach for automat.pdf}
}

@article{kumarTrustworthinessLLMsMedical2024,
  title = {Trustworthiness of {{LLMs}} in {{Medical Domain}}},
  author = {Kumar, Ravi R and {Vishal Pramanik} and {Utkarsh Grover}},
  year = {2024},
  publisher = {Unpublished},
  doi = {10.13140/RG.2.2.26102.31047},
  urldate = {2025-07-16},
  abstract = {Trustworthiness is a critical factor in deploying large language models (LLMs) in the medical domain, where decision-making significantly impacts patient outcomes. This study investigates the interpretability of machine learning models applied to classify patient symptoms into five distinct disease categories. We employ three popular explainability techniques---Local Interpretable Model-Agnostic Explanations (LIME), Shapley Additive Explanations (SHAP), and Integrated Gradients (IG)---to evaluate and compare the interpretability of three models: LLAMA 3.2, BERT, and logistic regression. Our findings reveal that each explainability method effectively identifies key features contributing to the classification process, with a focus on symptom-related keywords. Comparative results demonstrate the alignment of these methods in highlighting critical features, ensuring that the models base their predictions on medically relevant inputs. The study emphasizes the importance of model interpretability in fostering trust, providing insights into how the models process patient symptoms and arrive at diagnostic predictions. This analysis highlights the potential of interpretable AI tools in ensuring reliable and ethical use of LLMs in medical applications.},
  langid = {english},
  file = {C:\Users\lenna\Zotero\storage\S6R3QT9C\Kumar et al. - 2024 - Trustworthiness of LLMs in Medical Domain.pdf}
}

@incollection{kuorikoskiFactivityPluralismInferential2022,
  title = {Factivity, {{Pluralism}}, and the {{Inferential Account}} of {{Scientific Understanding}}},
  booktitle = {Scientific {{Understanding}} and {{Representation}}},
  author = {Kuorikoski, Jaakko},
  year = {2022},
  publisher = {Routledge},
  abstract = {This chapter develops an inferentialist account of the social epistemological function of the attributions of understanding, according to which the role of the concept of understanding is to be found in the social regulation of inferential practices. It is argued that such a deflationist and deeply pragmatist account is better suited for clarifying controversies concerning understanding within the sciences than more representationalist and internalist views. The inferentialist account, amended with an ontic dependency view of explanation, is then used to argue for the factivity of understanding and for moderate explanatory pluralism.},
  isbn = {978-1-00-320290-5}
}

@article{kuorikoskiSimulationSenseUnderstanding,
  title = {Simulation and the {{Sense}} of {{Understanding}}},
  author = {Kuorikoski, Jaakko},
  langid = {english},
  file = {C:\Users\lenna\Zotero\storage\HRTMIU9Q\Kuorikoski - Simulation and the Sense of Understanding.pdf}
}

@inproceedings{kuzluRiseGenerativeArtificial2023,
  title = {The {{Rise}} of {{Generative Artificial Intelligence}} in {{Healthcare}}},
  booktitle = {2023 12th {{Mediterranean Conference}} on {{Embedded Computing}} ({{MECO}})},
  author = {Kuzlu, Murat and Xiao, Zhenxin and Sarp, Salih and Catak, Ferhat Ozgur and Gurler, Necip and Guler, Ozgur},
  year = {2023},
  month = jun,
  pages = {1--4},
  issn = {2637-9511},
  doi = {10.1109/MECO58584.2023.10155107},
  urldate = {2024-08-05},
  abstract = {Generative Artificial Intelligence (GAI) is transforming various fields, including finance, education, marketing, and healthcare. Especially in healthcare, GAI has the potential to revolutionize various aspects, such as medical imaging, drug development, patient care, and treatment planning. Key stakeholders who stand to benefit from these advancements include hospitals, clinics, pharmaceutical companies, medical device manufacturers, and research institutions. However, the implementation of GAI in healthcare presents several challenges, such as ensuring data privacy and security, addressing ethical considerations, maintaining quality and accuracy, adhering to regulatory compliance, and integrating with existing systems. This paper examines the current state of GAI in healthcare, discusses its potential benefits and challenges, and highlights future directions that must be addressed to fully harness the power of GAI in improving patient outcomes and healthcare systems.},
  keywords = {AI in Healthcare,Companies,Data privacy,Ethics,Generative AI (GAI),Generative Pre-trained Transformer (GPT),Hospitals,Large Language Model (LLM),Medical devices,Medical services,Transformers},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\KRAUJ8FE\\Kuzlu et al. - 2023 - The Rise of Generative Artificial Intelligence in .pdf;C\:\\Users\\lenna\\Zotero\\storage\\MQCZTWR2\\10155107.html}
}

@book{kvanvigValueKnowledgePursuit2003,
  title = {The {{Value}} of {{Knowledge}} and the {{Pursuit}} of {{Understanding}}},
  author = {Kvanvig, Jonathan L.},
  year = {2003},
  month = aug,
  publisher = {Cambridge University Press},
  abstract = {Epistemology has for a long time focused on the concept of knowledge and tried to answer questions such as whether knowledge is possible and how much of it there is. Often missing from this inquiry, however, is a discussion on the value of knowledge. In The Value of Knowledge and the Pursuit of Understanding Jonathan Kvanvig argues that epistemology properly conceived cannot ignore the question of the value of knowledge. He also questions one of the most fundamental assumptions in epistemology, namely that knowledge is always more valuable than the value of its subparts. Taking Platos' Meno as a starting point of his discussion, Kvanvig tackles the different arguments about the value of knowledge and comes to the conclusion that knowledge is less valuable than generally assumed. Clearly written and well argued, this 2003 book will appeal to students and professionals in epistemology.},
  googlebooks = {ILTIEjvbeLoC},
  isbn = {978-1-139-44228-2},
  langid = {english},
  keywords = {Philosophy / Epistemology,Philosophy / Movements / Analytic}
}

@inproceedings{kwakClassifyFirstThen2024,
  title = {Classify {{First}}, and {{Then Extract}}: {{Prompt Chaining Technique}} for {{Information Extraction}}},
  shorttitle = {Classify {{First}}, and {{Then Extract}}},
  booktitle = {Proceedings of the {{Natural Legal Language Processing Workshop}} 2024},
  author = {Kwak, Alice and Morrison, Clayton and Bambauer, Derek and Surdeanu, Mihai},
  editor = {Aletras, Nikolaos and Chalkidis, Ilias and Barrett, Leslie and Goan{\textcommabelow t}{\u a}, C{\u a}t{\u a}lina and {Preo{\textcommabelow t}iuc-Pietro}, Daniel and Spanakis, Gerasimos},
  year = {2024},
  month = nov,
  pages = {303--317},
  publisher = {Association for Computational Linguistics},
  address = {Miami, FL, USA},
  doi = {10.18653/v1/2024.nllp-1.25},
  urldate = {2025-08-04},
  abstract = {This work presents a new task-aware prompt design and example retrieval approach for information extraction (IE) using a prompt chaining technique. Our approach divides IE tasks into two steps: (1) text classification to understand what information (e.g., entity or event types) is contained in the underlying text and (2) information extraction for the identified types. Initially, we use a large language model (LLM) in a few-shot setting to classify the contained information. The classification output is used to select the relevant prompt and retrieve the examples relevant to the input text. Finally, we ask a LLM to do the information extraction with the generated prompt. By evaluating our approach on legal IE tasks with two different LLMs, we demonstrate that the prompt chaining technique improves the LLM's overall performance in a few-shot setting when compared to the baseline in which examples from all possible classes are included in the prompt. Our approach can be used in a low-resource setting as it does not require a large amount of training data. Also, it can be easily adapted to many different IE tasks by simply adjusting the prompts. Lastly, it provides a cost benefit by reducing the number of tokens in the prompt.},
  file = {C:\Users\lenna\Zotero\storage\DIKKKZIJ\Kwak et al. - 2024 - Classify First, and Then Extract Prompt Chaining .pdf}
}

@article{landolsiInformationExtractionElectronic2023,
  title = {Information Extraction from Electronic Medical Documents: State of the Art and Future Research Directions},
  shorttitle = {Information Extraction from Electronic Medical Documents},
  author = {Landolsi, Mohamed Yassine and Hlaoua, Lobna and Ben~Romdhane, Lotfi},
  year = {2023},
  month = feb,
  journal = {Knowl Inf Syst},
  volume = {65},
  number = {2},
  pages = {463--516},
  issn = {0219-3116},
  doi = {10.1007/s10115-022-01779-1},
  urldate = {2025-03-24},
  abstract = {In the medical field, a doctor must have a comprehensive knowledge by reading and writing narrative documents, and he is responsible for every decision he takes for patients. Unfortunately, it is very tiring to read all necessary information about drugs, diseases and patients due to the large amount of documents that are increasing every day. Consequently, so many medical errors can happen and even kill people. Likewise, there is such an important field that can handle this problem, which is the information extraction. There are several important tasks in this field to extract the important and desired information from unstructured text written in natural language. The main principal tasks are named entity recognition and relation extraction since they can structure the text by extracting the relevant information. However, in order to treat the narrative text we should use natural language processing techniques to extract useful information and features. In our paper, we introduce and discuss the several techniques and solutions used in these tasks. Furthermore, we outline the challenges in information extraction from medical documents. In our knowledge, this is the most comprehensive survey in the literature with an experimental analysis and a suggestion for some uncovered directions.},
  langid = {english},
  keywords = {Electronic medical records,Information extraction,Medical named entities recognition,Medical relation extraction,Section detection},
  file = {C:\Users\lenna\Zotero\storage\I8ZHWDLT\Landolsi et al. - 2023 - Information extraction from electronic medical doc.pdf}
}

@article{liChatGPTHealthcareTaxonomy2024,
  title = {{{ChatGPT}} in Healthcare: {{A}} Taxonomy and Systematic Review},
  shorttitle = {{{ChatGPT}} in Healthcare},
  author = {Li, Jianning and Dada, Amin and Puladi, Behrus and Kleesiek, Jens and Egger, Jan},
  year = {2024},
  month = mar,
  journal = {Computer Methods and Programs in Biomedicine},
  volume = {245},
  pages = {108013},
  issn = {0169-2607},
  doi = {10.1016/j.cmpb.2024.108013},
  urldate = {2025-02-26},
  abstract = {The recent release of ChatGPT, a chat bot research project/product of natural language processing (NLP) by OpenAI, stirs up a sensation among both the general public and medical professionals, amassing a phenomenally large user base in a short time. This is a typical example of the `productization' of cutting-edge technologies, which allows the general public without a technical background to gain firsthand experience in artificial intelligence (AI), similar to the AI hype created by AlphaGo (DeepMind Technologies, UK) and self-driving cars (Google, Tesla, etc.). However, it is crucial, especially for healthcare researchers, to remain prudent amidst the hype. This work provides a systematic review of existing publications on the use of ChatGPT in healthcare, elucidating the `status quo' of ChatGPT in medical applications, for general readers, healthcare professionals as well as NLP scientists. The large biomedical literature database PubMed is used to retrieve published works on this topic using the keyword `ChatGPT'. An inclusion criterion and a taxonomy are further proposed to filter the search results and categorize the selected publications, respectively. It is found through the review that the current release of ChatGPT has achieved only moderate or `passing' performance in a variety of tests, and is unreliable for actual clinical deployment, since it is not intended for clinical applications by design. We conclude that specialized NLP models trained on (bio)medical datasets still represent the right direction to pursue for critical clinical applications.},
  keywords = {Bard,BERT,ChatGPT,Healthcare,LLaMA,LLM,NLP,OpenAI,Taxonomy,Transformer},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\75BCUJ3E\\Li et al. - 2024 - ChatGPT in healthcare A taxonomy and systematic r.pdf;C\:\\Users\\lenna\\Zotero\\storage\\6CHSXMY2\\S0169260724000087.html}
}

@misc{liLLaVAMedTrainingLarge2023,
  title = {{{LLaVA-Med}}: {{Training}} a {{Large Language-and-Vision Assistant}} for {{Biomedicine}} in {{One Day}}},
  shorttitle = {{{LLaVA-Med}}},
  author = {Li, Chunyuan and Wong, Cliff and Zhang, Sheng and Usuyama, Naoto and Liu, Haotian and Yang, Jianwei and Naumann, Tristan and Poon, Hoifung and Gao, Jianfeng},
  year = {2023},
  month = jun,
  number = {arXiv:2306.00890},
  eprint = {2306.00890},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2306.00890},
  urldate = {2025-08-12},
  abstract = {Conversational generative AI has demonstrated remarkable promise for empowering biomedical practitioners, but current investigations focus on unimodal text. Multimodal conversational AI has seen rapid progress by leveraging billions of image-text pairs from the public web, but such general-domain vision-language models still lack sophistication in understanding and conversing about biomedical images. In this paper, we propose a cost-efficient approach for training a vision-language conversational assistant that can answer open-ended research questions of biomedical images. The key idea is to leverage a large-scale, broad-coverage biomedical figure-caption dataset extracted from PubMed Central, use GPT-4 to self-instruct open-ended instruction-following data from the captions, and then fine-tune a large general-domain vision-language model using a novel curriculum learning method. Specifically, the model first learns to align biomedical vocabulary using the figure-caption pairs as is, then learns to master open-ended conversational semantics using GPT-4 generated instruction-following data, broadly mimicking how a layperson gradually acquires biomedical knowledge. This enables us to train a Large Language and Vision Assistant for BioMedicine (LLaVA-Med) in less than 15 hours (with eight A100s). LLaVA-Med exhibits excellent multimodal conversational capability and can follow open-ended instruction to assist with inquiries about a biomedical image. On three standard biomedical visual question answering datasets, LLaVA-Med outperforms previous supervised state-of-the-art on certain metrics. To facilitate biomedical multimodal research, we will release our instruction-following data and the LLaVA-Med model.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,evaluation_models},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\PD5AQKXY\\Li et al. - 2023 - LLaVA-Med Training a Large Language-and-Vision As.pdf;C\:\\Users\\lenna\\Zotero\\storage\\6D43EK6P\\2306.html}
}

@article{linExploringBiasNLP2024,
  title = {Exploring {{Bias}} in {{NLP Models}}: {{Analyzing}} the {{Impact}} of {{Training Data}} on {{Fairness}} and {{Equity}}},
  shorttitle = {Exploring {{Bias}} in {{NLP Models}}},
  author = {Lin, Weikun and Xiao, Jingxuan and Cen, Zuen},
  year = {2024},
  month = oct,
  journal = {Journal of Industrial Engineering and Applied Science},
  volume = {2},
  number = {5},
  pages = {24--28},
  issn = {3005-6071},
  doi = {10.5281/zenodo.13845132},
  urldate = {2025-06-03},
  abstract = {Natural Language Processing (NLP) technologies have revolutionized human-computer interactions, allowing machines to understand and generate human language with unparalleled precision. This advancement has created numerous applications, from virtual assistants and chatbots to sentiment analysis and automated content generation. As more models become incorporated into systems affecting people's lives--for instance hiring algorithms, judicial decision-making tools, or social media content moderation--they raise serious concerns over bias and fairness. Examining the factors contributing to bias within NLP models is of utmost importance, specifically the influence of training data on their performance. Training data selection and curation have an enormous influence on a model's ability to perform equally across diverse demographic groups; biased selection may reinforce existing stereotypes while poor representation may lead to underperformance for marginalized communities. Preprocessing techniques such as tokenization and normalization may inadvertently perpetuate biases if not applied with care. Through an in-depth literature review and case studies, this paper explores the sources of bias within NLP systems. Furthermore, various mitigation strategies for mitigating such biases to promote fairness within these applications are proposed in order to increase equity. [1] By identifying best practices for data curation, employing fairness-aware algorithms, and setting robust evaluation metrics, our aim is to develop NLP technologies that are not only effective but also just and equitable. The findings highlight the significance of responsible AI practices while encouraging developers and researchers alike to prioritize fairness as an essential aspect of NLP system design.},
  copyright = {Copyright (c) 2024 The author retains copyright and grants the journal the right of first publication.},
  langid = {english},
  keywords = {Bias in NLP Models,Fairness in AI,Human-computer Interaction,Marginalized Communities,Mitigation Strategies,Natural Language Processing (NLP),Preprocessing Techniques,Responsible AI Practices,Stereotype Reinforcement,Training Data Selection},
  file = {C:\Users\lenna\Zotero\storage\NZNM8YF9\Lin et al. - 2024 - Exploring Bias in NLP Models Analyzing the Impact.pdf}
}

@incollection{liptonInferenceBestExplanation2017,
  title = {Inference to the {{Best Explanation}}},
  booktitle = {A {{Companion}} to the {{Philosophy}} of {{Science}}},
  author = {Lipton, Peter},
  year = {2017},
  pages = {184--193},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9781405164481.ch29},
  urldate = {2024-06-30},
  abstract = {Science depends on judgments of the bearing of evidence on theory. Scientists must judge whether an observation or the result of an experiment supports, disconfirms, or is simply irrelevant to a given hypothesis. Similarly, scientists may judge that, given all the available evidence, a hypothesis ought to be accepted as correct or nearly so, rejected as false, or neither. Occasionally, these evidential judgments can be make on deductive grounds. If an experimental result strictly contradicts a hypothesis, then the truth of the evidence deductively entails the falsity of the hypothesis. In the great majority of cases, however, the connection between evidence and hypothesis is nondemonstrative or inductive. In particular, this is so whenever a general hypothesis is inferred to be correct on the basis of the available data, since the truth of the data will not deductively entail the truth of the hypothesis. It always remains possible that the hypothesis is false even though the data are correct.},
  chapter = {29},
  isbn = {978-1-4051-6448-1},
  langid = {english},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\F8UXV55X\\Lipton - 2017 - Inference to the Best Explanation.pdf;C\:\\Users\\lenna\\Zotero\\storage\\XC66ERN4\\9781405164481.html}
}

@article{liRTRetrievingChainofThought2024,
  title = {{{RT}}: A {{Retrieving}} and {{Chain-of-Thought}} Framework for Few-Shot Medical Named Entity Recognition},
  shorttitle = {{{RT}}},
  author = {Li, Mingchen and Zhou, Huixue and Yang, Han and Zhang, Rui},
  year = {2024},
  month = sep,
  journal = {Journal of the American Medical Informatics Association},
  volume = {31},
  number = {9},
  pages = {1929--1938},
  issn = {1527-974X},
  doi = {10.1093/jamia/ocae095},
  urldate = {2025-01-16},
  abstract = {This article aims to enhance the performance of larger language models (LLMs) on the few-shot biomedical named entity recognition (NER) task by developing a simple and effective method called Retrieving and Chain-of-Thought (RT) framework and to evaluate the improvement after applying RT framework.Given the remarkable advancements in retrieval-based language model and Chain-of-Thought across various natural language processing tasks, we propose a pioneering RT framework designed to amalgamate both approaches. The RT approach encompasses dedicated modules for information retrieval and Chain-of-Thought processes. In the retrieval module, RT discerns pertinent examples from demonstrations during instructional tuning for each input sentence. Subsequently, the Chain-of-Thought module employs a systematic reasoning process to identify entities. We conducted a comprehensive comparative analysis of our RT framework against 16 other models for few-shot NER tasks on BC5CDR and NCBI corpora. Additionally, we explored the impacts of negative samples, output formats, and missing data on performance.Our proposed RT framework outperforms other LMs for few-shot NER tasks with micro-F1 scores of 93.50 and 91.76 on BC5CDR and NCBI corpora, respectively. We found that using both positive and negative samples, Chain-of-Thought (vs Tree-of-Thought) performed better. Additionally, utilization of a partially annotated dataset has a marginal effect of the model performance.This is the first investigation to combine a retrieval-based LLM and Chain-of-Thought methodology to enhance the performance in biomedical few-shot NER. The retrieval-based LLM aids in retrieving the most relevant examples of the input sentence, offering crucial knowledge to predict the entity in the sentence. We also conducted a meticulous examination of our methodology, incorporating an ablation study.The RT framework with LLM has demonstrated state-of-the-art performance on few-shot NER tasks.},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\ACUWV9LY\\Li et al. - 2024 - RT a Retrieving and Chain-of-Thought framework fo.pdf;C\:\\Users\\lenna\\Zotero\\storage\\9LAUG9VH\\7665312.html}
}

@misc{liuHumanlevelInformationExtraction2025,
  title = {Human-Level Information Extraction from Clinical Reports with Fine-Tuned Language Models},
  author = {Liu, Longchao and Lian, Long and Hao, Yiyan and Pace, Aidan and Kim, Elaine and Homsi, Nour and Pershad, Yash and Lai, Liheng and Gracie, Thomas and Kishtagari, Ashwin and Carroll, Peter R. and Bick, Alexander G. and Odisho, Anobel Y. and Chung, Maggie and Yala, Adam},
  year = {2025},
  month = apr,
  pages = {2024.11.18.24317466},
  publisher = {medRxiv},
  doi = {10.1101/2024.11.18.24317466},
  urldate = {2025-05-06},
  abstract = {Extracting structured data from clinical notes remains a key bottleneck in clinical research. We hypothesized that with minimal computational and annotation resources, open-source large language models (LLMs) could create high-quality research databases. We developed Strata, a low-code library for leveraging LLMs for data extraction from clinical reports. Trained researchers labeled four datasets from prostate MRI, breast pathology, kidney pathology, and bone marrow (MDS) pathology reports. Using Strata, we evaluated open-source LLMs, including instruction-tuned, medicine-specific, reasoning-based, and LoRA-finetuned LLMs. We compared these models to zero-shot GPT-4 and a second human annotator. Our primary evaluation metric was exact match accuracy, which assesses if all variables for a report were extracted correctly. LoRa-finetuned Llama-3.1 8B achieved non-inferior performance to the second human annotator across all four datasets, with an average exact match accuracy of 90.0 {\textpm} 1.7. Fine-tuned Llama-3.1 outperformed all other open-source models, including DeepSeekR1-Distill-Llama and Llama-3-8B-UltraMedical, which obtained average exact match accuracies of 56.8 {\textpm} 29.0 and 39.1 {\textpm} 24.4 respectively. GPT-4 was non-inferior to the second human annotator in all datasets except kidney pathology. Small, open-source LLMs offer an accessible solution for the curation of local research databases; they obtain human-level accuracy while only leveraging desktop-grade hardware and {$\leq$} 100 training reports. Unlike commercial LLMs, these tools can be locally hosted and version-controlled. Strata enables automated human-level performance in extracting structured data from clinical notes using {$\leq$} 100 training reports and a single desktop-grade GPU. Extracting structured data from clinical notes remains a key bottleneck in clinical research. We hypothesized that with minimal computational and annotation resources, open-source large language models (LLMs) could create high-quality research databases. We developed Strata, a low-code library for leveraging LLMs for data extraction from clinical reports. Trained researchers labeled four datasets from prostate MRI, breast pathology, kidney pathology, and bone marrow (MDS) pathology reports. Using Strata, we evaluated open-source LLMs, including instruction-tuned, medicine-specific, reasoning-based, and LoRA-finetuned LLMs. We compared these models to zero-shot GPT-4 and a second human annotator. Our primary evaluation metric was exact match accuracy, which assesses if all variables for a report were extracted correctly. LoRa-finetuned Llama-3.1 8B achieved non-inferior performance to the second human annotator across all four datasets, with an average exact match accuracy of 90.0 {\textpm} 1.7. Fine-tuned Llama-3.1 outperformed all other open-source models, including DeepSeekR1-Distill-Llama and Llama-3-8B-UltraMedical, which obtained average exact match accuracies of 56.8 {\textpm} 29.0 and 39.1 {\textpm} 24.4 respectively. GPT-4 was non-inferior to the second human annotator in all datasets except kidney pathology. Small, open-source LLMs offer an accessible solution for the curation of local research databases; they obtain human-level accuracy while only leveraging desktop-grade hardware and {$\leq$} 100 training reports. Unlike commercial LLMs, these tools can be locally hosted and version-controlled. Strata enables automated human-level performance in extracting structured data from clinical notes using {$\leq$} 100 training reports and a single desktop-grade GPU.},
  archiveprefix = {medRxiv},
  copyright = {{\copyright} 2025, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
  langid = {english},
  file = {C:\Users\lenna\Zotero\storage\A8HWZ4LA\Liu et al. - 2025 - Human-level information extraction from clinical r.pdf}
}

@misc{liuPerformanceAdvancedLarge2024,
  title = {Performance of {{Advanced Large Language Models}} ({{GPT-4o}}, {{GPT-4}}, {{Gemini}} 1.5 {{Pro}}, {{Claude}} 3 {{Opus}}) on {{Japanese Medical Licensing Examination}}: {{A Comparative Study}}},
  shorttitle = {Performance of {{Advanced Large Language Models}} ({{GPT-4o}}, {{GPT-4}}, {{Gemini}} 1.5 {{Pro}}, {{Claude}} 3 {{Opus}}) on {{Japanese Medical Licensing Examination}}},
  author = {Liu, Mingxin and Okuhara, Tsuyoshi and Dai, Zhehao and Huang, Wenbo and Okada, Hiroko and Furukawa, Emi and Kiuchi, Takahiro},
  year = {2024},
  month = jul,
  pages = {2024.07.09.24310129},
  publisher = {medRxiv},
  doi = {10.1101/2024.07.09.24310129},
  urldate = {2025-08-19},
  abstract = {Purpose This study aims to evaluate the accuracy of medical knowledge in the most advanced LLMs (GPT-4o, GPT-4, Gemini 1.5 Pro, and Claude 3 Opus) as of 2024. It is the first to evaluate these LLMs using a non-English medical licensing exam. The insights from this study will guide educators, policymakers, and technical experts in the effective use of AI in medical education and clinical diagnosis. Method Authors inputted 790 questions from Japanese National Medical Examination into the chat windows of the LLMs to obtain responses. Two authors independently assessed the correctness. Authors analyzed the overall accuracy rates of the LLMs and compared their performance on image and non-image questions, questions of varying difficulty levels, general and clinical questions, and questions from different medical specialties. Additionally, authors examined the correlation between the number of publications and LLMs' performance in different medical specialties. Results GPT-4o achieved highest accuracy rate of 89.2\% and outperformed the other LLMs in overall performance and each specific category. All four LLMs performed better on non-image questions than image questions, with a 10\% accuracy gap. They also performed better on easy questions compared to normal and difficult ones. GPT-4o achieved a 95.0\% accuracy rate on easy questions, marking it as an effective knowledge source for medical education. Four LLMs performed worst on ``Gastroenterology and Hepatology'' specialty. There was a positive correlation between the number of publications and LLM performance in different specialties. Conclusions GPT-4o achieved an overall accuracy rate close to 90\%, with 95.0\% on easy questions, significantly outperforming the other LLMs. This indicates GPT-4o's potential as a knowledge source for easy questions. Image-based questions and question difficulty significantly impact LLM accuracy. ``Gastroenterology and Hepatology'' is the specialty with the lowest performance. The LLMs' performance across medical specialties correlates positively with the number of related publications.},
  archiveprefix = {medRxiv},
  copyright = {{\copyright} 2024, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at http://creativecommons.org/licenses/by-nd/4.0/},
  langid = {english},
  file = {C:\Users\lenna\Zotero\storage\LRU4J4E9\Liu et al. - 2024 - Performance of Advanced Large Language Models (GPT.pdf}
}

@misc{Llama31,
  title = {Llama3.1},
  urldate = {2025-08-12},
  abstract = {Llama 3.1 is a new state-of-the-art model from Meta available in 8B, 70B and 405B parameter sizes.},
  howpublished = {https://ollama.com/library/llama3.1},
  keywords = {evaluation_models},
  file = {C:\Users\lenna\Zotero\storage\TNPBG9YL\llama3.html}
}

@inproceedings{loglisciKnowledgeBasedFrameworkInformation2009,
  title = {A {{Knowledge-Based Framework}} for {{Information Extraction}} from {{Clinical Practice Guidelines}}},
  booktitle = {Foundations of {{Intelligent Systems}}},
  author = {Loglisci, Corrado and Ceci, Michelangelo and Malerba, Donato},
  editor = {Rauch, Jan and Ra{\'s}, Zbigniew W. and Berka, Petr and Elomaa, Tapio},
  year = {2009},
  pages = {119--128},
  publisher = {Springer},
  address = {Berlin, Heidelberg},
  doi = {10.1007/978-3-642-04125-9_15},
  abstract = {Clinical Practice Guidelines guide decision making in decision problems such as the diagnosis, prevention, etc. for specific clinical circumstances. They are usually available in the form of textual documents written in natural language whose interpretation, however, can make difficult their implementation. Additionally, the high number of available documents and the presence of information for different decision problems in the same document can further hinder their use. In this paper, we propose a framework to extract practices and indications considered to be important in a particular clinical circumstance for a specific decision problem from textual clinical guidelines. The framework operates in two consecutive phases: the first one aims at extracting pieces of information relevant for each decision problem from the documents, while the second one exploits pieces of information in order to generate a structured representation of the clinical practice guidelines for each decision problem. The application to the context of Metabolic Syndrome proves the effectiveness of the proposed framework.},
  isbn = {978-3-642-04125-9},
  langid = {english},
  keywords = {Clinical Practices Guidelines,Information Extraction,Medical Decision Making,Zwischenprasentation},
  file = {C:\Users\lenna\Zotero\storage\K6QRLPWL\Loglisci et al. - 2009 - A Knowledge-Based Framework for Information Extrac.pdf}
}

@article{lombrozoStructureFunctionExplanations2006,
  title = {The Structure and Function of Explanations},
  author = {Lombrozo, Tania},
  year = {2006},
  month = oct,
  journal = {Trends in Cognitive Sciences},
  volume = {10},
  number = {10},
  pages = {464--470},
  publisher = {Elsevier},
  issn = {1364-6613, 1879-307X},
  doi = {10.1016/j.tics.2006.08.004},
  urldate = {2024-06-30},
  langid = {english},
  pmid = {16942895}
}

@inproceedings{longoExplainableArtificialIntelligence2020,
  title = {Explainable {{Artificial Intelligence}}: {{Concepts}}, {{Applications}}, {{Research Challenges}} and {{Visions}}},
  shorttitle = {Explainable {{Artificial Intelligence}}},
  booktitle = {Machine {{Learning}} and {{Knowledge Extraction}}},
  author = {Longo, Luca and Goebel, Randy and Lecue, Freddy and Kieseberg, Peter and Holzinger, Andreas},
  editor = {Holzinger, Andreas and Kieseberg, Peter and Tjoa, A Min and Weippl, Edgar},
  year = {2020},
  pages = {1--16},
  publisher = {Springer International Publishing},
  address = {Cham},
  doi = {10.1007/978-3-030-57321-8_1},
  abstract = {The development of theory, frameworks and tools for Explainable AI (XAI) is a very active area of research these days, and articulating any kind of coherence on a vision and challenges is itself a challenge. At least two sometimes complementary and colliding threads have emerged. The first focuses on the development of pragmatic tools for increasing the transparency of automatically learned prediction models, as for instance by deep or reinforcement learning. The second is aimed at anticipating the negative impact of opaque models with the desire to regulate or control impactful consequences of incorrect predictions, especially in sensitive areas like medicine and law. The formulation of methods to augment the construction of predictive models with domain knowledge can provide support for producing human understandable explanations for predictions. This runs in parallel with AI regulatory concerns, like the European Union General Data Protection Regulation, which sets standards for the production of explanations from automated or semi-automated decision making. Despite the fact that all this research activity is the growing acknowledgement that the topic of explainability is essential, it is important to recall that it is also among the oldest fields of computer science. In fact, early AI was re-traceable, interpretable, thus understandable by and explainable to humans. The goal of this research is to articulate the big picture ideas and their role in advancing the development of XAI systems, to acknowledge their historical roots, and to emphasise the biggest challenges to moving forward.},
  isbn = {978-3-030-57321-8},
  langid = {english},
  keywords = {Explainability,Explainable artificial intelligence,Machine learning},
  file = {C:\Users\lenna\Zotero\storage\LE4A94IW\Longo et al. - 2020 - Explainable Artificial Intelligence Concepts, App.pdf}
}

@article{longoExplainableArtificialIntelligence2024,
  title = {Explainable {{Artificial Intelligence}} ({{XAI}}) 2.0: {{A}} Manifesto of Open Challenges and Interdisciplinary Research Directions},
  shorttitle = {Explainable {{Artificial Intelligence}} ({{XAI}}) 2.0},
  author = {Longo, Luca and Brcic, Mario and Cabitza, Federico and Choi, Jaesik and Confalonieri, Roberto and Ser, Javier Del and Guidotti, Riccardo and Hayashi, Yoichi and Herrera, Francisco and Holzinger, Andreas and Jiang, Richard and Khosravi, Hassan and Lecue, Freddy and Malgieri, Gianclaudio and P{\'a}ez, Andr{\'e}s and Samek, Wojciech and Schneider, Johannes and Speith, Timo and Stumpf, Simone},
  year = {2024},
  month = jun,
  journal = {Information Fusion},
  volume = {106},
  pages = {102301},
  issn = {1566-2535},
  doi = {10.1016/j.inffus.2024.102301},
  urldate = {2024-06-29},
  abstract = {Understanding black box models has become paramount as systems based on opaque Artificial Intelligence (AI) continue to flourish in diverse real-world applications. In response, Explainable AI (XAI) has emerged as a field of research with practical and ethical benefits across various domains. This paper highlights the advancements in XAI and its application in real-world scenarios and addresses the ongoing challenges within XAI, emphasizing the need for broader perspectives and collaborative efforts. We bring together experts from diverse fields to identify open problems, striving to synchronize research agendas and accelerate XAI in practical applications. By fostering collaborative discussion and interdisciplinary cooperation, we aim to propel XAI forward, contributing to its continued success. We aim to develop a comprehensive proposal for advancing XAI. To achieve this goal, we present a manifesto of 28 open problems categorized into nine categories. These challenges encapsulate the complexities and nuances of XAI and offer a road map for future research. For each problem, we provide promising research directions in the hope of harnessing the collective intelligence of interested stakeholders.},
  keywords = {Actionable XAI,Causality,Concept-based explanations,Ethical AI,Explainable artificial intelligence,Falsifiability,Generative AI,Interdisciplinarity,Interpretability,Large language models,Manifesto,Multi-faceted explanations,Open challenges,Responsible AI,Trustworthy AI,XAI},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\6VHLV5PC\\Longo et al. - 2024 - Explainable Artificial Intelligence (XAI) 2.0 A m.pdf;C\:\\Users\\lenna\\Zotero\\storage\\9HD5NPVT\\S1566253524000794.html}
}

@inproceedings{lundbergUnifiedApproachInterpreting2017,
  title = {A {{Unified Approach}} to {{Interpreting Model Predictions}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {Lundberg, Scott M and Lee, Su-In},
  year = {2017},
  volume = {30},
  publisher = {Curran Associates, Inc.},
  urldate = {2024-06-30},
  abstract = {Understanding why a model makes a certain prediction can be as crucial as the prediction's accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, SHAP (SHapley Additive exPlanations). SHAP assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.},
  file = {C:\Users\lenna\Zotero\storage\X2LXBKJT\Lundberg und Lee - 2017 - A Unified Approach to Interpreting Model Predictio.pdf}
}

@misc{maDICEDataEfficientClinical2023,
  title = {{{DICE}}: {{Data-Efficient Clinical Event Extraction}} with {{Generative Models}}},
  shorttitle = {{{DICE}}},
  author = {Ma, Mingyu Derek and Taylor, Alexander K. and Wang, Wei and Peng, Nanyun},
  year = {2023},
  month = may,
  number = {arXiv:2208.07989},
  eprint = {2208.07989},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2208.07989},
  urldate = {2025-01-16},
  abstract = {Event extraction for the clinical domain is an under-explored research area. The lack of training data along with the high volume of domain-specific terminologies with vague entity boundaries makes the task especially challenging. In this paper, we introduce DICE, a robust and data-efficient generative model for clinical event extraction. DICE frames event extraction as a conditional generation problem and introduces a contrastive learning objective to accurately decide the boundaries of biomedical mentions. DICE also trains an auxiliary mention identification task jointly with event extraction tasks to better identify entity mention boundaries, and further introduces special markers to incorporate identified entity mentions as trigger and argument candidates for their respective tasks. To benchmark clinical event extraction, we compose MACCROBAT-EE, the first clinical event extraction dataset with argument annotation, based on an existing clinical information extraction dataset MACCROBAT. Our experiments demonstrate state-of-the-art performances of DICE for clinical and news domain event extraction, especially under low data settings.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\QYRNIQXM\\Ma et al. - 2023 - DICE Data-Efficient Clinical Event Extraction wit.pdf;C\:\\Users\\lenna\\Zotero\\storage\\C8QLTZTB\\2208.html}
}

@book{malleHowMindExplains2006,
  title = {How the {{Mind Explains Behavior}}: {{Folk Explanations}}, {{Meaning}}, and {{Social Interaction}}},
  shorttitle = {How the {{Mind Explains Behavior}}},
  author = {Malle, Bertram F.},
  year = {2006},
  month = aug,
  publisher = {MIT Press},
  abstract = {In this provocative monograph, Bertram Malle describes behavior explanations as having a dual nature---as being both cognitive and social acts---and proposes a comprehensive theoretical model that integrates the two aspects. When people try to understand puzzling human behavior, they construct behavior explanations, which are a fundamental tool of social cognition. But, Malle argues, behavior explanations exist not only in the mind; they are also overt verbal actions used for social purposes. When people explain their own behavior or the behavior of others, they are using the explanation to manage a social interaction---by offering clarification, trying to save face, or casting blame. Malle's account makes clear why these two aspects of behavior explanation exist and why they are closely linked; along the way, he illustrates the astonishingly sophisticated and subtle patterns of folk behavior explanations.Malle begins by reviewing traditional attribution theories and their simplified portrayal of behavior explanation. A more realistic portrayal, he argues, must be grounded in the nature, function, and origins of the folk theory of mind---the conceptual framework underlying people's grasp of human behavior and its connection to the mind. Malle then presents a theory of behavior explanations, focusing first on their conceptual structure and then on their psychological construction. He applies this folk-conceptual theory to a number of questions, including the communicative functions of behavior explanations, and the differences in explanations given for self and others as well as for individuals and groups. Finally, he highlights the strengths of the folk-conceptual theory of explanation over traditional attribution theory and points to future research applications.},
  isbn = {978-0-262-25035-1},
  langid = {english},
  keywords = {Psychology / Cognitive Psychology & Cognition}
}

@article{mcevoy2024ESCGuidelines2024,
  title = {2024 {{ESC Guidelines}} for the Management of Elevated Blood Pressure and Hypertension},
  author = {McEvoy, John William and McCarthy, Cian P and Bruno, Rosa Maria and Brouwers, Sofie and Canavan, Michelle D and Ceconi, Claudio and Christodorescu, Ruxandra Maria and Daskalopoulou, Stella S and Ferro, Charles J and Gerdts, Eva and Hanssen, Henner and Harris, Julie and Lauder, Lucas and McManus, Richard J and Molloy, Gerard J and Rahimi, Kazem and {Regitz-Zagrosek}, Vera and Rossi, Gian Paolo and Sandset, Else Charlotte and Scheenaerts, Bart and Staessen, Jan A and Uchmanowicz, Izabella and Volterrani, Maurizio and Touyz, Rhian M and {ESC Scientific Document Group} and Abreu, Ana and Olsen, Michael Hecht and Ambrosetti, Marco and Androulakis, Emmanuel and Bang, Lia Evi and Bech, Jesper N{\o}rgaard and Borger, Michael A and Boutouyrie, Pierre and Bronze, Lu{\'i}s and Buccheri, Sergio and Dalmau, Regina and De Pablo Zarzosa, Maria Carmen and Delles, Christian and Fiuza, Maria Manuela and Gabulova, Rahima and Haugen, Bj{\o}rn Olav and Heiss, Christian and Ibanez, Borja and James, Stefan and Kapil, Vikas and Kayik{\c c}ioglu, Meral and K{\o}ber, Lars and Koskinas, Konstantinos C and Locati, Emanuela Teresa and MacDonald, Sharon and Mihailidou, Anastasia S and Mihaylova, Borislava and Mindham, Richard and Mortensen, Martin Bodtker and Nardai, Sandor and Neubeck, Lis and Nielsen, Jens Cosedis and Nilsson, Peter M and Pasquet, Agnes A and Pedro, M{\'o}nica Mendes and Prescott, Eva and Rakisheva, Amina and Rietzschel, Ernst and Rocca, Bianca and Rossello, Xavier and Schmid, Jean-Paul and Shantsila, Eduard and Sudano, Isabella and Tim{\'o}teo, Ana Teresa and Tsivgoulis, Georgios and Ungar, Andrea and Vaartjes, Ilonca and Visseren, Frank and Voeller, Heinz and Vrints, Christiaan and Witkowski, Adam and Zennaro, Maria-Christina and Zeppenfeld, Katja and Shuka, Naltin and Laredj, Nadia and Pavo, Noemi and Mirzoyev, Ulvi and Van De Borne, Philippe and Sokolovi{\'c}, {\v S}ekib and Postadzhiyan, Arman and Samardzic, Jure and Agathangelou, Petros and Widimsky, Jiri and Olsen, Michael Hecht and {El-Kilany}, Wael M and Pauklin, Priit and Laukkanen, Jari A and Boulestreau, Romain and Tsinamdzgvrishvili, Bezhan and Kintscher, Ulrich and Marketou, Maria and P{\'a}ll, D{\'e}nes and Hrafnkelsd{\'o}ttir, {\TH}{\'o}rd{\'i}s J{\'o}na and Dolan, Eamon and Wolak, Talya and Bilo, Grzegorz and Tundybayeva, Meiramgul Kapsimetovna and Mirrakhimov, Erkin and Trusinskis, Karlis and Kiwan, Ghassan and Msalem, Omar and Badarien{\.e}, Jolita and Banu, Cristiana-Astra and Balbi, Matthew Mercieca and Caraus, Alexandru and Boskovic, Aneta and Mouine, Najat and Vromen, Tom and Bosevski, Marijan and Midtb{\o}, Helga B and Doroszko, Adrian and Dores, H{\'e}lder and Badila, Elisabeta and Bini, Roberto and Simi{\'c}, Dragan Vojislav and Fras, Zlatko and Maz{\'o}n, Pilar and Spaak, Jonas and Burkard, Thilo and Barakat, Elias and Abdessalem, Salem and Gunes, Yilmaz and Sirenko, Yurij M and Brady, Adrian J B and Khamidullaeva, Gulnoz Abdusattarovna},
  year = {2024},
  month = oct,
  journal = {European Heart Journal},
  volume = {45},
  number = {38},
  pages = {3912--4018},
  publisher = {Oxford University Press (OUP)},
  issn = {0195-668X, 1522-9645},
  doi = {10.1093/eurheartj/ehae178},
  urldate = {2025-08-01},
  copyright = {https://academic.oup.com/pages/standard-publication-reuse-rights},
  langid = {english},
  file = {C:\Users\lenna\Zotero\storage\3RA9LZHG\McEvoy et al. - 2024 - 2024 ESC Guidelines for the management of elevated.pdf}
}

@inproceedings{meoniLargeLanguageModels2023,
  title = {Large {{Language Models}} as {{Instructors}}: {{A Study}} on {{Multilingual Clinical Entity Extraction}}},
  shorttitle = {Large {{Language Models}} as {{Instructors}}},
  booktitle = {The 22nd {{Workshop}} on {{Biomedical Natural Language Processing}} and {{BioNLP Shared Tasks}}},
  author = {Meoni, Simon and Ryffel, Theo and {Villemonte de La Clergerie}, Eric},
  year = {2023},
  month = jul,
  pages = {178--190},
  publisher = {Association for Computational Linguistics},
  address = {Toronto, Canada},
  doi = {10.18653/v1/2023.bionlp-1.15},
  urldate = {2025-01-16},
  abstract = {In clinical and other specialized domains, data are scarce due to their confidential nature. This lack of data is a major problem when finetuning language models. Nevertheless, very large language models (LLMs) are promising for the medical domain but cannot be used directly in healthcare facilities due to data confidentiality issues. We explore an approach of annotating training data with LLMs to train smaller models more adapted to our problem. We show that this method yields promising results for information extraction tasks.},
  file = {C:\Users\lenna\Zotero\storage\T58XXAAL\Meoni et al. - 2023 - Large Language Models as Instructors A Study on M.pdf}
}

@misc{MetallamaMetaLlama38BInstructHugging2024,
  title = {Meta-Llama/{{Meta-Llama-3-8B-Instruct}} {$\cdot$} {{Hugging Face}}},
  year = {2024},
  month = dec,
  urldate = {2025-06-02},
  abstract = {We're on a journey to advance and democratize artificial intelligence through open source and open science.},
  howpublished = {https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct},
  file = {C:\Users\lenna\Zotero\storage\PEERCJBH\Meta-Llama-3-8B-Instruct.html}
}

@article{millsEffectHighCorrelated2007,
  title = {The Effect of High Correlated Colour Temperature Office Lighting on Employee Wellbeing and Work Performance},
  author = {Mills, Peter R and Tomkins, Susannah C and Schlangen, Luc Jm},
  year = {2007},
  month = jan,
  journal = {J Circadian Rhythms},
  volume = {5},
  number = {0},
  pages = {2},
  issn = {1740-3391},
  doi = {10.1186/1740-3391-5-2},
  urldate = {2024-04-30},
  copyright = {http://creativecommons.org/licenses/by/4.0},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\JJG5Z427\\Mills et al. - 2007 - The effect of high correlated colour temperature o.pdf;C\:\\Users\\lenna\\Zotero\\storage\\8Q8CBUIR\\1740-3391-5-2.html}
}

@misc{Mistral,
  title = {Mistral},
  urldate = {2025-08-12},
  abstract = {The 7B model released by Mistral AI, updated to version 0.3.},
  howpublished = {https://ollama.com/library/mistral},
  keywords = {evaluation_models},
  file = {C:\Users\lenna\Zotero\storage\2SM8X44E\mistral.html}
}

@article{montavonMethodsInterpretingUnderstanding2018,
  title = {Methods for Interpreting and Understanding Deep Neural Networks},
  author = {Montavon, Gr{\'e}goire and Samek, Wojciech and M{\"u}ller, Klaus-Robert},
  year = {2018},
  month = feb,
  journal = {Digital Signal Processing},
  volume = {73},
  pages = {1--15},
  issn = {1051-2004},
  doi = {10.1016/j.dsp.2017.10.011},
  urldate = {2024-08-05},
  abstract = {This paper provides an entry point to the problem of interpreting a deep neural network model and explaining its predictions. It is based on a tutorial given at ICASSP 2017. As a tutorial paper, the set of methods covered here is not exhaustive, but sufficiently representative to discuss a number of questions in interpretability, technical challenges, and possible applications. The second part of the tutorial focuses on the recently proposed layer-wise relevance propagation (LRP) technique, for which we provide theory, recommendations, and tricks, to make most efficient use of it on real data.},
  keywords = {Activation maximization,Deep neural networks,Layer-wise relevance propagation,Sensitivity analysis,Taylor decomposition},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\9S2HNA7W\\Montavon et al. - 2018 - Methods for interpreting and understanding deep ne.pdf;C\:\\Users\\lenna\\Zotero\\storage\\6UU7KIQK\\S1051200417302385.html}
}

@article{moralesImpromptuFrameworkModeldriven2025,
  title = {Impromptu: A Framework for Model-Driven Prompt Engineering},
  shorttitle = {Impromptu},
  author = {Morales, Sergio and Claris{\'o}, Robert and Cabot, Jordi},
  year = {2025},
  month = jan,
  journal = {Softw Syst Model},
  issn = {1619-1374},
  doi = {10.1007/s10270-024-01235-4},
  urldate = {2025-05-06},
  abstract = {Generative artificial intelligence (AI) systems are capable of synthesizing complex artifacts such as text, source code or images according to the instructions provided in a natural language prompt. The quality of the input prompt, in terms of both content and structure, has a large impact on the quality of the output. This has given rise to prompt engineering, the process of designing natural language prompts to best take advantage of the capabilities of generative AI systems. This paper describes Impromptu, a model-driven engineering framework to support the creation, management and reuse of prompts for generative AI. Impromptu~offers a domain-specific language (DSL) to define multimodal prompts in a modular and tool-independent way. The language offers additional features such as versioning, prompt chaining and multi-language support. Moreover, it provides tool support to adapt prompts for specific generative AI systems, execute those prompts on a generative AI system and validate the quality of the response that is generated. Impromptu~is available as a Langium-based Visual Studio Code plugin.},
  langid = {english},
  keywords = {Domain-specific language,Generative AI,Large language models,Model-driven engineering,Prompt engineering},
  file = {C:\Users\lenna\Zotero\storage\7HUU7TRQ\Morales et al. - 2025 - Impromptu a framework for model-driven prompt eng.pdf}
}

@article{mudgalRealworldApplicationChallenges2022,
  title = {Real-World Application, Challenges and Implication of Artificial Intelligence in Healthcare: An Essay},
  shorttitle = {Real-World Application, Challenges and Implication of Artificial Intelligence in Healthcare},
  author = {Mudgal, Shiv Kumar and Agarwal, Rajat and Chaturvedi, Jitender and Gaur, Rakhi and Ranjan, Nishit},
  year = {2022},
  month = sep,
  journal = {Pan Afr Med J},
  volume = {43},
  pages = {3},
  issn = {1937-8688},
  doi = {10.11604/pamj.2022.43.3.33384},
  urldate = {2025-02-26},
  abstract = {This essay examines the state of Artificial Intelligence (AI) based technology applications in healthcare and the impact they have on the industry. This study comprised a detailed review of the literature and analyzed real-world examples of AI applications in healthcare. The findings show that major hospitals use AI-based technology to enhance knowledge and skills of their healthcare professionals for patient diagnosis and treatment. AI systems have also been shown to improve the efficiency and management of hospitals{\textasciiacute} nursing and managerial functions. Healthcare providers are positively accepting AI in multiple arenas. However, its applications offer both the utopian (new opportunities) as well as the dystopian (challenges). Unlike pessimists, AI should not be seen a potential source of ``Digital Dictatorship'' in future of 22nd century. To provide a balanced view on the potential and challenges of AI in healthcare, we discuss these details. It is evident that AI and related technologies are rapidly evolving and will allow care providers to create new value for patients and improve their operational efficiency. Effective AI applications will require planning and strategies that transform both the care service and the operations in order to reap the benefits.},
  pmcid = {PMC9557803},
  pmid = {36284890},
  file = {C:\Users\lenna\Zotero\storage\F3WT8Y6U\Mudgal et al. - 2022 - Real-world application, challenges and implication.pdf}
}

@misc{munnangiOntheflyDefinitionAugmentation2024,
  title = {On-the-Fly {{Definition Augmentation}} of {{LLMs}} for {{Biomedical NER}}},
  author = {Munnangi, Monica and Feldman, Sergey and Wallace, Byron C. and Amir, Silvio and Hope, Tom and Naik, Aakanksha},
  year = {2024},
  month = apr,
  number = {arXiv:2404.00152},
  eprint = {2404.00152},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2404.00152},
  urldate = {2025-01-16},
  abstract = {Despite their general capabilities, LLMs still struggle on biomedical NER tasks, which are difficult due to the presence of specialized terminology and lack of training data. In this work we set out to improve LLM performance on biomedical NER in limited data settings via a new knowledge augmentation approach which incorporates definitions of relevant concepts on-the-fly. During this process, to provide a test bed for knowledge augmentation, we perform a comprehensive exploration of prompting strategies. Our experiments show that definition augmentation is useful for both open source and closed LLMs. For example, it leads to a relative improvement of 15{\textbackslash}\% (on average) in GPT-4 performance (F1) across all (six) of our test datasets. We conduct extensive ablations and analyses to demonstrate that our performance improvements stem from adding relevant definitional knowledge. We find that careful prompting strategies also improve LLM performance, allowing them to outperform fine-tuned language models in few-shot settings. To facilitate future research in this direction, we release our code at https://github.com/allenai/beacon.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\XJEGPBNK\\Munnangi et al. - 2024 - On-the-fly Definition Augmentation of LLMs for Bio.pdf;C\:\\Users\\lenna\\Zotero\\storage\\JHQ5HWXA\\2404.html}
}

@misc{naguibFewshotClinicalEntity2024,
  title = {Few-Shot Clinical Entity Recognition in {{English}}, {{French}} and {{Spanish}}: Masked Language Models Outperform Generative Model Prompting},
  shorttitle = {Few-Shot Clinical Entity Recognition in {{English}}, {{French}} and {{Spanish}}},
  author = {Naguib, Marco and Tannier, Xavier and N{\'e}v{\'e}ol, Aur{\'e}lie},
  year = {2024},
  month = oct,
  number = {arXiv:2402.12801},
  eprint = {2402.12801},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2402.12801},
  urldate = {2025-01-16},
  abstract = {Large language models (LLMs) have become the preferred solution for many natural language processing tasks. In low-resource environments such as specialized domains, their few-shot capabilities are expected to deliver high performance. Named Entity Recognition (NER) is a critical task in information extraction that is not covered in recent LLM benchmarks. There is a need for better understanding the performance of LLMs for NER in a variety of settings including languages other than English. This study aims to evaluate generative LLMs, employed through prompt engineering, for few-shot clinical NER. \%from the perspective of F1 performance and environmental impact. We compare 13 auto-regressive models using prompting and 16 masked models using fine-tuning on 14 NER datasets covering English, French and Spanish. While prompt-based auto-regressive models achieve competitive F1 for general NER, they are outperformed within the clinical domain by lighter biLSTM-CRF taggers based on masked models. Additionally, masked models exhibit lower environmental impact compared to auto-regressive models. Findings are consistent across the three languages studied, which suggests that LLM prompting is not yet suited for NER production in the clinical domain.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\R67TJVJ6\\Naguib et al. - 2024 - Few-shot clinical entity recognition in English, F.pdf;C\:\\Users\\lenna\\Zotero\\storage\\RDCTZZAZ\\2402.html}
}

@article{nororiAddressingBiasBig2021,
  title = {Addressing Bias in Big Data and {{AI}} for Health Care: {{A}} Call for Open Science},
  shorttitle = {Addressing Bias in Big Data and {{AI}} for Health Care},
  author = {Norori, Natalia and Hu, Qiyang and Aellen, Florence Marcelle and Faraci, Francesca Dalia and Tzovara, Athina},
  year = {2021},
  month = oct,
  journal = {PATTER},
  volume = {2},
  number = {10},
  publisher = {Elsevier},
  issn = {2666-3899},
  doi = {10.1016/j.patter.2021.100347},
  urldate = {2025-06-03},
  langid = {english},
  pmid = {34693373},
  keywords = {artificial intelligence,bias,data standards,deep learning,DSML 1: Concept: Basic principles of a new data science output observed and reported,health care,open science,participatory science},
  file = {C:\Users\lenna\Zotero\storage\LZXQ6KUU\Norori et al. - 2021 - Addressing bias in big data and AI for health care.pdf}
}

@misc{Ollama,
  title = {Ollama},
  urldate = {2025-08-12},
  abstract = {Get up and running with large language models.},
  howpublished = {https://ollama.com},
  file = {C:\Users\lenna\Zotero\storage\JWVQLR8L\ollama.com.html}
}

@misc{OpenMedicalLLMLeaderboard,
  title = {Open {{Medical-LLM Leaderboard}} - a {{Hugging Face Space}} by Openlifescienceai},
  urldate = {2025-06-03},
  abstract = {Browse a leaderboard of large language model evaluations and submit your model for evaluation. You can search and filter models by type, precision, and size. Submission requires providing details a...},
  howpublished = {https://huggingface.co/spaces/openlifescienceai/open\_medical\_llm\_leaderboard},
  file = {C:\Users\lenna\Zotero\storage\VS7QA7CK\open_medical_llm_leaderboard.html}
}

@misc{paezAxeXAIPlea2024,
  title = {Axe the {{X}} in {{XAI}}: {{A Plea}} for {{Understandable AI}}},
  shorttitle = {Axe the {{X}} in {{XAI}}},
  author = {P{\'a}ez, Andr{\'e}s},
  year = {2024},
  month = mar,
  number = {arXiv:2403.00315},
  eprint = {2403.00315},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2403.00315},
  urldate = {2024-06-30},
  abstract = {In a recent paper, Erasmus et al. (2021) defend the idea that the ambiguity of the term "explanation" in explainable AI (XAI) can be solved by adopting any of four different extant accounts of explanation in the philosophy of science: the Deductive Nomological, Inductive Statistical, Causal Mechanical, and New Mechanist models. In this chapter, I show that the authors' claim that these accounts can be applied to deep neural networks as they would to any natural phenomenon is mistaken. I also provide a more general argument as to why the notion of explainability as it is currently used in the XAI literature bears little resemblance to the traditional concept of scientific explanation. It would be more fruitful to use the label "understandable AI" to avoid the confusion that surrounds the goal and purposes of XAI. In the second half of the chapter, I argue for a pragmatic conception of understanding that is better suited to play the central role attributed to explanation in XAI. Following Kuorikoski \& Ylikoski (2015), the conditions of satisfaction for understanding an ML system are fleshed out in terms of an agent's success in using the system, in drawing correct inferences from it.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\ZHUUAG52\\Páez - 2024 - Axe the X in XAI A Plea for Understandable AI.pdf;C\:\\Users\\lenna\\Zotero\\storage\\RWYSH5JG\\2403.html}
}

@misc{qinLargeLanguageModels2024,
  title = {Large {{Language Models Meet NLP}}: {{A Survey}}},
  shorttitle = {Large {{Language Models Meet NLP}}},
  author = {Qin, Libo and Chen, Qiguang and Feng, Xiachong and Wu, Yang and Zhang, Yongheng and Li, Yinghui and Li, Min and Che, Wanxiang and Yu, Philip S.},
  year = {2024},
  month = may,
  number = {arXiv:2405.12819},
  eprint = {2405.12819},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2405.12819},
  urldate = {2025-08-19},
  abstract = {While large language models (LLMs) like ChatGPT have shown impressive capabilities in Natural Language Processing (NLP) tasks, a systematic investigation of their potential in this field remains largely unexplored. This study aims to address this gap by exploring the following questions: (1) How are LLMs currently applied to NLP tasks in the literature? (2) Have traditional NLP tasks already been solved with LLMs? (3) What is the future of the LLMs for NLP? To answer these questions, we take the first step to provide a comprehensive overview of LLMs in NLP. Specifically, we first introduce a unified taxonomy including (1) parameter-frozen application and (2) parameter-tuning application to offer a unified perspective for understanding the current progress of LLMs in NLP. Furthermore, we summarize the new frontiers and the associated challenges, aiming to inspire further groundbreaking advancements. We hope this work offers valuable insights into the \{potential and limitations\} of LLMs in NLP, while also serving as a practical guide for building effective LLMs in NLP.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C:\Users\lenna\Zotero\storage\3AX59JK2\Qin et al. - 2024 - Large Language Models Meet NLP A Survey.pdf}
}

@article{radfordImprovingLanguageUnderstanding2018,
  title = {Improving {{Language Understanding}} by {{Generative Pre-Training}}},
  author = {Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
  year = {2018},
  month = jun,
  urldate = {2025-08-18},
  abstract = {Natural language understanding comprises a wide range of diverse tasks such as textual entailment, question answering, semantic similarity assessment, and document classification. Although large unlabeled text corpora are abundant, labeled data for learning these specific tasks is scarce, making it challenging for discriminatively trained models to perform adequately. We demonstrate that large gains on these tasks can be realized by generative pre-training of a language model on a diverse corpus of unlabeled text, followed by discriminative fine-tuning on each specific task. In contrast to previous approaches, we make use of task-aware input transformations during fine-tuning to achieve effective transfer while requiring minimal changes to the model architecture. We demonstrate the effectiveness of our approach on a wide range of benchmarks for natural language understanding. Our general task-agnostic model outperforms discriminatively trained models that use architectures specifically crafted for each task, significantly improving upon the state of the art in 9 out of the 12 tasks studied. For instance, we achieve absolute improvements of 8.9\% on commonsense reasoning (Stories Cloze Test), 5.7\% on question answering (RACE), and 1.5\% on textual entailment (MultiNLI).},
  langid = {english},
  file = {C:\Users\lenna\Zotero\storage\UNJPCQ9D\Radford et al. - Improving Language Understanding by Generative Pre.pdf}
}

@book{ranjanTrustworthinessLLMsMedical2024,
  title = {Trustworthiness of {{LLMs}} in {{Medical Domain}}},
  author = {Ranjan, Ravi and Pramanik, Vishal and Grover, Utkarsh},
  year = {2024},
  month = dec,
  doi = {10.13140/RG.2.2.26102.31047},
  abstract = {Trustworthiness is a critical factor in deploying large language models (LLMs) in the medical domain, where decision-making significantly impacts patient outcomes. This study investigates the interpretability of machine learning models applied to classify patient symptoms into five distinct disease categories. We employ three popular explainability techniques-Local Interpretable Model-Agnostic Explanations (LIME), Shapley Additive Explanations (SHAP), and Integrated Gradients (IG)-to evaluate and compare the interpretability of three models: LLAMA 3.2, BERT, and logistic regression. Our findings reveal that each explainability method effectively identifies key features contributing to the classification process, with a focus on symptom-related keywords. Comparative results demonstrate the alignment of these methods in highlighting critical features, ensuring that the models base their predictions on medically relevant inputs. The study emphasizes the importance of model interpretability in fostering trust, providing insights into how the models process patient symptoms and arrive at diagnostic predictions. This analysis highlights the potential of interpretable AI tools in ensuring reliable and ethical use of LLMs in medical applications.},
  file = {C:\Users\lenna\Zotero\storage\4K8QUYT9\Ranjan et al. - 2024 - Trustworthiness of LLMs in Medical Domain.pdf}
}

@misc{reichenpfaderRadExFrameworkStructured2024,
  title = {{{RadEx}}: {{A Framework}} for {{Structured Information Extraction}} from {{Radiology Reports}} Based on {{Large Language Models}}},
  shorttitle = {{{RadEx}}},
  author = {Reichenpfader, Daniel and Knupp, Jonas and Sander, Andr{\'e} and Denecke, Kerstin},
  year = {2024},
  month = jun,
  number = {arXiv:2406.15465},
  eprint = {2406.15465},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2406.15465},
  urldate = {2024-12-19},
  abstract = {Annually and globally, over three billion radiography examinations and computer tomography scans result in mostly unstructured radiology reports containing free text. Despite the potential benefits of structured reporting, its adoption is limited by factors such as established processes, resource constraints and potential loss of information. However, structured information would be necessary for various use cases, including automatic analysis, clinical trial matching, and prediction of health outcomes. This study introduces RadEx, an end-to-end framework comprising 15 software components and ten artifacts to develop systems that perform automated information extraction from radiology reports. It covers the complete process from annotating training data to extracting information by offering a consistent generic information model and setting boundaries for model development. Specifically, RadEx allows clinicians to define relevant information for clinical domains (e.g., mammography) and to create report templates. The framework supports both generative and encoder-only models and the decoupling of information extraction from template filling enables independent model improvements. Developing information extraction systems according to the RadEx framework facilitates implementation and maintenance as components are easily exchangeable, while standardized artifacts ensure interoperability between components.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\7IL4LD2B\\Reichenpfader et al. - 2024 - RadEx A Framework for Structured Information Extr.pdf;C\:\\Users\\lenna\\Zotero\\storage\\BYQ756VH\\2406.html}
}

@inproceedings{ribeiroWhyShouldTrust2016,
  title = {"{{Why Should I Trust You}}?": {{Explaining}} the {{Predictions}} of {{Any Classifier}}},
  shorttitle = {"{{Why Should I Trust You}}?},
  booktitle = {Proceedings of the 22nd {{ACM SIGKDD International Conference}} on {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  year = {2016},
  month = aug,
  series = {{{KDD}} '16},
  pages = {1135--1144},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/2939672.2939778},
  urldate = {2024-06-30},
  abstract = {Despite widespread adoption, machine learning models remain mostly black boxes. Understanding the reasons behind predictions is, however, quite important in assessing trust, which is fundamental if one plans to take action based on a prediction, or when choosing whether to deploy a new model. Such understanding also provides insights into the model, which can be used to transform an untrustworthy model or prediction into a trustworthy one.In this work, we propose LIME, a novel explanation technique that explains the predictions of any classifier in an interpretable and faithful manner, by learning an interpretable model locally varound the prediction. We also propose a method to explain models by presenting representative individual predictions and their explanations in a non-redundant way, framing the task as a submodular optimization problem. We demonstrate the flexibility of these methods by explaining different models for text (e.g. random forests) and image classification (e.g. neural networks). We show the utility of explanations via novel experiments, both simulated and with human subjects, on various scenarios that require trust: deciding if one should trust a prediction, choosing between models, improving an untrustworthy classifier, and identifying why a classifier should not be trusted.},
  isbn = {978-1-4503-4232-2}
}

@article{ROBOTLEARNINGEdited1999,
  title = {{{ROBOT LEARNING}}, Edited by {{Jonathan H}}. {{Connell}} and {{Sridhar Mahadevan}}, {{Kluwer}}, {{Boston}}, 1993/1997, Xii+240 Pp., {{ISBN}} 0-7923-9365-1 ({{Hardback}}, 218.00 {{Guilders}}, \$120.00, {\pounds}89.95).},
  year = {1999},
  month = mar,
  journal = {Robotica},
  volume = {17},
  number = {2},
  pages = {229--235},
  issn = {1469-8668, 0263-5747},
  doi = {10.1017/S0263574799271172},
  urldate = {2025-08-18},
  abstract = {ROBOT LEARNING, edited by Jonathan H. Connell and Sridhar Mahadevan, Kluwer, Boston, 1993/1997, xii+240\hspace{0.166em}pp., ISBN 0-7923-9365-1 (Hardback, 218.00 Guilders, \$120.00, {\pounds}89.95). - Volume 17 Issue 2},
  langid = {english}
}

@misc{roeschlAssessingLimitationsLarge2025,
  title = {Assessing the {{Limitations}} of {{Large Language Models}} in {{Clinical Practice Guideline-concordant Treatment Decision-making}} on {{Real-world Data}}},
  author = {Roeschl, Tobias and Hoffmann, Marie and Hashemi, Djawid and Rarreck, Felix and Hinrichs, Nils and Trippel, Tobias D. and Gr{\"o}schel, Matthias I. and Unbehaun, Axel and Klein, Christoph and Kempfert, J{\"o}rg and Dreger, Henryk and O'Brien, Benjamin and Hindricks, Gerhard and Balzer, Felix and Falk, Volkmar and Meyer, Alexander},
  year = {2025},
  month = feb,
  pages = {2024.11.20.24313385},
  publisher = {medRxiv},
  doi = {10.1101/2024.11.20.24313385},
  urldate = {2025-05-28},
  abstract = {Aims Large Language Models (LLMs) have shown promise in therapeutic decision-making comparable to medical experts, but these studies have used highly curated patient data. The aim of this study was to determine whether LLMs can make guideline-concordant treatment decisions based on patient data as it typically presents in clinical practice. Methods and Results We conducted a retrospective study of 80 patients with severe aortic stenosis who were scheduled for either surgical (SAVR, n=24) or transcatheter aortic valve replacement (TAVR, n=56) by our institutional heart team in 2022. Various LLMs (BioGPT, GPT-3.5, GPT-4, GPT-4 Turbo, GPT-4o, Llama-2, Mistral, PaLM 2, and DeepSeek-R1) were queried using either anonymized original medical reports or manually generated case summaries to determine the most guideline-concordant treatment. Agreement with the Heart Team was measured using Cohen's kappa coefficients, reliability using intraclass correlation coefficients (ICCs), and fairness using frequency bias indices (FBIs) with FBIs {$>$}1 indicating bias towards TAVR. When presented with original medical reports, LLMs showed poor performance (kappa: -0.47--0.22, ICC: 0.0--1.0, FBI: 0.95--1.51). The LLMs' performance improved substantially when case summaries were used as input and additional guideline knowledge was added to the prompt (kappa: -0.02--0.63, ICC: 0.01--1.0, FBI: 0.46--1.23). Qualitative analysis revealed instances of hallucinations in all LLMs tested. Conclusion Even advanced LLMs require extensively curated input for informed treatment decisions. Unreliable responses, bias and hallucinations pose significant health risks and highlight the need for caution in applying LLMs to real-world clinical decision-making.},
  archiveprefix = {medRxiv},
  copyright = {{\copyright} 2025, Posted by Cold Spring Harbor Laboratory. This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at http://creativecommons.org/licenses/by-nc-nd/4.0/},
  langid = {english},
  file = {C:\Users\lenna\Zotero\storage\6WZVTABK\Roeschl et al. - 2025 - Assessing the Limitations of Large Language Models.pdf}
}

@article{rokachDecisionForestTwenty2016,
  title = {Decision Forest: {{Twenty}} Years of Research},
  shorttitle = {Decision Forest},
  author = {Rokach, Lior},
  year = {2016},
  month = jan,
  journal = {Information Fusion},
  volume = {27},
  pages = {111--125},
  issn = {1566-2535},
  doi = {10.1016/j.inffus.2015.06.005},
  urldate = {2024-08-06},
  abstract = {A decision tree is a predictive model that recursively partitions the covariate's space into subspaces such that each subspace constitutes a basis for a different prediction function. Decision trees can be used for various learning tasks including classification, regression and survival analysis. Due to their unique benefits, decision trees have become one of the most powerful and popular approaches in data science. Decision forest aims to improve the predictive performance of a single decision tree by training multiple trees and combining their predictions. This paper provides an introduction to the subject by explaining how a decision forest can be created and when it is most valuable. In addition, we are reviewing some popular methods for generating the forest, fusion the individual trees' outputs and thinning large decision forests.},
  keywords = {Classification tree,Decision forest,Decision tree,Random forest},
  file = {C:\Users\lenna\Zotero\storage\7E8QCPZT\S1566253515000561.html}
}

@misc{roziereCodeLlamaOpen2024,
  title = {Code {{Llama}}: {{Open Foundation Models}} for {{Code}}},
  shorttitle = {Code {{Llama}}},
  author = {Rozi{\`e}re, Baptiste and Gehring, Jonas and Gloeckle, Fabian and Sootla, Sten and Gat, Itai and Tan, Xiaoqing Ellen and Adi, Yossi and Liu, Jingyu and Sauvestre, Romain and Remez, Tal and Rapin, J{\'e}r{\'e}my and Kozhevnikov, Artyom and Evtimov, Ivan and Bitton, Joanna and Bhatt, Manish and Ferrer, Cristian Canton and Grattafiori, Aaron and Xiong, Wenhan and D{\'e}fossez, Alexandre and Copet, Jade and Azhar, Faisal and Touvron, Hugo and Martin, Louis and Usunier, Nicolas and Scialom, Thomas and Synnaeve, Gabriel},
  year = {2024},
  month = jan,
  number = {arXiv:2308.12950},
  eprint = {2308.12950},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2308.12950},
  urldate = {2025-06-02},
  abstract = {We release Code Llama, a family of large language models for code based on Llama 2 providing state-of-the-art performance among open models, infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks. We provide multiple flavors to cover a wide range of applications: foundation models (Code Llama), Python specializations (Code Llama - Python), and instruction-following models (Code Llama - Instruct) with 7B, 13B, 34B and 70B parameters each. All models are trained on sequences of 16k tokens and show improvements on inputs with up to 100k tokens. 7B, 13B and 70B Code Llama and Code Llama - Instruct variants support infilling based on surrounding content. Code Llama reaches state-of-the-art performance among open models on several code benchmarks, with scores of up to 67\% and 65\% on HumanEval and MBPP, respectively. Notably, Code Llama - Python 7B outperforms Llama 2 70B on HumanEval and MBPP, and all our models outperform every other publicly available model on MultiPL-E. We release Code Llama under a permissive license that allows for both research and commercial use.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\PIJZFK8B\\Rozière et al. - 2024 - Code Llama Open Foundation Models for Code.pdf;C\:\\Users\\lenna\\Zotero\\storage\\2EXKVMM8\\2308.html}
}

@misc{sainzGoLLIEAnnotationGuidelines2024,
  title = {{{GoLLIE}}: {{Annotation Guidelines}} Improve {{Zero-Shot Information-Extraction}}},
  shorttitle = {{{GoLLIE}}},
  author = {Sainz, Oscar and {Garc{\'i}a-Ferrero}, Iker and Agerri, Rodrigo and de Lacalle, Oier Lopez and Rigau, German and Agirre, Eneko},
  year = {2024},
  month = mar,
  number = {arXiv:2310.03668},
  eprint = {2310.03668},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2310.03668},
  urldate = {2025-01-16},
  abstract = {Large Language Models (LLMs) combined with instruction tuning have made significant progress when generalizing to unseen tasks. However, they have been less successful in Information Extraction (IE), lagging behind task-specific models. Typically, IE tasks are characterized by complex annotation guidelines that describe the task and give examples to humans. Previous attempts to leverage such information have failed, even with the largest models, as they are not able to follow the guidelines out of the box. In this paper, we propose GoLLIE (Guideline-following Large Language Model for IE), a model able to improve zero-shot results on unseen IE tasks by virtue of being fine-tuned to comply with annotation guidelines. Comprehensive evaluation empirically demonstrates that GoLLIE is able to generalize to and follow unseen guidelines, outperforming previous attempts at zero-shot information extraction. The ablation study shows that detailed guidelines are key for good results.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\W69NF65Y\\Sainz et al. - 2024 - GoLLIE Annotation Guidelines improve Zero-Shot In.pdf;C\:\\Users\\lenna\\Zotero\\storage\\FEQRGZN5\\2310.html}
}

@article{samuelStudiesMachineLearning1959,
  title = {Some Studies in Machine Learning Using the Game of Checkers},
  author = {Samuel, A. L.},
  year = {1959},
  month = jul,
  journal = {IBM J. Res. Dev.},
  volume = {3},
  number = {3},
  pages = {210--229},
  issn = {0018-8646},
  doi = {10.1147/rd.33.0210},
  urldate = {2025-08-19},
  abstract = {Two machine-learning procedures have been investigated in some detail using the game of checkers. Enough work has been done to verify the fact that a computer can be programmed so that it will learn to play a better game of checkers than can be played by the person who wrote the program. Furthermore, it can learn to do this in a remarkably short period of time (8 or 10 hours of machine-playing time) when given only the rules of the game, a sense of direction, and a redundant and incomplete list of parameters which are thought to have something to do with the game, but whose correct signs and relative weights are unknown and unspecified. The principles of machine learning verified by these experiments are, of course, applicable to many other situations.},
  file = {C:\Users\lenna\Zotero\storage\YQXS5W9T\Samuel - 1959 - Some studies in machine learning using the game of.pdf}
}

@article{sanderIntegratingTerminologiesStandard2019,
  title = {Integrating Terminologies into Standard {{SQL}}: {{A}} New Approach for Research on Routine Data},
  shorttitle = {Integrating Terminologies into Standard {{SQL}}},
  author = {Sander, Andr{\'e} and Wauer, Roland},
  year = {2019},
  month = apr,
  journal = {Journal of Biomedical Semantics},
  volume = {10},
  doi = {10.1186/s13326-019-0199-z},
  abstract = {Background Most electronic medical records still contain large amounts of free-text data. Semantic evaluation of such data requires the data to be encoded with sufficient classifications or transformed into a knowledge-based database. Methods We present an approach that allows databases accessible via SQL (Structured Query Language) to be searched directly through semantic queries without the need for further transformations. Therefore, we developed I) an extension to SQL named Ontology-SQL (O-SQL) that allows to use semantic expressions, II) a framework that uses a standard terminology server to annotate free-text containing database tables and III) a parser that rewrites O-SQL to SQL, so that such queries can be passed to the database server. Results I) We compared several semantic queries published to date and were able to reproduce them in a reduced, highly condensed form. II) The quality of the annotation process was measured against manual annotation, and we found a sensitivity of 97.62\% and a specificity of 100.00\%. III) Different semantic queries were analyzed, and measured with F-scores between 0.91 and 0.98. Conclusions We showed that systematic analysis of free-text-containing medical records is possible with standard tools. The seamless connection of ontologies and standard technologies from the database field represents an important constituent of unstructured data analysis. The developed technology can be readily applied to relationally organized data and supports the increasingly important field of translational research. Electronic supplementary material The online version of this article (10.1186/s13326-019-0199-z) contains supplementary material, which is available to authorized users.},
  file = {C:\Users\lenna\Zotero\storage\S67FRF8N\Sander und Wauer - 2019 - Integrating terminologies into standard SQL A new.pdf}
}

@misc{sellergrenMedGemmaTechnicalReport2025,
  title = {{{MedGemma Technical Report}}},
  author = {Sellergren, Andrew and Kazemzadeh, Sahar and Jaroensri, Tiam and Kiraly, Atilla and Traverse, Madeleine and Kohlberger, Timo and Xu, Shawn and Jamil, Fayaz and Hughes, C{\'i}an and Lau, Charles and Chen, Justin and Mahvar, Fereshteh and Yatziv, Liron and Chen, Tiffany and Sterling, Bram and Baby, Stefanie Anna and Baby, Susanna Maria and Lai, Jeremy and Schmidgall, Samuel and Yang, Lu and Chen, Kejia and Bjornsson, Per and Reddy, Shashir and Brush, Ryan and Philbrick, Kenneth and Asiedu, Mercy and Mezerreg, Ines and Hu, Howard and Yang, Howard and Tiwari, Richa and Jansen, Sunny and Singh, Preeti and Liu, Yun and Azizi, Shekoofeh and Kamath, Aishwarya and Ferret, Johan and Pathak, Shreya and Vieillard, Nino and Merhej, Ramona and Perrin, Sarah and Matejovicova, Tatiana and Ram{\'e}, Alexandre and Riviere, Morgane and Rouillard, Louis and Mesnard, Thomas and Cideron, Geoffrey and Grill, Jean-bastien and Ramos, Sabela and Yvinec, Edouard and Casbon, Michelle and Buchatskaya, Elena and Alayrac, Jean-Baptiste and Lepikhin, Dmitry and Feinberg, Vlad and Borgeaud, Sebastian and Andreev, Alek and Hardin, Cassidy and Dadashi, Robert and Hussenot, L{\'e}onard and Joulin, Armand and Bachem, Olivier and Matias, Yossi and Chou, Katherine and Hassidim, Avinatan and Goel, Kavi and Farabet, Clement and Barral, Joelle and Warkentin, Tris and Shlens, Jonathon and Fleet, David and Cotruta, Victor and Sanseviero, Omar and Martins, Gus and Kirk, Phoebe and Rao, Anand and Shetty, Shravya and Steiner, David F. and Kirmizibayrak, Can and Pilgrim, Rory and Golden, Daniel and Yang, Lin},
  year = {2025},
  month = jul,
  number = {arXiv:2507.05201},
  eprint = {2507.05201},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2507.05201},
  urldate = {2025-08-12},
  abstract = {Artificial intelligence (AI) has significant potential in healthcare applications, but its training and deployment faces challenges due to healthcare's diverse data, complex tasks, and the need to preserve privacy. Foundation models that perform well on medical tasks and require less task-specific tuning data are critical to accelerate the development of healthcare AI applications. We introduce MedGemma, a collection of medical vision-language foundation models based on Gemma 3 4B and 27B. MedGemma demonstrates advanced medical understanding and reasoning on images and text, significantly exceeding the performance of similar-sized generative models and approaching the performance of task-specific models, while maintaining the general capabilities of the Gemma 3 base models. For out-of-distribution tasks, MedGemma achieves 2.6-10\% improvement on medical multimodal question answering, 15.5-18.1\% improvement on chest X-ray finding classification, and 10.8\% improvement on agentic evaluations compared to the base models. Fine-tuning MedGemma further improves performance in subdomains, reducing errors in electronic health record information retrieval by 50\% and reaching comparable performance to existing specialized state-of-the-art methods for pneumothorax classification and histopathology patch classification. We additionally introduce MedSigLIP, a medically-tuned vision encoder derived from SigLIP. MedSigLIP powers the visual understanding capabilities of MedGemma and as an encoder achieves comparable or better performance than specialized medical image encoders. Taken together, the MedGemma collection provides a strong foundation of medical image and text capabilities, with potential to significantly accelerate medical research and development of downstream applications. The MedGemma collection, including tutorials and model weights, can be found at https://goo.gle/medgemma.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Recognition,evaluation_models},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\XZYSNJXV\\Sellergren et al. - 2025 - MedGemma Technical Report.pdf;C\:\\Users\\lenna\\Zotero\\storage\\EG8VW3TN\\2507.html}
}

@article{sinooLightConditionsOlder2011,
  title = {Light Conditions for Older Adults in the Nursing Home: {{Assessment}} of Environmental Illuminances and Colour Temperature},
  shorttitle = {Light Conditions for Older Adults in the Nursing Home},
  author = {Sinoo, Marianne M. and Van Hoof, Joost and Kort, Helianthe SM},
  year = {2011},
  journal = {Building and Environment},
  volume = {46},
  number = {10},
  pages = {1917--1927},
  publisher = {Elsevier},
  urldate = {2024-04-30}
}

@article{smallReviewInformationExtraction2014,
  title = {Review of Information Extraction Technologies and Applications},
  author = {Small, Sharon Gower and Medsker, Larry},
  year = {2014},
  month = sep,
  journal = {Neural Comput \& Applic},
  volume = {25},
  number = {3},
  pages = {533--548},
  issn = {1433-3058},
  doi = {10.1007/s00521-013-1516-6},
  urldate = {2025-08-05},
  abstract = {Information extraction (IE) is an important and growing field, in part because of the development of ubiquitous social media networking millions of people and producing huge collections of textual information. Mined information is being used in a wide array of application areas from targeted marketing of products to intelligence gathering for military and security needs. IE has its roots in artificial intelligence fields including machine learning, logic and search algorithms, computational linguistics, and pattern recognition. This review summarizes the history of IE, surveys the various uses of IE, identifies current technological accomplishments and challenges, and explores the role that neural and adaptive computing might play in future research. A goal for this review is also to encourage practitioners of neural and adaptive computing to look for interesting applications in the important emerging area of IE.},
  langid = {english},
  keywords = {Adaptive computing,Big Data,Computational Intelligence,Computational linguistics,Computer and Information Systems Applications,Data Mining and Knowledge Discovery,Information extraction,Information Processing,Information retrieval,Information Storage and Retrieval,Information Studies,Machine learning,Neural computing,Web IE,Web information analysis},
  file = {C:\Users\lenna\Zotero\storage\MMES4JZJ\Small und Medsker - 2014 - Review of information extraction technologies and .pdf}
}

@article{smedingaMetaphorsToolsUnderstanding2023,
  title = {Metaphors as Tools for Understanding in Science Communication among Experts and to the Public},
  author = {Smedinga, Marthe and Cienki, Alan and de Regt, Henk W.},
  year = {2023},
  month = nov,
  journal = {Metaphor and the Social World},
  volume = {13},
  number = {2},
  pages = {248--268},
  publisher = {John Benjamins},
  issn = {2210-4070, 2210-4097},
  doi = {10.1075/msw.22016.sme},
  urldate = {2024-06-30},
  abstract = {Abstract Science communication is highly important in present-day society. But mere factual information transfer does not suffice for enhancing public understanding of scientific results, theories, and concepts. In this paper we compare science communication among experts with communication from experts to laypeople, to better understand the role of metaphors in constructing understanding of abstract scientific concepts. As a case study, we analyze specialist and non-specialist scientific articles on epigenetics, the study of heritable changes in gene expression not altering DNA sequence. The results of our analysis show that there is no substantial difference between the two types of articles in frequency of metaphors and in their content. However, the function of the metaphors is different: the figurative aspect of metaphors is employed for public understanding but plays no role in specialist scientific articles. We outline the implications of these results for current philosophical debates on scientific understanding and public understanding of science: (1) metaphors are tools for rendering theoretical concepts intelligible, for both expert and lay audiences; (2) expert and public understanding differ in degree rather than in kind; (3) conveying understanding crucially involves skills: metaphors in this context do not so much add knowledge as enhance relevant conceptual reasoning abilities.},
  langid = {english},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\Q5XCZL9Y\\Smedinga et al. - 2023 - Metaphors as tools for understanding in science co.pdf;C\:\\Users\\lenna\\Zotero\\storage\\B42K9QDM\\msw.22016.html}
}

@article{snyderAcuteAppendicitisEfficient2018,
  title = {Acute {{Appendicitis}}: {{Efficient Diagnosis}} and {{Management}}},
  shorttitle = {Acute {{Appendicitis}}},
  author = {Snyder, Matthew J. and Guthrie, Marjorie and Cagle, Stephen},
  year = {2018},
  month = jul,
  journal = {afp},
  volume = {98},
  number = {1},
  pages = {25--33},
  urldate = {2025-08-01},
  abstract = {Appendicitis is one of the most common causes of acute abdominal pain in adults and children, and the most common nonobstetric surgical emergency during pregnancy. Right lower quadrant pain, abdominal rigidity, and periumbilical pain radiating to the right lower quadrant are the best signs for ruling in acute appendicitis in adults. Absent or decreased bowel sounds, a positive psoas sign, a positive obturator sign, and a positive Rovsing sign are most reliable for ruling in acute appendicitis in children. Clinical decision rules incorporate common clinical and laboratory findings to stratify patients as low, moderate, or high risk and can help in making a timely diagnosis.},
  langid = {american},
  file = {C:\Users\lenna\Zotero\storage\5RQZV7QE\Snyder et al. - 2018 - Acute Appendicitis Efficient Diagnosis and Manage.pdf}
}

@inproceedings{speithReviewTaxonomiesExplainable2022,
  title = {A {{Review}} of {{Taxonomies}} of {{Explainable Artificial Intelligence}} ({{XAI}}) {{Methods}}},
  booktitle = {Proceedings of the 2022 {{ACM Conference}} on {{Fairness}}, {{Accountability}}, and {{Transparency}}},
  author = {Speith, Timo},
  year = {2022},
  month = jun,
  series = {{{FAccT}} '22},
  pages = {2239--2250},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3531146.3534639},
  urldate = {2024-08-05},
  abstract = {The recent surge in publications related to explainable artificial intelligence (XAI) has led to an almost insurmountable wall if one wants to get started or stay up to date with XAI. For this reason, articles and reviews that present taxonomies of XAI methods seem to be a welcomed way to get an overview of the field. Building on this idea, there is currently a trend of producing such taxonomies, leading to several competing approaches to construct them. In this paper, we will review recent approaches to constructing taxonomies of XAI methods and discuss general challenges concerning them as well as their individual advantages and limitations. Our review is intended to help scholars be aware of challenges current taxonomies face. As we will argue, when charting the field of XAI, it may not be sufficient to rely on one of the approaches we found. To amend this problem, we will propose and discuss three possible solutions: a new taxonomy that incorporates the reviewed ones, a database of XAI methods, and a decision tree to help choose fitting methods.},
  isbn = {978-1-4503-9352-2},
  file = {C:\Users\lenna\Zotero\storage\BWHSF4M8\Speith - 2022 - A Review of Taxonomies of Explainable Artificial I.pdf}
}

@book{stevensPrinciplesLighting1951,
  title = {Principles of {{Lighting}}},
  author = {Stevens, Wallace Roberts},
  year = {1951},
  publisher = {Constable},
  googlebooks = {gH5RAAAAMAAJ},
  langid = {english}
}

@article{sudmannQuestionnaireArtificialIntelligence,
  title = {Questionnaire {{Artificial Intelligence}} in Medical Devices},
  author = {Sudmann, Volker},
  journal = {Artificial Intelligence},
  langid = {english}
}

@book{sutton1998reinforcement,
  title = {Reinforcement Learning: {{An}} Introduction},
  author = {Sutton, Richard S and Barto, Andrew G and others},
  year = {1998},
  volume = {1},
  publisher = {MIT press Cambridge}
}

@misc{teamGemma3Technical2025,
  title = {Gemma 3 {{Technical Report}}},
  author = {Team, Gemma and Kamath, Aishwarya and Ferret, Johan and Pathak, Shreya and Vieillard, Nino and Merhej, Ramona and Perrin, Sarah and Matejovicova, Tatiana and Ram{\'e}, Alexandre and Rivi{\`e}re, Morgane and Rouillard, Louis and Mesnard, Thomas and Cideron, Geoffrey and Grill, Jean-bastien and Ramos, Sabela and Yvinec, Edouard and Casbon, Michelle and Pot, Etienne and Penchev, Ivo and Liu, Ga{\"e}l and Visin, Francesco and Kenealy, Kathleen and Beyer, Lucas and Zhai, Xiaohai and Tsitsulin, Anton and {Busa-Fekete}, Robert and Feng, Alex and Sachdeva, Noveen and Coleman, Benjamin and Gao, Yi and Mustafa, Basil and Barr, Iain and Parisotto, Emilio and Tian, David and Eyal, Matan and Cherry, Colin and Peter, Jan-Thorsten and Sinopalnikov, Danila and Bhupatiraju, Surya and Agarwal, Rishabh and Kazemi, Mehran and Malkin, Dan and Kumar, Ravin and Vilar, David and Brusilovsky, Idan and Luo, Jiaming and Steiner, Andreas and Friesen, Abe and Sharma, Abhanshu and Sharma, Abheesht and Gilady, Adi Mayrav and Goedeckemeyer, Adrian and Saade, Alaa and Feng, Alex and Kolesnikov, Alexander and Bendebury, Alexei and Abdagic, Alvin and Vadi, Amit and Gy{\"o}rgy, Andr{\'a}s and Pinto, Andr{\'e} Susano and Das, Anil and Bapna, Ankur and Miech, Antoine and Yang, Antoine and Paterson, Antonia and Shenoy, Ashish and Chakrabarti, Ayan and Piot, Bilal and Wu, Bo and Shahriari, Bobak and Petrini, Bryce and Chen, Charlie and Lan, Charline Le and {Choquette-Choo}, Christopher A. and Carey, C. J. and Brick, Cormac and Deutsch, Daniel and Eisenbud, Danielle and Cattle, Dee and Cheng, Derek and Paparas, Dimitris and Sreepathihalli, Divyashree Shivakumar and Reid, Doug and Tran, Dustin and Zelle, Dustin and Noland, Eric and Huizenga, Erwin and Kharitonov, Eugene and Liu, Frederick and Amirkhanyan, Gagik and Cameron, Glenn and Hashemi, Hadi and {Klimczak-Pluci{\'n}ska}, Hanna and Singh, Harman and Mehta, Harsh and Lehri, Harshal Tushar and Hazimeh, Hussein and Ballantyne, Ian and Szpektor, Idan and Nardini, Ivan and {Pouget-Abadie}, Jean and Chan, Jetha and Stanton, Joe and Wieting, John and Lai, Jonathan and Orbay, Jordi and Fernandez, Joseph and Newlan, Josh and Ji, Ju-yeong and Singh, Jyotinder and Black, Kat and Yu, Kathy and Hui, Kevin and Vodrahalli, Kiran and Greff, Klaus and Qiu, Linhai and Valentine, Marcella and Coelho, Marina and Ritter, Marvin and Hoffman, Matt and Watson, Matthew and Chaturvedi, Mayank and Moynihan, Michael and Ma, Min and Babar, Nabila and Noy, Natasha and Byrd, Nathan and Roy, Nick and Momchev, Nikola and Chauhan, Nilay and Sachdeva, Noveen and Bunyan, Oskar and Botarda, Pankil and Caron, Paul and Rubenstein, Paul Kishan and Culliton, Phil and Schmid, Philipp and Sessa, Pier Giuseppe and Xu, Pingmei and Stanczyk, Piotr and Tafti, Pouya and Shivanna, Rakesh and Wu, Renjie and Pan, Renke and Rokni, Reza and Willoughby, Rob and Vallu, Rohith and Mullins, Ryan and Jerome, Sammy and Smoot, Sara and Girgin, Sertan and Iqbal, Shariq and Reddy, Shashir and Sheth, Shruti and P{\~o}der, Siim and Bhatnagar, Sijal and Panyam, Sindhu Raghuram and Eiger, Sivan and Zhang, Susan and Liu, Tianqi and Yacovone, Trevor and Liechty, Tyler and Kalra, Uday and Evci, Utku and Misra, Vedant and Roseberry, Vincent and Feinberg, Vlad and Kolesnikov, Vlad and Han, Woohyun and Kwon, Woosuk and Chen, Xi and Chow, Yinlam and Zhu, Yuvein and Wei, Zichuan and Egyed, Zoltan and Cotruta, Victor and Giang, Minh and Kirk, Phoebe and Rao, Anand and Black, Kat and Babar, Nabila and Lo, Jessica and Moreira, Erica and Martins, Luiz Gustavo and Sanseviero, Omar and Gonzalez, Lucas and Gleicher, Zach and Warkentin, Tris and Mirrokni, Vahab and Senter, Evan and Collins, Eli and Barral, Joelle and Ghahramani, Zoubin and Hadsell, Raia and Matias, Yossi and Sculley, D. and Petrov, Slav and Fiedel, Noah and Shazeer, Noam and Vinyals, Oriol and Dean, Jeff and Hassabis, Demis and Kavukcuoglu, Koray and Farabet, Clement and Buchatskaya, Elena and Alayrac, Jean-Baptiste and Anil, Rohan and Dmitry and Lepikhin and Borgeaud, Sebastian and Bachem, Olivier and Joulin, Armand and Andreev, Alek and Hardin, Cassidy and Dadashi, Robert and Hussenot, L{\'e}onard},
  year = {2025},
  month = mar,
  number = {arXiv:2503.19786},
  eprint = {2503.19786},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2503.19786},
  urldate = {2025-08-12},
  abstract = {We introduce Gemma 3, a multimodal addition to the Gemma family of lightweight open models, ranging in scale from 1 to 27 billion parameters. This version introduces vision understanding abilities, a wider coverage of languages and longer context - at least 128K tokens. We also change the architecture of the model to reduce the KV-cache memory that tends to explode with long context. This is achieved by increasing the ratio of local to global attention layers, and keeping the span on local attention short. The Gemma 3 models are trained with distillation and achieve superior performance to Gemma 2 for both pre-trained and instruction finetuned versions. In particular, our novel post-training recipe significantly improves the math, chat, instruction-following and multilingual abilities, making Gemma3-4B-IT competitive with Gemma2-27B-IT and Gemma3-27B-IT comparable to Gemini-1.5-Pro across benchmarks. We release all our models to the community.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,evaluation_models},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\ZCBMJXGP\\Team et al. - 2025 - Gemma 3 Technical Report.pdf;C\:\\Users\\lenna\\Zotero\\storage\\N855RDIP\\2503.html}
}

@misc{ThewindmomLlama3med428b,
  title = {Thewindmom/Llama3-Med42-8b},
  urldate = {2025-08-12},
  abstract = {m42-health/Llama3-Med42-8B in Ollama},
  howpublished = {https://ollama.com/thewindmom/llama3-med42-8b},
  keywords = {evaluation_models},
  file = {C:\Users\lenna\Zotero\storage\3MUXRXSX\llama3-med42-8b.html}
}

@misc{ThewindmomLlama3med428ba,
  title = {Thewindmom/Llama3-Med42-8b},
  urldate = {2025-08-12},
  abstract = {m42-health/Llama3-Med42-8B in Ollama},
  howpublished = {https://ollama.com/thewindmom/llama3-med42-8b},
  file = {C:\Users\lenna\Zotero\storage\HZQYXVHR\llama3-med42-8b.html}
}

@article{thirunavukarasuLargeLanguageModels2023,
  title = {Large Language Models in Medicine},
  author = {Thirunavukarasu, Arun James and Ting, Darren Shu Jeng and Elangovan, Kabilan and Gutierrez, Laura and Tan, Ting Fang and Ting, Daniel Shu Wei},
  year = {2023},
  month = aug,
  journal = {Nat Med},
  volume = {29},
  number = {8},
  pages = {1930--1940},
  publisher = {Nature Publishing Group},
  issn = {1546-170X},
  doi = {10.1038/s41591-023-02448-8},
  urldate = {2025-05-28},
  abstract = {Large language models (LLMs) can respond to free-text queries without being specifically trained in the task in question, causing excitement and concern about their use in healthcare settings. ChatGPT is a generative artificial intelligence (AI) chatbot produced through sophisticated fine-tuning of an LLM, and other tools are emerging through similar developmental processes. Here we outline how LLM applications such as ChatGPT are developed, and we discuss how they are being leveraged in clinical settings. We consider the strengths and limitations of LLMs and their potential to improve the efficiency and effectiveness of clinical, educational and research work in medicine. LLM chatbots have already been deployed in a range of biomedical contexts, with impressive but mixed results. This review acts as a primer for interested clinicians, who will determine if and how LLM technology is used in healthcare for the benefit of patients and practitioners.},
  copyright = {2023 Springer Nature America, Inc.},
  langid = {english},
  keywords = {Patient education,Translational research},
  file = {C:\Users\lenna\Zotero\storage\VDXUPCM5\Thirunavukarasu et al. - 2023 - Large language models in medicine.pdf}
}

@mastersthesis{TOM,
  title = {Context-Adaptive Patient Data Presentation for Information Provision Systems in Healthcare},
  author = {Schreiber, Tom-Maurice},
  year = {2024},
  school = {Technische Universit{\"a}t Dresden}
}

@article{tordjmanComparativeBenchmarkingDeepSeek2025,
  title = {Comparative Benchmarking of the {{DeepSeek}} Large Language Model on Medical Tasks and Clinical Reasoning},
  author = {Tordjman, Mickael and Liu, Zelong and Yuce, Murat and Fauveau, Valentin and Mei, Yunhao and Hadjadj, Jerome and Bolger, Ian and Almansour, Haidara and Horst, Carolyn and Parihar, Ashwin Singh and Geahchan, Amine and Meribout, Anis and Yatim, Nader and Ng, Nicole and Robson, Phillip and Zhou, Alexander and Lewis, Sara and Huang, Mingqian and Deyer, Timothy and Taouli, Bachir and Lee, Hao-Chih and Fayad, Zahi A. and Mei, Xueyan},
  year = {2025},
  month = apr,
  journal = {Nat Med},
  pages = {1--6},
  publisher = {Nature Publishing Group},
  issn = {1546-170X},
  doi = {10.1038/s41591-025-03726-3},
  urldate = {2025-06-03},
  abstract = {DeepSeek is a newly introduced large language model (LLM) designed for enhanced reasoning, but its medical-domain capabilities have not yet been evaluated. Here we assessed the capabilities of three LLMs--- DeepSeek-R1, ChatGPT-o1 and Llama 3.1-405B---in performing four different medical tasks: answering questions from the United States Medical Licensing Examination (USMLE), interpreting and reasoning on the basis of text-based diagnostic and management cases, providing tumor classification according to RECIST 1.1 criteria and providing summaries of diagnostic imaging reports across multiple modalities. In the USMLE test, the performance of DeepSeek-R1 (accuracy 0.92) was slightly inferior to that of ChatGPT-o1 (accuracy 0.95; P\,=\,0.04) but better than that of Llama 3.1-405B (accuracy 0.83; P\,{$<$}\,10-3). For text-based case challenges, DeepSeek-R1 performed similarly to ChatGPT-o1 (accuracy of 0.57 versus 0.55; P\,=\,0.76 and 0.74 versus 0.76; P\,=\,0.06, using New England Journal of Medicine and M{\'e}dicilline databases, respectively). For RECIST classifications, DeepSeek-R1 also performed similarly to ChatGPT-o1 (0.74 versus 0.81; P\,=\,0.10). Diagnostic reasoning steps provided by DeepSeek were deemed more accurate than those provided by ChatGPT and Llama 3.1-405B (average Likert score of 3.61, 3.22 and 3.13, respectively, P\,=\,0.005 and P\,{$<$}\,10-3). However, summarized imaging reports provided by DeepSeek-R1 exhibited lower global quality than those provided by ChatGPT-o1 (5-point Likert score: 4.5 versus 4.8; P\,{$<$}\,10-3). This study highlights the potential of DeepSeek-R1 LLM for medical applications but also underlines areas needing improvements.},
  copyright = {2025 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  keywords = {Health care,Medical research},
  file = {C:\Users\lenna\Zotero\storage\GPNDNJK4\Tordjman et al. - 2025 - Comparative benchmarking of the DeepSeek large lan.pdf}
}

@misc{touvronLlama2Open2023,
  title = {Llama 2: {{Open Foundation}} and {{Fine-Tuned Chat Models}}},
  shorttitle = {Llama 2},
  author = {Touvron, Hugo and Martin, Louis and Stone, Kevin and Albert, Peter and Almahairi, Amjad and Babaei, Yasmine and Bashlykov, Nikolay and Batra, Soumya and Bhargava, Prajjwal and Bhosale, Shruti and Bikel, Dan and Blecher, Lukas and Ferrer, Cristian Canton and Chen, Moya and Cucurull, Guillem and Esiobu, David and Fernandes, Jude and Fu, Jeremy and Fu, Wenyin and Fuller, Brian and Gao, Cynthia and Goswami, Vedanuj and Goyal, Naman and Hartshorn, Anthony and Hosseini, Saghar and Hou, Rui and Inan, Hakan and Kardas, Marcin and Kerkez, Viktor and Khabsa, Madian and Kloumann, Isabel and Korenev, Artem and Koura, Punit Singh and Lachaux, Marie-Anne and Lavril, Thibaut and Lee, Jenya and Liskovich, Diana and Lu, Yinghai and Mao, Yuning and Martinet, Xavier and Mihaylov, Todor and Mishra, Pushkar and Molybog, Igor and Nie, Yixin and Poulton, Andrew and Reizenstein, Jeremy and Rungta, Rashi and Saladi, Kalyan and Schelten, Alan and Silva, Ruan and Smith, Eric Michael and Subramanian, Ranjan and Tan, Xiaoqing Ellen and Tang, Binh and Taylor, Ross and Williams, Adina and Kuan, Jian Xiang and Xu, Puxin and Yan, Zheng and Zarov, Iliyan and Zhang, Yuchen and Fan, Angela and Kambadur, Melanie and Narang, Sharan and Rodriguez, Aurelien and Stojnic, Robert and Edunov, Sergey and Scialom, Thomas},
  year = {2023},
  month = jul,
  number = {arXiv:2307.09288},
  eprint = {2307.09288},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2307.09288},
  urldate = {2025-06-02},
  abstract = {In this work, we develop and release Llama 2, a collection of pretrained and fine-tuned large language models (LLMs) ranging in scale from 7 billion to 70 billion parameters. Our fine-tuned LLMs, called Llama 2-Chat, are optimized for dialogue use cases. Our models outperform open-source chat models on most benchmarks we tested, and based on our human evaluations for helpfulness and safety, may be a suitable substitute for closed-source models. We provide a detailed description of our approach to fine-tuning and safety improvements of Llama 2-Chat in order to enable the community to build on our work and contribute to the responsible development of LLMs.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\H39SPXJN\\Touvron et al. - 2023 - Llama 2 Open Foundation and Fine-Tuned Chat Model.pdf;C\:\\Users\\lenna\\Zotero\\storage\\L6WX4BNM\\2307.html}
}

@article{ullahChallengesBarriersUsing2024,
  title = {Challenges and Barriers of Using Large Language Models ({{LLM}}) Such as {{ChatGPT}} for Diagnostic Medicine with a Focus on Digital Pathology -- a Recent Scoping Review},
  author = {Ullah, Ehsan and Parwani, Anil and Baig, Mirza Mansoor and Singh, Rajendra},
  year = {2024},
  month = feb,
  journal = {Diagn Pathol},
  volume = {19},
  number = {1},
  pages = {43},
  issn = {1746-1596},
  doi = {10.1186/s13000-024-01464-7},
  urldate = {2025-05-26},
  abstract = {The integration of large language models (LLMs) like ChatGPT in diagnostic medicine, with a focus on digital pathology, has garnered significant attention. However, understanding the challenges and barriers associated with the use of LLMs in this context is crucial for their successful implementation.},
  langid = {english},
  keywords = {AI,Challenges and barriers of using LLMs,ChatGPT,Diagnostic medicine,Digital pathology,Geriatrics,Health Communication,Large learning models,LLMs,Medical Humanities,Medical Law,Mixed Methods,ML,Pathology,Predictive medicine},
  file = {C:\Users\lenna\Zotero\storage\8ZZU7ISA\Ullah et al. - 2024 - Challenges and barriers of using large language mo.pdf}
}

@misc{vaswaniAttentionAllYou2023,
  title = {Attention {{Is All You Need}}},
  author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
  year = {2023},
  month = aug,
  number = {arXiv:1706.03762},
  eprint = {1706.03762},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1706.03762},
  urldate = {2025-08-19},
  abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\8YR9LYIB\\Vaswani et al. - 2023 - Attention Is All You Need.pdf;C\:\\Users\\lenna\\Zotero\\storage\\62GC8SGC\\1706.html}
}

@incollection{vormsFormatsRepresentationScientific2011,
  title = {Formats of {{Representation}} in {{Scientific Theorizing}}},
  booktitle = {Models, {{Simulations}}, and {{Representations}}},
  author = {Vorms, Marion},
  year = {2011},
  publisher = {Routledge},
  abstract = {Scientists use models as representations of systems or types of systems in order to gain knowledge about them: the representational relationship between features of the model and features of the system enables scientists to draw inferences concerning the system by reasoning with the model. Theoretical models, such as the simple pendulum, as well as data models, can be displayed in different formats: the equation of the simple pendulum can be written in Cartesian coordinates as well as in polar coordinates; temperature values in function of time can be displayed in a list as well as in a graph or a table. Lists and graphs can contain the same information though they convey it in different formats. This paper intends to show that the particular format in which a model is presented matters to the reasoning processes of its users. Moreover, it aims at clarifying the very notion of ``format.''},
  isbn = {978-0-203-80841-2}
}

@article{wangHistoryDevelopmentPrinciples2025,
  title = {History, Development, and Principles of Large Language Models: An Introductory Survey},
  shorttitle = {History, Development, and Principles of Large Language Models},
  author = {Wang, Zichong and Chu, Zhibo and Doan, Thang Viet and Ni, Shiwen and Yang, Min and Zhang, Wenbin},
  year = {2025},
  month = jun,
  journal = {AI Ethics},
  volume = {5},
  number = {3},
  pages = {1955--1971},
  issn = {2730-5961},
  doi = {10.1007/s43681-024-00583-7},
  urldate = {2025-08-06},
  abstract = {Language models serve as a cornerstone in natural language processing, utilizing mathematical methods to generalize language laws and knowledge for prediction and generation. Over extensive research spanning decades, language modeling has progressed from initial statistical language models to the contemporary landscape of large language models (LLMs). Notably, the swift evolution of LLMs has reached the ability to process, understand, and generate human-level text. Nevertheless, despite the significant advantages that LLMs offer in improving both work and personal lives, the limited understanding among general practitioners about the background and principles of these models hampers their full potential. Notably, most LLM reviews focus on specific aspects and utilize specialized language, posing a challenge for practitioners lacking relevant background knowledge. In light of this, this survey aims to present a comprehensible overview of LLMs to assist a broader audience. It strives to facilitate a comprehensive understanding by exploring the historical background of language models and tracing their evolution over time. The survey further investigates the factors influencing the development of LLMs, emphasizing key contributions. Additionally, it concentrates on elucidating the underlying principles of LLMs, equipping audiences with essential theoretical knowledge. The survey also highlights the limitations of existing work and points out promising future directions.},
  langid = {english},
  keywords = {Analytical Philosophy of Language,Artificial intelligence,Computational Linguistics,Evolution of language,Historical Linguistics,Language History,Language model,Large language model,Natural language processing,Research Methods in Language and Linguistics},
  file = {C:\Users\lenna\Zotero\storage\4QYH5ZLZ\Wang et al. - 2025 - History, development, and principles of large lang.pdf}
}

@misc{wangInstructUIEMultitaskInstruction2023,
  title = {{{InstructUIE}}: {{Multi-task Instruction Tuning}} for {{Unified Information Extraction}}},
  shorttitle = {{{InstructUIE}}},
  author = {Wang, Xiao and Zhou, Weikang and Zu, Can and Xia, Han and Chen, Tianze and Zhang, Yuansen and Zheng, Rui and Ye, Junjie and Zhang, Qi and Gui, Tao and Kang, Jihua and Yang, Jingsheng and Li, Siyuan and Du, Chunsai},
  year = {2023},
  month = apr,
  number = {arXiv:2304.08085},
  eprint = {2304.08085},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2304.08085},
  urldate = {2025-01-16},
  abstract = {Large language models have unlocked strong multi-task capabilities from reading instructive prompts. However, recent studies have shown that existing large models still have difficulty with information extraction tasks. For example, gpt-3.5-turbo achieved an F1 score of 18.22 on the Ontonotes dataset, which is significantly lower than the state-of-the-art performance. In this paper, we propose InstructUIE, a unified information extraction framework based on instruction tuning, which can uniformly model various information extraction tasks and capture the inter-task dependency. To validate the proposed method, we introduce IE INSTRUCTIONS, a benchmark of 32 diverse information extraction datasets in a unified text-to-text format with expert-written instructions. Experimental results demonstrate that our method achieves comparable performance to Bert in supervised settings and significantly outperforms the state-of-the-art and gpt3.5 in zero-shot settings.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\E24LF9SE\\Wang et al. - 2023 - InstructUIE Multi-task Instruction Tuning for Uni.pdf;C\:\\Users\\lenna\\Zotero\\storage\\QBX9X3AQ\\2304.html}
}

@article{wiestDeepSightEnhancing2024,
  title = {Deep Sight: Enhancing Periprocedural Adverse Event Recording in Endoscopy by Structuring Text Documentation with Privacy-Preserving Large Language Models},
  shorttitle = {Deep Sight},
  author = {Wiest, Isabella C. and Ferber, Dyke and Wittlinger, Stefan and Ebert, Matthias P. and Belle, Sebastian and Kather, Jakob Nikolas},
  year = {2024},
  month = dec,
  journal = {iGIE},
  volume = {3},
  number = {4},
  pages = {447-452.e5},
  publisher = {Elsevier},
  issn = {2949-7086},
  doi = {10.1016/j.igie.2024.08.001},
  urldate = {2025-01-16},
  langid = {english},
  keywords = {adverse event,AE,large language model,LLM,PoC-S,proof-of-concept set,test set,TS},
  file = {C:\Users\lenna\Zotero\storage\U64NMH3R\Wiest et al. - 2024 - Deep sight enhancing periprocedural adverse event.pdf}
}

@article{wiestPrivacypreservingLargeLanguage2024,
  title = {Privacy-Preserving Large Language Models for Structured Medical Information Retrieval},
  author = {Wiest, Isabella Catharina and Ferber, Dyke and Zhu, Jiefu and {van Treeck}, Marko and Meyer, Sonja K. and Juglan, Radhika and Carrero, Zunamys I. and Paech, Daniel and Kleesiek, Jens and Ebert, Matthias P. and Truhn, Daniel and Kather, Jakob Nikolas},
  year = {2024},
  month = sep,
  journal = {npj Digit. Med.},
  volume = {7},
  number = {1},
  pages = {1--9},
  publisher = {Nature Publishing Group},
  issn = {2398-6352},
  doi = {10.1038/s41746-024-01233-2},
  urldate = {2025-01-16},
  abstract = {Most clinical information is encoded as free text, not accessible for quantitative analysis. This study presents an open-source pipeline using the local large language model (LLM) ``Llama 2'' to extract quantitative information from clinical text and evaluates its performance in identifying features of decompensated liver cirrhosis. The LLM identified five key clinical features in a zero- and one-shot manner from 500 patient medical histories in the MIMIC IV dataset. We compared LLMs of three sizes and various prompt engineering approaches, with predictions compared against ground truth from three blinded medical experts. Our pipeline achieved high accuracy, detecting liver cirrhosis with 100\% sensitivity and 96\% specificity. High sensitivities and specificities were also yielded for detecting ascites (95\%, 95\%), confusion (76\%, 94\%), abdominal pain (84\%, 97\%), and shortness of breath (87\%, 97\%) using the 70 billion parameter model, which outperformed smaller versions. Our study successfully demonstrates the capability of locally deployed LLMs to extract clinical information from free text with low hardware requirements.},
  copyright = {2024 The Author(s)},
  langid = {english},
  keywords = {Digestive signs and symptoms,Health care,Liver diseases},
  file = {C:\Users\lenna\Zotero\storage\4RZWPFAH\Wiest et al. - 2024 - Privacy-preserving large language models for struc.pdf}
}

@misc{workshopBLOOM176BParameterOpenAccess2023,
  title = {{{BLOOM}}: {{A 176B-Parameter Open-Access Multilingual Language Model}}},
  shorttitle = {{{BLOOM}}},
  author = {Workshop, BigScience and Scao, Teven Le and Fan, Angela and Akiki, Christopher and Pavlick, Ellie and Ili{\'c}, Suzana and Hesslow, Daniel and Castagn{\'e}, Roman and Luccioni, Alexandra Sasha and Yvon, Fran{\c c}ois and Gall{\'e}, Matthias and Tow, Jonathan and Rush, Alexander M. and Biderman, Stella and Webson, Albert and Ammanamanchi, Pawan Sasanka and Wang, Thomas and Sagot, Beno{\^i}t and Muennighoff, Niklas and del Moral, Albert Villanova and Ruwase, Olatunji and Bawden, Rachel and Bekman, Stas and {McMillan-Major}, Angelina and Beltagy, Iz and Nguyen, Huu and Saulnier, Lucile and Tan, Samson and Suarez, Pedro Ortiz and Sanh, Victor and Lauren{\c c}on, Hugo and Jernite, Yacine and Launay, Julien and Mitchell, Margaret and Raffel, Colin and Gokaslan, Aaron and Simhi, Adi and Soroa, Aitor and Aji, Alham Fikri and Alfassy, Amit and Rogers, Anna and Nitzav, Ariel Kreisberg and Xu, Canwen and Mou, Chenghao and Emezue, Chris and Klamm, Christopher and Leong, Colin and van Strien, Daniel and Adelani, David Ifeoluwa and Radev, Dragomir and Ponferrada, Eduardo Gonz{\'a}lez and Levkovizh, Efrat and Kim, Ethan and Natan, Eyal Bar and Toni, Francesco De and Dupont, G{\'e}rard and Kruszewski, Germ{\'a}n and Pistilli, Giada and Elsahar, Hady and Benyamina, Hamza and Tran, Hieu and Yu, Ian and Abdulmumin, Idris and Johnson, Isaac and {Gonzalez-Dios}, Itziar and de la Rosa, Javier and Chim, Jenny and Dodge, Jesse and Zhu, Jian and Chang, Jonathan and Frohberg, J{\"o}rg and Tobing, Joseph and Bhattacharjee, Joydeep and Almubarak, Khalid and Chen, Kimbo and Lo, Kyle and Werra, Leandro Von and Weber, Leon and Phan, Long and {allal}, Loubna Ben and Tanguy, Ludovic and Dey, Manan and Mu{\~n}oz, Manuel Romero and Masoud, Maraim and Grandury, Mar{\'i}a and {\v S}a{\v s}ko, Mario and Huang, Max and Coavoux, Maximin and Singh, Mayank and Jiang, Mike Tian-Jian and Vu, Minh Chien and Jauhar, Mohammad A. and Ghaleb, Mustafa and Subramani, Nishant and Kassner, Nora and Khamis, Nurulaqilla and Nguyen, Olivier and Espejel, Omar and de Gibert, Ona and Villegas, Paulo and Henderson, Peter and Colombo, Pierre and Amuok, Priscilla and Lhoest, Quentin and Harliman, Rheza and Bommasani, Rishi and L{\'o}pez, Roberto Luis and Ribeiro, Rui and Osei, Salomey and Pyysalo, Sampo and Nagel, Sebastian and Bose, Shamik and Muhammad, Shamsuddeen Hassan and Sharma, Shanya and Longpre, Shayne and Nikpoor, Somaieh and Silberberg, Stanislav and Pai, Suhas and Zink, Sydney and Torrent, Tiago Timponi and Schick, Timo and Thrush, Tristan and Danchev, Valentin and Nikoulina, Vassilina and Laippala, Veronika and Lepercq, Violette and Prabhu, Vrinda and Alyafeai, Zaid and Talat, Zeerak and Raja, Arun and Heinzerling, Benjamin and Si, Chenglei and Ta{\c s}ar, Davut Emre and Salesky, Elizabeth and Mielke, Sabrina J. and Lee, Wilson Y. and Sharma, Abheesht and Santilli, Andrea and Chaffin, Antoine and Stiegler, Arnaud and Datta, Debajyoti and Szczechla, Eliza and Chhablani, Gunjan and Wang, Han and Pandey, Harshit and Strobelt, Hendrik and Fries, Jason Alan and Rozen, Jos and Gao, Leo and Sutawika, Lintang and Bari, M. Saiful and {Al-shaibani}, Maged S. and Manica, Matteo and Nayak, Nihal and Teehan, Ryan and Albanie, Samuel and Shen, Sheng and {Ben-David}, Srulik and Bach, Stephen H. and Kim, Taewoon and Bers, Tali and Fevry, Thibault and Neeraj, Trishala and Thakker, Urmish and Raunak, Vikas and Tang, Xiangru and Yong, Zheng-Xin and Sun, Zhiqing and Brody, Shaked and Uri, Yallow and Tojarieh, Hadar and Roberts, Adam and Chung, Hyung Won and Tae, Jaesung and Phang, Jason and Press, Ofir and Li, Conglong and Narayanan, Deepak and Bourfoune, Hatim and Casper, Jared and Rasley, Jeff and Ryabinin, Max and Mishra, Mayank and Zhang, Minjia and Shoeybi, Mohammad and Peyrounette, Myriam and Patry, Nicolas and Tazi, Nouamane and Sanseviero, Omar and von Platen, Patrick and Cornette, Pierre and Lavall{\'e}e, Pierre Fran{\c c}ois and Lacroix, R{\'e}mi and Rajbhandari, Samyam and Gandhi, Sanchit and Smith, Shaden and Requena, St{\'e}phane and Patil, Suraj and Dettmers, Tim and Baruwa, Ahmed and Singh, Amanpreet and Cheveleva, Anastasia and Ligozat, Anne-Laure and Subramonian, Arjun and N{\'e}v{\'e}ol, Aur{\'e}lie and Lovering, Charles and Garrette, Dan and Tunuguntla, Deepak and Reiter, Ehud and Taktasheva, Ekaterina and Voloshina, Ekaterina and Bogdanov, Eli and Winata, Genta Indra and Schoelkopf, Hailey and Kalo, Jan-Christoph and Novikova, Jekaterina and Forde, Jessica Zosa and Clive, Jordan and Kasai, Jungo and Kawamura, Ken and Hazan, Liam and Carpuat, Marine and Clinciu, Miruna and Kim, Najoung and Cheng, Newton and Serikov, Oleg and Antverg, Omer and van der Wal, Oskar and Zhang, Rui and Zhang, Ruochen and Gehrmann, Sebastian and Mirkin, Shachar and Pais, Shani and Shavrina, Tatiana and Scialom, Thomas and Yun, Tian and Limisiewicz, Tomasz and Rieser, Verena and Protasov, Vitaly and Mikhailov, Vladislav and Pruksachatkun, Yada and Belinkov, Yonatan and Bamberger, Zachary and Kasner, Zden{\v e}k and Rueda, Alice and Pestana, Amanda and Feizpour, Amir and Khan, Ammar and Faranak, Amy and Santos, Ana and Hevia, Anthony and Unldreaj, Antigona and Aghagol, Arash and Abdollahi, Arezoo and Tammour, Aycha and HajiHosseini, Azadeh and Behroozi, Bahareh and Ajibade, Benjamin and Saxena, Bharat and Ferrandis, Carlos Mu{\~n}oz and McDuff, Daniel and Contractor, Danish and Lansky, David and David, Davis and Kiela, Douwe and Nguyen, Duong A. and Tan, Edward and Baylor, Emi and Ozoani, Ezinwanne and Mirza, Fatima and Ononiwu, Frankline and Rezanejad, Habib and Jones, Hessie and Bhattacharya, Indrani and Solaiman, Irene and Sedenko, Irina and Nejadgholi, Isar and Passmore, Jesse and Seltzer, Josh and Sanz, Julio Bonis and Dutra, Livia and Samagaio, Mairon and Elbadri, Maraim and Mieskes, Margot and Gerchick, Marissa and Akinlolu, Martha and McKenna, Michael and Qiu, Mike and Ghauri, Muhammed and Burynok, Mykola and Abrar, Nafis and Rajani, Nazneen and Elkott, Nour and Fahmy, Nour and Samuel, Olanrewaju and An, Ran and Kromann, Rasmus and Hao, Ryan and Alizadeh, Samira and Shubber, Sarmad and Wang, Silas and Roy, Sourav and Viguier, Sylvain and Le, Thanh and Oyebade, Tobi and Le, Trieu and Yang, Yoyo and Nguyen, Zach and Kashyap, Abhinav Ramesh and Palasciano, Alfredo and Callahan, Alison and Shukla, Anima and {Miranda-Escalada}, Antonio and Singh, Ayush and Beilharz, Benjamin and Wang, Bo and Brito, Caio and Zhou, Chenxi and Jain, Chirag and Xu, Chuxin and Fourrier, Cl{\'e}mentine and Peri{\~n}{\'a}n, Daniel Le{\'o}n and Molano, Daniel and Yu, Dian and Manjavacas, Enrique and Barth, Fabio and Fuhrimann, Florian and Altay, Gabriel and Bayrak, Giyaseddin and Burns, Gully and Vrabec, Helena U. and Bello, Imane and Dash, Ishani and Kang, Jihyun and Giorgi, John and Golde, Jonas and Posada, Jose David and Sivaraman, Karthik Rangasai and Bulchandani, Lokesh and Liu, Lu and Shinzato, Luisa and de Bykhovetz, Madeleine Hahn and Takeuchi, Maiko and P{\`a}mies, Marc and Castillo, Maria A. and Nezhurina, Marianna and S{\"a}nger, Mario and Samwald, Matthias and Cullan, Michael and Weinberg, Michael and Wolf, Michiel De and Mihaljcic, Mina and Liu, Minna and Freidank, Moritz and Kang, Myungsun and Seelam, Natasha and Dahlberg, Nathan and Broad, Nicholas Michio and Muellner, Nikolaus and Fung, Pascale and Haller, Patrick and Chandrasekhar, Ramya and Eisenberg, Renata and Martin, Robert and Canalli, Rodrigo and Su, Rosaline and Su, Ruisi and Cahyawijaya, Samuel and Garda, Samuele and Deshmukh, Shlok S. and Mishra, Shubhanshu and Kiblawi, Sid and Ott, Simon and {Sang-aroonsiri}, Sinee and Kumar, Srishti and Schweter, Stefan and Bharati, Sushil and Laud, Tanmay and Gigant, Th{\'e}o and Kainuma, Tomoya and Kusa, Wojciech and Labrak, Yanis and Bajaj, Yash Shailesh and Venkatraman, Yash and Xu, Yifan and Xu, Yingxin and Xu, Yu and Tan, Zhe and Xie, Zhongli and Ye, Zifan and Bras, Mathilde and Belkada, Younes and Wolf, Thomas},
  year = {2023},
  month = jun,
  number = {arXiv:2211.05100},
  eprint = {2211.05100},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2211.05100},
  urldate = {2025-08-19},
  abstract = {Large language models (LLMs) have been shown to be able to perform new tasks based on a few demonstrations or natural language instructions. While these capabilities have led to widespread adoption, most LLMs are developed by resource-rich organizations and are frequently kept from the public. As a step towards democratizing this powerful technology, we present BLOOM, a 176B-parameter open-access language model designed and built thanks to a collaboration of hundreds of researchers. BLOOM is a decoder-only Transformer language model that was trained on the ROOTS corpus, a dataset comprising hundreds of sources in 46 natural and 13 programming languages (59 in total). We find that BLOOM achieves competitive performance on a wide variety of benchmarks, with stronger results after undergoing multitask prompted finetuning. To facilitate future research and applications using LLMs, we publicly release our models and code under the Responsible AI License.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\WNFEL9E6\\Workshop et al. - 2023 - BLOOM A 176B-Parameter Open-Access Multilingual L.pdf;C\:\\Users\\lenna\\Zotero\\storage\\FUTC94YQ\\2211.html}
}

@misc{xiaAnalyzing16193LLM2025,
  title = {Analyzing 16,193 {{LLM Papers}} for {{Fun}} and {{Profits}}},
  author = {Xia, Zhiqiu and Zhu, Lang and Li, Bingzhe and Chen, Feng and Li, Qiannan and Liao, Chunhua and Wang, Feiyi and Liu, Hang},
  year = {2025},
  month = apr,
  number = {arXiv:2504.08619},
  eprint = {2504.08619},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2504.08619},
  urldate = {2025-08-08},
  abstract = {Large Language Models (LLMs) are reshaping the landscape of computer science research, driving significant shifts in research priorities across diverse conferences and fields. This study provides a comprehensive analysis of the publication trend of LLM-related papers in 77 top-tier computer science conferences over the past six years (2019-2024). We approach this analysis from four distinct perspectives: (1) We investigate how LLM research is driving topic shifts within major conferences. (2) We adopt a topic modeling approach to identify various areas of LLM-related topic growth and reveal the topics of concern at different conferences. (3) We explore distinct contribution patterns of academic and industrial institutions. (4) We study the influence of national origins on LLM development trajectories. Synthesizing the findings from these diverse analytical angles, we derive ten key insights that illuminate the dynamics and evolution of the LLM research ecosystem.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Digital Libraries},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\LNY4ZED5\\Xia et al. - 2025 - Analyzing 16,193 LLM Papers for Fun and Profits.pdf;C\:\\Users\\lenna\\Zotero\\storage\\TIQYQMAP\\2504.html}
}

@article{xuLargeLanguageModels2024,
  title = {Large Language Models for Generative Information Extraction: A Survey},
  shorttitle = {Large Language Models for Generative Information Extraction},
  author = {Xu, Derong and Chen, Wei and Peng, Wenjun and Zhang, Chao and Xu, Tong and Zhao, Xiangyu and Wu, Xian and Zheng, Yefeng and Wang, Yang and Chen, Enhong},
  year = {2024},
  month = nov,
  journal = {Front. Comput. Sci.},
  volume = {18},
  number = {6},
  pages = {186357},
  issn = {2095-2236},
  doi = {10.1007/s11704-024-40555-y},
  urldate = {2024-12-19},
  abstract = {Information Extraction (IE) aims to extract structural knowledge from plain natural language texts. Recently, generative Large Language Models (LLMs) have demonstrated remarkable capabilities in text understanding and generation. As a result, numerous works have been proposed to integrate LLMs for IE tasks based on a generative paradigm. To conduct a comprehensive systematic review and exploration of LLM efforts for IE tasks, in this study, we survey the most recent advancements in this field. We first present an extensive overview by categorizing these works in terms of various IE subtasks and techniques, and then we empirically analyze the most advanced methods and discover the emerging trend of IE tasks with LLMs. Based on a thorough review conducted, we identify several insights in technique and promising research directions that deserve further exploration in future studies. We maintain a public repository and consistently update related works and resources on GitHub (LLM4IE repository).},
  langid = {english},
  keywords = {information extraction,large language models,review},
  file = {C:\Users\lenna\Zotero\storage\2QMWKCNG\Xu et al. - 2024 - Large language models for generative information e.pdf}
}

@inproceedings{zhaiLargeLanguageModels2024,
  title = {Large {{Language Models}} and {{Future}} of {{Information Retrieval}}: {{Opportunities}} and {{Challenges}}},
  shorttitle = {Large {{Language Models}} and {{Future}} of {{Information Retrieval}}},
  booktitle = {Proceedings of the 47th {{International ACM SIGIR Conference}} on {{Research}} and {{Development}} in {{Information Retrieval}}},
  author = {Zhai, ChengXiang},
  year = {2024},
  month = jul,
  series = {{{SIGIR}} '24},
  pages = {481--490},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  doi = {10.1145/3626772.3657848},
  urldate = {2024-12-19},
  abstract = {Recent years have seen great success of large language models (LLMs) in performing many natural language processing tasks with impressive performance, including tasks that directly serve users such as question answering and text summarization. They open up unprecedented opportunities for transforming information retrieval (IR) research and applications. However, concerns such as halluciation undermine their trustworthiness, limiting their actual utility when deployed in real-world applications, especially high-stake applications where trust is vital. How can we both exploit the strengths of LLMs and mitigate any risk caused by their weaknesses when applying LLMs to IR? What are the best opportunities for us to apply LLMs to IR? What are the major challenges that we will need to address in the future to fully exploit such opportunities? Given the anticipated growth of LLMs, what will future information retrieval systems look like? Will LLMs eventually replace an IR system? In this perspective paper, we examine these questions and provide provisional answers to them. We argue that LLMs will not be able to replace search engines, and future LLMs would need to learn how to use a search engine so that they can interact with a search engine on behalf of users. We conclude with a set of promising future research directions in applying LLMs to IR.},
  isbn = {9798400704314},
  file = {C:\Users\lenna\Zotero\storage\KQEBUAGI\Zhai - 2024 - Large Language Models and Future of Information Re.pdf}
}

@article{zhangAutomaticPromptDesign2025,
  title = {Automatic Prompt Design via Particle Swarm Optimization Driven {{LLM}} for Efficient Medical Information Extraction},
  author = {Zhang, Tian and Ma, Lianbo and Cheng, Shi and Liu, Yikai and Li, Nan and Wang, Hongjiang},
  year = {2025},
  month = jun,
  journal = {Swarm and Evolutionary Computation},
  volume = {95},
  pages = {101922},
  issn = {2210-6502},
  doi = {10.1016/j.swevo.2025.101922},
  urldate = {2025-07-16},
  abstract = {Medical information extraction (IE) is an essential aspect of electronic health records (EHRs), but it is a challenging task that converts plain text into structured knowledge, where domain models struggle to achieve performance. Recently, large language models (LLMs), which have demonstrated remarkable capabilities in text understanding and generation, have emerged as a promising method for handling natural language texts. However, LLMs are too dependent on elaborate prompts, resulting in extensive expert knowledge and manual prompt templates needed. In this work, we propose a novel method for the automatic prompt design, called Particle Swarm Optimization-based Prompt using a Large language model (PSOPL). As an efficient method for medical information extraction from EHRs, PSOPL can allow particle swarm optimization (PSO) to automate design prompts by leveraging LLM's ability to generate coherent text token-by-token. Specifically, starting with a small number of initial prompts, evolutionary operators in PSOPL guide the LLM to generate new candidate prompts iteratively, and the PSOPL evaluates population fitness to retain the optimal prompts. In this way, PSOPL can achieve prompt evolution without model training and reduce the human effort and requirement for domain knowledge. We conducted experiments for open-source LLMs (e.g., Alpaca-7B, GPT-J-6B) and closed-source LLM (e.g., GLM-4), on public medical datasets (e.g., CMeEE, CMeIE, CHIP-CDEE) covering information extraction tasks (e.g., named Entity recognition, relation extraction, event extraction) to verify the method's generalizability. The experimental results demonstrate the potential of using PSO-based LLMs to design prompts automatically, allowing for the swift extraction of important information about patients in the EHRs.},
  keywords = {Electronic health record,Information extraction,Large language model,Particle swarm optimization,Prompt design},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\77LQ5IQN\\Zhang et al. - 2025 - Automatic prompt design via particle swarm optimiz.pdf;C\:\\Users\\lenna\\Zotero\\storage\\CWFB76HE\\S221065022500080X.html}
}

@article{zhangAutomaticPromptDesign2025a,
  title = {Automatic Prompt Design via Particle Swarm Optimization Driven {{LLM}} for Efficient Medical Information Extraction},
  author = {Zhang, Tian and Ma, Lianbo and Cheng, Shi and Liu, Yikai and Li, Nan and Wang, Hongjiang},
  year = {2025},
  month = jun,
  journal = {Swarm and Evolutionary Computation},
  volume = {95},
  pages = {101922},
  issn = {2210-6502},
  doi = {10.1016/j.swevo.2025.101922},
  urldate = {2025-07-16},
  abstract = {Medical information extraction (IE) is an essential aspect of electronic health records (EHRs), but it is a challenging task that converts plain text into structured knowledge, where domain models struggle to achieve performance. Recently, large language models (LLMs), which have demonstrated remarkable capabilities in text understanding and generation, have emerged as a promising method for handling natural language texts. However, LLMs are too dependent on elaborate prompts, resulting in extensive expert knowledge and manual prompt templates needed. In this work, we propose a novel method for the automatic prompt design, called Particle Swarm Optimization-based Prompt using a Large language model (PSOPL). As an efficient method for medical information extraction from EHRs, PSOPL can allow particle swarm optimization (PSO) to automate design prompts by leveraging LLM's ability to generate coherent text token-by-token. Specifically, starting with a small number of initial prompts, evolutionary operators in PSOPL guide the LLM to generate new candidate prompts iteratively, and the PSOPL evaluates population fitness to retain the optimal prompts. In this way, PSOPL can achieve prompt evolution without model training and reduce the human effort and requirement for domain knowledge. We conducted experiments for open-source LLMs (e.g., Alpaca-7B, GPT-J-6B) and closed-source LLM (e.g., GLM-4), on public medical datasets (e.g., CMeEE, CMeIE, CHIP-CDEE) covering information extraction tasks (e.g., named Entity recognition, relation extraction, event extraction) to verify the method's generalizability. The experimental results demonstrate the potential of using PSO-based LLMs to design prompts automatically, allowing for the swift extraction of important information about patients in the EHRs.},
  keywords = {Electronic health record,Information extraction,Large language model,Particle swarm optimization,Prompt design},
  file = {C:\Users\lenna\Zotero\storage\9HKJJES6\S221065022500080X.html}
}

@misc{zhangMethodArchitectureMedical2025,
  title = {A {{Method}} for the {{Architecture}} of a {{Medical Vertical Large Language Model Based}} on {{Deepseek R1}}},
  author = {Zhang, Mingda and Qin, Jianglong},
  year = {2025},
  month = apr,
  number = {arXiv:2505.00025},
  eprint = {2505.00025},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2505.00025},
  urldate = {2025-06-03},
  abstract = {In recent years, despite foundation models like DeepSeek-R1 and ChatGPT demonstrating significant capabilities in general tasks, professional knowledge barriers, computational resource requirements, and deployment environment limitations have severely hindered their application in actual medical scenarios. Addressing these challenges, this paper proposes an efficient lightweight medical vertical large language model architecture method, systematically solving the lightweight problem of medical large models from three dimensions: knowledge acquisition, model compression, and computational optimization. At the knowledge acquisition level, a knowledge transfer pipeline is designed from the fine-tuned DeepSeek-R1-Distill-70B teacher model to the DeepSeek-R1-Distill-7B student model, and Low-Rank Adaptation (LoRA) technology is adopted to precisely adjust key attention layers. At the model compression level, compression techniques including 4-bit weight quantization are implemented while preserving the core representation ability for medical reasoning. At the computational optimization level, inference optimization techniques such as Flash Attention acceleration and continuous batching are integrated, and a professional prompt template system is constructed to adapt to different types of medical problems. Experimental results on medical question-answering datasets show that the method proposed in this paper maintains professional accuracy while reducing memory consumption by 64.7{\textbackslash}\% and inference latency by 12.4{\textbackslash}\%, providing an effective solution for the application of medical large models in resource-constrained environments such as edge computing devices.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\2CGFMGWE\\Zhang und Qin - 2025 - A Method for the Architecture of a Medical Vertica.pdf;C\:\\Users\\lenna\\Zotero\\storage\\8SGBRDCQ\\2505.html}
}

@article{zhaoExplainabilityLargeLanguage2024,
  title = {Explainability for {{Large Language Models}}: {{A Survey}}},
  shorttitle = {Explainability for {{Large Language Models}}},
  author = {Zhao, Haiyan and Chen, Hanjie and Yang, Fan and Liu, Ninghao and Deng, Huiqi and Cai, Hengyi and Wang, Shuaiqiang and Yin, Dawei and Du, Mengnan},
  year = {2024},
  month = feb,
  journal = {ACM Trans. Intell. Syst. Technol.},
  volume = {15},
  number = {2},
  pages = {20:1--20:38},
  issn = {2157-6904},
  doi = {10.1145/3639372},
  urldate = {2025-07-16},
  abstract = {Large language models (LLMs) have demonstrated impressive capabilities in natural language processing. However, their internal mechanisms are still unclear and this lack of transparency poses unwanted risks for downstream applications. Therefore, understanding and explaining these models is crucial for elucidating their behaviors, limitations, and social impacts. In this article, we introduce a taxonomy of explainability techniques and provide a structured overview of methods for explaining Transformer-based language models. We categorize techniques based on the training paradigms of LLMs: traditional fine-tuning-based paradigm and prompting-based paradigm. For each paradigm, we summarize the goals and dominant approaches for generating local explanations of individual predictions and global explanations of overall model knowledge. We also discuss metrics for evaluating generated explanations and discuss how explanations can be leveraged to debug models and improve performance. Lastly, we examine key challenges and emerging opportunities for explanation techniques in the era of LLMs in comparison to conventional deep learning models.},
  file = {C:\Users\lenna\Zotero\storage\5VQPZU5B\Zhao et al. - 2024 - Explainability for Large Language Models A Survey.pdf}
}

@article{zhouExtractingSymbolicRules2003,
  title = {Extracting Symbolic Rules from Trained Neural Network Ensembles},
  author = {Zhou, Zhi-Hua and Jiang, Yuan and Chen, Shi-Fu},
  year = {2003},
  month = jan,
  journal = {AI Communications},
  volume = {16},
  number = {1},
  pages = {3--15},
  publisher = {IOS Press},
  issn = {0921-7126},
  urldate = {2024-08-06},
  abstract = {Neural network ensemble can significantly improve the generalization ability of neural network based systems. However, its comprehensibility is even worse than that of a single neural network because it comprises a collection of individual neural net},
  langid = {english}
}

@misc{zhuLargeLanguageModels2024,
  title = {Large {{Language Models}} for {{Information Retrieval}}: {{A Survey}}},
  shorttitle = {Large {{Language Models}} for {{Information Retrieval}}},
  author = {Zhu, Yutao and Yuan, Huaying and Wang, Shuting and Liu, Jiongnan and Liu, Wenhan and Deng, Chenlong and Chen, Haonan and Liu, Zheng and Dou, Zhicheng and Wen, Ji-Rong},
  year = {2024},
  month = sep,
  number = {arXiv:2308.07107},
  eprint = {2308.07107},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.2308.07107},
  urldate = {2024-12-19},
  abstract = {As a primary means of information acquisition, information retrieval (IR) systems, such as search engines, have integrated themselves into our daily lives. These systems also serve as components of dialogue, question-answering, and recommender systems. The trajectory of IR has evolved dynamically from its origins in term-based methods to its integration with advanced neural models. While the neural models excel at capturing complex contextual signals and semantic nuances, thereby reshaping the IR landscape, they still face challenges such as data scarcity, interpretability, and the generation of contextually plausible yet potentially inaccurate responses. This evolution requires a combination of both traditional methods (such as term-based sparse retrieval methods with rapid response) and modern neural architectures (such as language models with powerful language understanding capacity). Meanwhile, the emergence of large language models (LLMs), typified by ChatGPT and GPT-4, has revolutionized natural language processing due to their remarkable language understanding, generation, generalization, and reasoning abilities. Consequently, recent research has sought to leverage LLMs to improve IR systems. Given the rapid evolution of this research trajectory, it is necessary to consolidate existing methodologies and provide nuanced insights through a comprehensive overview. In this survey, we delve into the confluence of LLMs and IR systems, including crucial aspects such as query rewriters, retrievers, rerankers, and readers. Additionally, we explore promising directions, such as search agents, within this expanding field.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Information Retrieval},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\US5R2ZFQ\\Zhu et al. - 2024 - Large Language Models for Information Retrieval A.pdf;C\:\\Users\\lenna\\Zotero\\storage\\XTBZV77A\\2308.html}
}

@misc{zieglerFineTuningLanguageModels2020,
  title = {Fine-{{Tuning Language Models}} from {{Human Preferences}}},
  author = {Ziegler, Daniel M. and Stiennon, Nisan and Wu, Jeffrey and Brown, Tom B. and Radford, Alec and Amodei, Dario and Christiano, Paul and Irving, Geoffrey},
  year = {2020},
  month = jan,
  number = {arXiv:1909.08593},
  eprint = {1909.08593},
  primaryclass = {cs},
  publisher = {arXiv},
  doi = {10.48550/arXiv.1909.08593},
  urldate = {2025-08-18},
  abstract = {Reward learning enables the application of reinforcement learning (RL) to tasks where reward is defined by human judgment, building a model of reward by asking humans questions. Most work on reward learning has used simulated environments, but complex information about values is often expressed in natural language, and we believe reward learning for language is a key to making RL practical and safe for real-world tasks. In this paper, we build on advances in generative pretraining of language models to apply reward learning to four natural language tasks: continuing text with positive sentiment or physically descriptive language, and summarization tasks on the TL;DR and CNN/Daily Mail datasets. For stylistic continuation we achieve good results with only 5,000 comparisons evaluated by humans. For summarization, models trained with 60,000 comparisons copy whole sentences from the input but skip irrelevant preamble; this leads to reasonable ROUGE scores and very good performance according to our human labelers, but may be exploiting the fact that labelers rely on simple heuristics.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computation and Language,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\NW3HB9CX\\Ziegler et al. - 2020 - Fine-Tuning Language Models from Human Preferences.pdf;C\:\\Users\\lenna\\Zotero\\storage\\QPXM4VEM\\1909.html}
}

@misc{ZoteroDownloads,
  title = {Zotero {\textbar} {{Downloads}}},
  urldate = {2024-04-30},
  howpublished = {https://www.zotero.org/download/},
  file = {C:\Users\lenna\Zotero\storage\5VZAU6TR\download.html}
}

@misc{ZulassungKIbasiertenMedizinprodukten,
  title = {{Zulassung von KI-basierten Medizinprodukten in Europa}},
  urldate = {2025-02-02},
  abstract = {Welche regulatorischen Anforderungen gibt die MDR f{\"u}r KI-basierte Medizinprodukte vor? Hier finden Sie Informationen und Vorgehensweisen f{\"u}r Europa.},
  howpublished = {https://www.vde.com/topics-de/health/beratung/zulassung-von-ki-basierten-medizinprodukten-in-europa},
  langid = {ngerman},
  file = {C\:\\Users\\lenna\\Zotero\\storage\\KLKCK8GH\\Sudmann - Questionnaire Artificial Intelligence in medical d.pdf;C\:\\Users\\lenna\\Zotero\\storage\\K64GB9LD\\zulassung-von-ki-basierten-medizinprodukten-in-europa.html}
}

@misc{ZuoLlavamedv15mistral7b_q8_0,
  title = {Z-Uo/Llava-Med-v1.5-Mistral-7b\_q8\_0},
  urldate = {2025-08-12},
  abstract = {This is a 8 bit quantized version of Large Language and Vision Assistant for bio Medicine},
  howpublished = {https://ollama.com/z-uo/llava-med-v1.5-mistral-7b\_q8\_0},
  keywords = {evaluation_models},
  file = {C:\Users\lenna\Zotero\storage\CDQB5C6C\llava-med-v1.html}
}
